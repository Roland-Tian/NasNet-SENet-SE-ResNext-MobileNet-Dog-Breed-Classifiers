{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Human face detector with OpenCV, for comparison with dog breed later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 13233 total human images.\n",
      "There are 8351 total dog images.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from glob import glob\n",
    "\n",
    "# load filenames for human and dog images\n",
    "human_files = np.array(glob(\"D:\\Python\\deep-learning-v2-pytorch\\project-dog-classification\\lfw\\*\\*\"))\n",
    "dog_files = np.array(glob(\"D:\\Python\\deep-learning-v2-pytorch\\project-dog-classification\\dogImages\\*\\*\\*\"))\n",
    "\n",
    "# print number of images in each dataset\n",
    "print('There are %d total human images.' % len(human_files))\n",
    "print('There are %d total dog images.' % len(dog_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2                \n",
    "import matplotlib.pyplot as plt                        \n",
    "%matplotlib inline  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of faces detected: 1\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# extract pre-trained face detector\n",
    "face_cascade = cv2.CascadeClassifier('haarcascades/haarcascade_frontalface_alt.xml')\n",
    "\n",
    "# load color (BGR) image\n",
    "img = cv2.imread(human_files[0])\n",
    "# convert BGR image to grayscale\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# find faces in image\n",
    "faces = face_cascade.detectMultiScale(gray)\n",
    "\n",
    "# print number of faces detected in the image\n",
    "print('Number of faces detected:', len(faces))\n",
    "\n",
    "# get bounding box for each detected face\n",
    "for (x,y,w,h) in faces:\n",
    "    # add bounding box to color image\n",
    "    cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "    \n",
    "# convert BGR image to RGB for plotting\n",
    "cv_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# display the image, along with bounding box\n",
    "plt.imshow(cv_rgb)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns \"True\" if face is detected in image stored at img_path\n",
    "def face_detector(img_path):\n",
    "    img = cv2.imread(img_path)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray)\n",
    "    return len(faces) > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human faces detected in human images: 96.0 %\n",
      "Human faces detected in dog images: 17.0 %\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "human_files_short = human_files[:100]\n",
    "dog_files_short = dog_files[:100]\n",
    "\n",
    "human_in_human_counter = 0\n",
    "for humanimage in human_files_short:\n",
    "    human_in_human_counter += face_detector(humanimage)\n",
    "print(\"Human faces detected in human images:\", (human_in_human_counter/len(human_files_short))*100, '%')\n",
    "\n",
    "human_in_dog_counter = 0\n",
    "for dogimage in dog_files_short:\n",
    "    human_in_dog_counter += face_detector(dogimage)\n",
    "print(\"Human faces detected in dog images:\", (human_in_dog_counter/len(dog_files_short))*100, '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human faces detected in human images: 99.47101942114412 %\n"
     ]
    }
   ],
   "source": [
    "for humanimage in human_files:\n",
    "    human_in_human_counter += face_detector(humanimage)\n",
    "print(\"Human faces detected in human images:\", (human_in_human_counter/len(human_files))*100, '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGG Dog Detector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "\n",
    "# define VGG16 model\n",
    "VGG16 = models.vgg16(pretrained=True)\n",
    "\n",
    "# check if CUDA is available\n",
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "# move model to GPU if CUDA is available\n",
    "if use_cuda:\n",
    "    VGG16 = VGG16.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'tench, Tinca tinca',\n",
       " 1: 'goldfish, Carassius auratus',\n",
       " 2: 'great white shark, white shark, man-eater, man-eating shark, Carcharodon carcharias',\n",
       " 3: 'tiger shark, Galeocerdo cuvieri',\n",
       " 4: 'hammerhead, hammerhead shark',\n",
       " 5: 'electric ray, crampfish, numbfish, torpedo',\n",
       " 6: 'stingray',\n",
       " 7: 'cock',\n",
       " 8: 'hen',\n",
       " 9: 'ostrich, Struthio camelus',\n",
       " 10: 'brambling, Fringilla montifringilla',\n",
       " 11: 'goldfinch, Carduelis carduelis',\n",
       " 12: 'house finch, linnet, Carpodacus mexicanus',\n",
       " 13: 'junco, snowbird',\n",
       " 14: 'indigo bunting, indigo finch, indigo bird, Passerina cyanea',\n",
       " 15: 'robin, American robin, Turdus migratorius',\n",
       " 16: 'bulbul',\n",
       " 17: 'jay',\n",
       " 18: 'magpie',\n",
       " 19: 'chickadee',\n",
       " 20: 'water ouzel, dipper',\n",
       " 21: 'kite',\n",
       " 22: 'bald eagle, American eagle, Haliaeetus leucocephalus',\n",
       " 23: 'vulture',\n",
       " 24: 'great grey owl, great gray owl, Strix nebulosa',\n",
       " 25: 'European fire salamander, Salamandra salamandra',\n",
       " 26: 'common newt, Triturus vulgaris',\n",
       " 27: 'eft',\n",
       " 28: 'spotted salamander, Ambystoma maculatum',\n",
       " 29: 'axolotl, mud puppy, Ambystoma mexicanum',\n",
       " 30: 'bullfrog, Rana catesbeiana',\n",
       " 31: 'tree frog, tree-frog',\n",
       " 32: 'tailed frog, bell toad, ribbed toad, tailed toad, Ascaphus trui',\n",
       " 33: 'loggerhead, loggerhead turtle, Caretta caretta',\n",
       " 34: 'leatherback turtle, leatherback, leathery turtle, Dermochelys coriacea',\n",
       " 35: 'mud turtle',\n",
       " 36: 'terrapin',\n",
       " 37: 'box turtle, box tortoise',\n",
       " 38: 'banded gecko',\n",
       " 39: 'common iguana, iguana, Iguana iguana',\n",
       " 40: 'American chameleon, anole, Anolis carolinensis',\n",
       " 41: 'whiptail, whiptail lizard',\n",
       " 42: 'agama',\n",
       " 43: 'frilled lizard, Chlamydosaurus kingi',\n",
       " 44: 'alligator lizard',\n",
       " 45: 'Gila monster, Heloderma suspectum',\n",
       " 46: 'green lizard, Lacerta viridis',\n",
       " 47: 'African chameleon, Chamaeleo chamaeleon',\n",
       " 48: 'Komodo dragon, Komodo lizard, dragon lizard, giant lizard, Varanus komodoensis',\n",
       " 49: 'African crocodile, Nile crocodile, Crocodylus niloticus',\n",
       " 50: 'American alligator, Alligator mississipiensis',\n",
       " 51: 'triceratops',\n",
       " 52: 'thunder snake, worm snake, Carphophis amoenus',\n",
       " 53: 'ringneck snake, ring-necked snake, ring snake',\n",
       " 54: 'hognose snake, puff adder, sand viper',\n",
       " 55: 'green snake, grass snake',\n",
       " 56: 'king snake, kingsnake',\n",
       " 57: 'garter snake, grass snake',\n",
       " 58: 'water snake',\n",
       " 59: 'vine snake',\n",
       " 60: 'night snake, Hypsiglena torquata',\n",
       " 61: 'boa constrictor, Constrictor constrictor',\n",
       " 62: 'rock python, rock snake, Python sebae',\n",
       " 63: 'Indian cobra, Naja naja',\n",
       " 64: 'green mamba',\n",
       " 65: 'sea snake',\n",
       " 66: 'horned viper, cerastes, sand viper, horned asp, Cerastes cornutus',\n",
       " 67: 'diamondback, diamondback rattlesnake, Crotalus adamanteus',\n",
       " 68: 'sidewinder, horned rattlesnake, Crotalus cerastes',\n",
       " 69: 'trilobite',\n",
       " 70: 'harvestman, daddy longlegs, Phalangium opilio',\n",
       " 71: 'scorpion',\n",
       " 72: 'black and gold garden spider, Argiope aurantia',\n",
       " 73: 'barn spider, Araneus cavaticus',\n",
       " 74: 'garden spider, Aranea diademata',\n",
       " 75: 'black widow, Latrodectus mactans',\n",
       " 76: 'tarantula',\n",
       " 77: 'wolf spider, hunting spider',\n",
       " 78: 'tick',\n",
       " 79: 'centipede',\n",
       " 80: 'black grouse',\n",
       " 81: 'ptarmigan',\n",
       " 82: 'ruffed grouse, partridge, Bonasa umbellus',\n",
       " 83: 'prairie chicken, prairie grouse, prairie fowl',\n",
       " 84: 'peacock',\n",
       " 85: 'quail',\n",
       " 86: 'partridge',\n",
       " 87: 'African grey, African gray, Psittacus erithacus',\n",
       " 88: 'macaw',\n",
       " 89: 'sulphur-crested cockatoo, Kakatoe galerita, Cacatua galerita',\n",
       " 90: 'lorikeet',\n",
       " 91: 'coucal',\n",
       " 92: 'bee eater',\n",
       " 93: 'hornbill',\n",
       " 94: 'hummingbird',\n",
       " 95: 'jacamar',\n",
       " 96: 'toucan',\n",
       " 97: 'drake',\n",
       " 98: 'red-breasted merganser, Mergus serrator',\n",
       " 99: 'goose',\n",
       " 100: 'black swan, Cygnus atratus',\n",
       " 101: 'tusker',\n",
       " 102: 'echidna, spiny anteater, anteater',\n",
       " 103: 'platypus, duckbill, duckbilled platypus, duck-billed platypus, Ornithorhynchus anatinus',\n",
       " 104: 'wallaby, brush kangaroo',\n",
       " 105: 'koala, koala bear, kangaroo bear, native bear, Phascolarctos cinereus',\n",
       " 106: 'wombat',\n",
       " 107: 'jellyfish',\n",
       " 108: 'sea anemone, anemone',\n",
       " 109: 'brain coral',\n",
       " 110: 'flatworm, platyhelminth',\n",
       " 111: 'nematode, nematode worm, roundworm',\n",
       " 112: 'conch',\n",
       " 113: 'snail',\n",
       " 114: 'slug',\n",
       " 115: 'sea slug, nudibranch',\n",
       " 116: 'chiton, coat-of-mail shell, sea cradle, polyplacophore',\n",
       " 117: 'chambered nautilus, pearly nautilus, nautilus',\n",
       " 118: 'Dungeness crab, Cancer magister',\n",
       " 119: 'rock crab, Cancer irroratus',\n",
       " 120: 'fiddler crab',\n",
       " 121: 'king crab, Alaska crab, Alaskan king crab, Alaska king crab, Paralithodes camtschatica',\n",
       " 122: 'American lobster, Northern lobster, Maine lobster, Homarus americanus',\n",
       " 123: 'spiny lobster, langouste, rock lobster, crawfish, crayfish, sea crawfish',\n",
       " 124: 'crayfish, crawfish, crawdad, crawdaddy',\n",
       " 125: 'hermit crab',\n",
       " 126: 'isopod',\n",
       " 127: 'white stork, Ciconia ciconia',\n",
       " 128: 'black stork, Ciconia nigra',\n",
       " 129: 'spoonbill',\n",
       " 130: 'flamingo',\n",
       " 131: 'little blue heron, Egretta caerulea',\n",
       " 132: 'American egret, great white heron, Egretta albus',\n",
       " 133: 'bittern',\n",
       " 134: 'crane',\n",
       " 135: 'limpkin, Aramus pictus',\n",
       " 136: 'European gallinule, Porphyrio porphyrio',\n",
       " 137: 'American coot, marsh hen, mud hen, water hen, Fulica americana',\n",
       " 138: 'bustard',\n",
       " 139: 'ruddy turnstone, Arenaria interpres',\n",
       " 140: 'red-backed sandpiper, dunlin, Erolia alpina',\n",
       " 141: 'redshank, Tringa totanus',\n",
       " 142: 'dowitcher',\n",
       " 143: 'oystercatcher, oyster catcher',\n",
       " 144: 'pelican',\n",
       " 145: 'king penguin, Aptenodytes patagonica',\n",
       " 146: 'albatross, mollymawk',\n",
       " 147: 'grey whale, gray whale, devilfish, Eschrichtius gibbosus, Eschrichtius robustus',\n",
       " 148: 'killer whale, killer, orca, grampus, sea wolf, Orcinus orca',\n",
       " 149: 'dugong, Dugong dugon',\n",
       " 150: 'sea lion',\n",
       " 151: 'Chihuahua',\n",
       " 152: 'Japanese spaniel',\n",
       " 153: 'Maltese dog, Maltese terrier, Maltese',\n",
       " 154: 'Pekinese, Pekingese, Peke',\n",
       " 155: 'Shih-Tzu',\n",
       " 156: 'Blenheim spaniel',\n",
       " 157: 'papillon',\n",
       " 158: 'toy terrier',\n",
       " 159: 'Rhodesian ridgeback',\n",
       " 160: 'Afghan hound, Afghan',\n",
       " 161: 'basset, basset hound',\n",
       " 162: 'beagle',\n",
       " 163: 'bloodhound, sleuthhound',\n",
       " 164: 'bluetick',\n",
       " 165: 'black-and-tan coonhound',\n",
       " 166: 'Walker hound, Walker foxhound',\n",
       " 167: 'English foxhound',\n",
       " 168: 'redbone',\n",
       " 169: 'borzoi, Russian wolfhound',\n",
       " 170: 'Irish wolfhound',\n",
       " 171: 'Italian greyhound',\n",
       " 172: 'whippet',\n",
       " 173: 'Ibizan hound, Ibizan Podenco',\n",
       " 174: 'Norwegian elkhound, elkhound',\n",
       " 175: 'otterhound, otter hound',\n",
       " 176: 'Saluki, gazelle hound',\n",
       " 177: 'Scottish deerhound, deerhound',\n",
       " 178: 'Weimaraner',\n",
       " 179: 'Staffordshire bullterrier, Staffordshire bull terrier',\n",
       " 180: 'American Staffordshire terrier, Staffordshire terrier, American pit bull terrier, pit bull terrier',\n",
       " 181: 'Bedlington terrier',\n",
       " 182: 'Border terrier',\n",
       " 183: 'Kerry blue terrier',\n",
       " 184: 'Irish terrier',\n",
       " 185: 'Norfolk terrier',\n",
       " 186: 'Norwich terrier',\n",
       " 187: 'Yorkshire terrier',\n",
       " 188: 'wire-haired fox terrier',\n",
       " 189: 'Lakeland terrier',\n",
       " 190: 'Sealyham terrier, Sealyham',\n",
       " 191: 'Airedale, Airedale terrier',\n",
       " 192: 'cairn, cairn terrier',\n",
       " 193: 'Australian terrier',\n",
       " 194: 'Dandie Dinmont, Dandie Dinmont terrier',\n",
       " 195: 'Boston bull, Boston terrier',\n",
       " 196: 'miniature schnauzer',\n",
       " 197: 'giant schnauzer',\n",
       " 198: 'standard schnauzer',\n",
       " 199: 'Scotch terrier, Scottish terrier, Scottie',\n",
       " 200: 'Tibetan terrier, chrysanthemum dog',\n",
       " 201: 'silky terrier, Sydney silky',\n",
       " 202: 'soft-coated wheaten terrier',\n",
       " 203: 'West Highland white terrier',\n",
       " 204: 'Lhasa, Lhasa apso',\n",
       " 205: 'flat-coated retriever',\n",
       " 206: 'curly-coated retriever',\n",
       " 207: 'golden retriever',\n",
       " 208: 'Labrador retriever',\n",
       " 209: 'Chesapeake Bay retriever',\n",
       " 210: 'German short-haired pointer',\n",
       " 211: 'vizsla, Hungarian pointer',\n",
       " 212: 'English setter',\n",
       " 213: 'Irish setter, red setter',\n",
       " 214: 'Gordon setter',\n",
       " 215: 'Brittany spaniel',\n",
       " 216: 'clumber, clumber spaniel',\n",
       " 217: 'English springer, English springer spaniel',\n",
       " 218: 'Welsh springer spaniel',\n",
       " 219: 'cocker spaniel, English cocker spaniel, cocker',\n",
       " 220: 'Sussex spaniel',\n",
       " 221: 'Irish water spaniel',\n",
       " 222: 'kuvasz',\n",
       " 223: 'schipperke',\n",
       " 224: 'groenendael',\n",
       " 225: 'malinois',\n",
       " 226: 'briard',\n",
       " 227: 'kelpie',\n",
       " 228: 'komondor',\n",
       " 229: 'Old English sheepdog, bobtail',\n",
       " 230: 'Shetland sheepdog, Shetland sheep dog, Shetland',\n",
       " 231: 'collie',\n",
       " 232: 'Border collie',\n",
       " 233: 'Bouvier des Flandres, Bouviers des Flandres',\n",
       " 234: 'Rottweiler',\n",
       " 235: 'German shepherd, German shepherd dog, German police dog, alsatian',\n",
       " 236: 'Doberman, Doberman pinscher',\n",
       " 237: 'miniature pinscher',\n",
       " 238: 'Greater Swiss Mountain dog',\n",
       " 239: 'Bernese mountain dog',\n",
       " 240: 'Appenzeller',\n",
       " 241: 'EntleBucher',\n",
       " 242: 'boxer',\n",
       " 243: 'bull mastiff',\n",
       " 244: 'Tibetan mastiff',\n",
       " 245: 'French bulldog',\n",
       " 246: 'Great Dane',\n",
       " 247: 'Saint Bernard, St Bernard',\n",
       " 248: 'Eskimo dog, husky',\n",
       " 249: 'malamute, malemute, Alaskan malamute',\n",
       " 250: 'Siberian husky',\n",
       " 251: 'dalmatian, coach dog, carriage dog',\n",
       " 252: 'affenpinscher, monkey pinscher, monkey dog',\n",
       " 253: 'basenji',\n",
       " 254: 'pug, pug-dog',\n",
       " 255: 'Leonberg',\n",
       " 256: 'Newfoundland, Newfoundland dog',\n",
       " 257: 'Great Pyrenees',\n",
       " 258: 'Samoyed, Samoyede',\n",
       " 259: 'Pomeranian',\n",
       " 260: 'chow, chow chow',\n",
       " 261: 'keeshond',\n",
       " 262: 'Brabancon griffon',\n",
       " 263: 'Pembroke, Pembroke Welsh corgi',\n",
       " 264: 'Cardigan, Cardigan Welsh corgi',\n",
       " 265: 'toy poodle',\n",
       " 266: 'miniature poodle',\n",
       " 267: 'standard poodle',\n",
       " 268: 'Mexican hairless',\n",
       " 269: 'timber wolf, grey wolf, gray wolf, Canis lupus',\n",
       " 270: 'white wolf, Arctic wolf, Canis lupus tundrarum',\n",
       " 271: 'red wolf, maned wolf, Canis rufus, Canis niger',\n",
       " 272: 'coyote, prairie wolf, brush wolf, Canis latrans',\n",
       " 273: 'dingo, warrigal, warragal, Canis dingo',\n",
       " 274: 'dhole, Cuon alpinus',\n",
       " 275: 'African hunting dog, hyena dog, Cape hunting dog, Lycaon pictus',\n",
       " 276: 'hyena, hyaena',\n",
       " 277: 'red fox, Vulpes vulpes',\n",
       " 278: 'kit fox, Vulpes macrotis',\n",
       " 279: 'Arctic fox, white fox, Alopex lagopus',\n",
       " 280: 'grey fox, gray fox, Urocyon cinereoargenteus',\n",
       " 281: 'tabby, tabby cat',\n",
       " 282: 'tiger cat',\n",
       " 283: 'Persian cat',\n",
       " 284: 'Siamese cat, Siamese',\n",
       " 285: 'Egyptian cat',\n",
       " 286: 'cougar, puma, catamount, mountain lion, painter, panther, Felis concolor',\n",
       " 287: 'lynx, catamount',\n",
       " 288: 'leopard, Panthera pardus',\n",
       " 289: 'snow leopard, ounce, Panthera uncia',\n",
       " 290: 'jaguar, panther, Panthera onca, Felis onca',\n",
       " 291: 'lion, king of beasts, Panthera leo',\n",
       " 292: 'tiger, Panthera tigris',\n",
       " 293: 'cheetah, chetah, Acinonyx jubatus',\n",
       " 294: 'brown bear, bruin, Ursus arctos',\n",
       " 295: 'American black bear, black bear, Ursus americanus, Euarctos americanus',\n",
       " 296: 'ice bear, polar bear, Ursus Maritimus, Thalarctos maritimus',\n",
       " 297: 'sloth bear, Melursus ursinus, Ursus ursinus',\n",
       " 298: 'mongoose',\n",
       " 299: 'meerkat, mierkat',\n",
       " 300: 'tiger beetle',\n",
       " 301: 'ladybug, ladybeetle, lady beetle, ladybird, ladybird beetle',\n",
       " 302: 'ground beetle, carabid beetle',\n",
       " 303: 'long-horned beetle, longicorn, longicorn beetle',\n",
       " 304: 'leaf beetle, chrysomelid',\n",
       " 305: 'dung beetle',\n",
       " 306: 'rhinoceros beetle',\n",
       " 307: 'weevil',\n",
       " 308: 'fly',\n",
       " 309: 'bee',\n",
       " 310: 'ant, emmet, pismire',\n",
       " 311: 'grasshopper, hopper',\n",
       " 312: 'cricket',\n",
       " 313: 'walking stick, walkingstick, stick insect',\n",
       " 314: 'cockroach, roach',\n",
       " 315: 'mantis, mantid',\n",
       " 316: 'cicada, cicala',\n",
       " 317: 'leafhopper',\n",
       " 318: 'lacewing, lacewing fly',\n",
       " 319: \"dragonfly, darning needle, devil's darning needle, sewing needle, snake feeder, snake doctor, mosquito hawk, skeeter hawk\",\n",
       " 320: 'damselfly',\n",
       " 321: 'admiral',\n",
       " 322: 'ringlet, ringlet butterfly',\n",
       " 323: 'monarch, monarch butterfly, milkweed butterfly, Danaus plexippus',\n",
       " 324: 'cabbage butterfly',\n",
       " 325: 'sulphur butterfly, sulfur butterfly',\n",
       " 326: 'lycaenid, lycaenid butterfly',\n",
       " 327: 'starfish, sea star',\n",
       " 328: 'sea urchin',\n",
       " 329: 'sea cucumber, holothurian',\n",
       " 330: 'wood rabbit, cottontail, cottontail rabbit',\n",
       " 331: 'hare',\n",
       " 332: 'Angora, Angora rabbit',\n",
       " 333: 'hamster',\n",
       " 334: 'porcupine, hedgehog',\n",
       " 335: 'fox squirrel, eastern fox squirrel, Sciurus niger',\n",
       " 336: 'marmot',\n",
       " 337: 'beaver',\n",
       " 338: 'guinea pig, Cavia cobaya',\n",
       " 339: 'sorrel',\n",
       " 340: 'zebra',\n",
       " 341: 'hog, pig, grunter, squealer, Sus scrofa',\n",
       " 342: 'wild boar, boar, Sus scrofa',\n",
       " 343: 'warthog',\n",
       " 344: 'hippopotamus, hippo, river horse, Hippopotamus amphibius',\n",
       " 345: 'ox',\n",
       " 346: 'water buffalo, water ox, Asiatic buffalo, Bubalus bubalis',\n",
       " 347: 'bison',\n",
       " 348: 'ram, tup',\n",
       " 349: 'bighorn, bighorn sheep, cimarron, Rocky Mountain bighorn, Rocky Mountain sheep, Ovis canadensis',\n",
       " 350: 'ibex, Capra ibex',\n",
       " 351: 'hartebeest',\n",
       " 352: 'impala, Aepyceros melampus',\n",
       " 353: 'gazelle',\n",
       " 354: 'Arabian camel, dromedary, Camelus dromedarius',\n",
       " 355: 'llama',\n",
       " 356: 'weasel',\n",
       " 357: 'mink',\n",
       " 358: 'polecat, fitch, foulmart, foumart, Mustela putorius',\n",
       " 359: 'black-footed ferret, ferret, Mustela nigripes',\n",
       " 360: 'otter',\n",
       " 361: 'skunk, polecat, wood pussy',\n",
       " 362: 'badger',\n",
       " 363: 'armadillo',\n",
       " 364: 'three-toed sloth, ai, Bradypus tridactylus',\n",
       " 365: 'orangutan, orang, orangutang, Pongo pygmaeus',\n",
       " 366: 'gorilla, Gorilla gorilla',\n",
       " 367: 'chimpanzee, chimp, Pan troglodytes',\n",
       " 368: 'gibbon, Hylobates lar',\n",
       " 369: 'siamang, Hylobates syndactylus, Symphalangus syndactylus',\n",
       " 370: 'guenon, guenon monkey',\n",
       " 371: 'patas, hussar monkey, Erythrocebus patas',\n",
       " 372: 'baboon',\n",
       " 373: 'macaque',\n",
       " 374: 'langur',\n",
       " 375: 'colobus, colobus monkey',\n",
       " 376: 'proboscis monkey, Nasalis larvatus',\n",
       " 377: 'marmoset',\n",
       " 378: 'capuchin, ringtail, Cebus capucinus',\n",
       " 379: 'howler monkey, howler',\n",
       " 380: 'titi, titi monkey',\n",
       " 381: 'spider monkey, Ateles geoffroyi',\n",
       " 382: 'squirrel monkey, Saimiri sciureus',\n",
       " 383: 'Madagascar cat, ring-tailed lemur, Lemur catta',\n",
       " 384: 'indri, indris, Indri indri, Indri brevicaudatus',\n",
       " 385: 'Indian elephant, Elephas maximus',\n",
       " 386: 'African elephant, Loxodonta africana',\n",
       " 387: 'lesser panda, red panda, panda, bear cat, cat bear, Ailurus fulgens',\n",
       " 388: 'giant panda, panda, panda bear, coon bear, Ailuropoda melanoleuca',\n",
       " 389: 'barracouta, snoek',\n",
       " 390: 'eel',\n",
       " 391: 'coho, cohoe, coho salmon, blue jack, silver salmon, Oncorhynchus kisutch',\n",
       " 392: 'rock beauty, Holocanthus tricolor',\n",
       " 393: 'anemone fish',\n",
       " 394: 'sturgeon',\n",
       " 395: 'gar, garfish, garpike, billfish, Lepisosteus osseus',\n",
       " 396: 'lionfish',\n",
       " 397: 'puffer, pufferfish, blowfish, globefish',\n",
       " 398: 'abacus',\n",
       " 399: 'abaya',\n",
       " 400: \"academic gown, academic robe, judge's robe\",\n",
       " 401: 'accordion, piano accordion, squeeze box',\n",
       " 402: 'acoustic guitar',\n",
       " 403: 'aircraft carrier, carrier, flattop, attack aircraft carrier',\n",
       " 404: 'airliner',\n",
       " 405: 'airship, dirigible',\n",
       " 406: 'altar',\n",
       " 407: 'ambulance',\n",
       " 408: 'amphibian, amphibious vehicle',\n",
       " 409: 'analog clock',\n",
       " 410: 'apiary, bee house',\n",
       " 411: 'apron',\n",
       " 412: 'ashcan, trash can, garbage can, wastebin, ash bin, ash-bin, ashbin, dustbin, trash barrel, trash bin',\n",
       " 413: 'assault rifle, assault gun',\n",
       " 414: 'backpack, back pack, knapsack, packsack, rucksack, haversack',\n",
       " 415: 'bakery, bakeshop, bakehouse',\n",
       " 416: 'balance beam, beam',\n",
       " 417: 'balloon',\n",
       " 418: 'ballpoint, ballpoint pen, ballpen, Biro',\n",
       " 419: 'Band Aid',\n",
       " 420: 'banjo',\n",
       " 421: 'bannister, banister, balustrade, balusters, handrail',\n",
       " 422: 'barbell',\n",
       " 423: 'barber chair',\n",
       " 424: 'barbershop',\n",
       " 425: 'barn',\n",
       " 426: 'barometer',\n",
       " 427: 'barrel, cask',\n",
       " 428: 'barrow, garden cart, lawn cart, wheelbarrow',\n",
       " 429: 'baseball',\n",
       " 430: 'basketball',\n",
       " 431: 'bassinet',\n",
       " 432: 'bassoon',\n",
       " 433: 'bathing cap, swimming cap',\n",
       " 434: 'bath towel',\n",
       " 435: 'bathtub, bathing tub, bath, tub',\n",
       " 436: 'beach wagon, station wagon, wagon, estate car, beach waggon, station waggon, waggon',\n",
       " 437: 'beacon, lighthouse, beacon light, pharos',\n",
       " 438: 'beaker',\n",
       " 439: 'bearskin, busby, shako',\n",
       " 440: 'beer bottle',\n",
       " 441: 'beer glass',\n",
       " 442: 'bell cote, bell cot',\n",
       " 443: 'bib',\n",
       " 444: 'bicycle-built-for-two, tandem bicycle, tandem',\n",
       " 445: 'bikini, two-piece',\n",
       " 446: 'binder, ring-binder',\n",
       " 447: 'binoculars, field glasses, opera glasses',\n",
       " 448: 'birdhouse',\n",
       " 449: 'boathouse',\n",
       " 450: 'bobsled, bobsleigh, bob',\n",
       " 451: 'bolo tie, bolo, bola tie, bola',\n",
       " 452: 'bonnet, poke bonnet',\n",
       " 453: 'bookcase',\n",
       " 454: 'bookshop, bookstore, bookstall',\n",
       " 455: 'bottlecap',\n",
       " 456: 'bow',\n",
       " 457: 'bow tie, bow-tie, bowtie',\n",
       " 458: 'brass, memorial tablet, plaque',\n",
       " 459: 'brassiere, bra, bandeau',\n",
       " 460: 'breakwater, groin, groyne, mole, bulwark, seawall, jetty',\n",
       " 461: 'breastplate, aegis, egis',\n",
       " 462: 'broom',\n",
       " 463: 'bucket, pail',\n",
       " 464: 'buckle',\n",
       " 465: 'bulletproof vest',\n",
       " 466: 'bullet train, bullet',\n",
       " 467: 'butcher shop, meat market',\n",
       " 468: 'cab, hack, taxi, taxicab',\n",
       " 469: 'caldron, cauldron',\n",
       " 470: 'candle, taper, wax light',\n",
       " 471: 'cannon',\n",
       " 472: 'canoe',\n",
       " 473: 'can opener, tin opener',\n",
       " 474: 'cardigan',\n",
       " 475: 'car mirror',\n",
       " 476: 'carousel, carrousel, merry-go-round, roundabout, whirligig',\n",
       " 477: \"carpenter's kit, tool kit\",\n",
       " 478: 'carton',\n",
       " 479: 'car wheel',\n",
       " 480: 'cash machine, cash dispenser, automated teller machine, automatic teller machine, automated teller, automatic teller, ATM',\n",
       " 481: 'cassette',\n",
       " 482: 'cassette player',\n",
       " 483: 'castle',\n",
       " 484: 'catamaran',\n",
       " 485: 'CD player',\n",
       " 486: 'cello, violoncello',\n",
       " 487: 'cellular telephone, cellular phone, cellphone, cell, mobile phone',\n",
       " 488: 'chain',\n",
       " 489: 'chainlink fence',\n",
       " 490: 'chain mail, ring mail, mail, chain armor, chain armour, ring armor, ring armour',\n",
       " 491: 'chain saw, chainsaw',\n",
       " 492: 'chest',\n",
       " 493: 'chiffonier, commode',\n",
       " 494: 'chime, bell, gong',\n",
       " 495: 'china cabinet, china closet',\n",
       " 496: 'Christmas stocking',\n",
       " 497: 'church, church building',\n",
       " 498: 'cinema, movie theater, movie theatre, movie house, picture palace',\n",
       " 499: 'cleaver, meat cleaver, chopper',\n",
       " 500: 'cliff dwelling',\n",
       " 501: 'cloak',\n",
       " 502: 'clog, geta, patten, sabot',\n",
       " 503: 'cocktail shaker',\n",
       " 504: 'coffee mug',\n",
       " 505: 'coffeepot',\n",
       " 506: 'coil, spiral, volute, whorl, helix',\n",
       " 507: 'combination lock',\n",
       " 508: 'computer keyboard, keypad',\n",
       " 509: 'confectionery, confectionary, candy store',\n",
       " 510: 'container ship, containership, container vessel',\n",
       " 511: 'convertible',\n",
       " 512: 'corkscrew, bottle screw',\n",
       " 513: 'cornet, horn, trumpet, trump',\n",
       " 514: 'cowboy boot',\n",
       " 515: 'cowboy hat, ten-gallon hat',\n",
       " 516: 'cradle',\n",
       " 517: 'crane',\n",
       " 518: 'crash helmet',\n",
       " 519: 'crate',\n",
       " 520: 'crib, cot',\n",
       " 521: 'Crock Pot',\n",
       " 522: 'croquet ball',\n",
       " 523: 'crutch',\n",
       " 524: 'cuirass',\n",
       " 525: 'dam, dike, dyke',\n",
       " 526: 'desk',\n",
       " 527: 'desktop computer',\n",
       " 528: 'dial telephone, dial phone',\n",
       " 529: 'diaper, nappy, napkin',\n",
       " 530: 'digital clock',\n",
       " 531: 'digital watch',\n",
       " 532: 'dining table, board',\n",
       " 533: 'dishrag, dishcloth',\n",
       " 534: 'dishwasher, dish washer, dishwashing machine',\n",
       " 535: 'disk brake, disc brake',\n",
       " 536: 'dock, dockage, docking facility',\n",
       " 537: 'dogsled, dog sled, dog sleigh',\n",
       " 538: 'dome',\n",
       " 539: 'doormat, welcome mat',\n",
       " 540: 'drilling platform, offshore rig',\n",
       " 541: 'drum, membranophone, tympan',\n",
       " 542: 'drumstick',\n",
       " 543: 'dumbbell',\n",
       " 544: 'Dutch oven',\n",
       " 545: 'electric fan, blower',\n",
       " 546: 'electric guitar',\n",
       " 547: 'electric locomotive',\n",
       " 548: 'entertainment center',\n",
       " 549: 'envelope',\n",
       " 550: 'espresso maker',\n",
       " 551: 'face powder',\n",
       " 552: 'feather boa, boa',\n",
       " 553: 'file, file cabinet, filing cabinet',\n",
       " 554: 'fireboat',\n",
       " 555: 'fire engine, fire truck',\n",
       " 556: 'fire screen, fireguard',\n",
       " 557: 'flagpole, flagstaff',\n",
       " 558: 'flute, transverse flute',\n",
       " 559: 'folding chair',\n",
       " 560: 'football helmet',\n",
       " 561: 'forklift',\n",
       " 562: 'fountain',\n",
       " 563: 'fountain pen',\n",
       " 564: 'four-poster',\n",
       " 565: 'freight car',\n",
       " 566: 'French horn, horn',\n",
       " 567: 'frying pan, frypan, skillet',\n",
       " 568: 'fur coat',\n",
       " 569: 'garbage truck, dustcart',\n",
       " 570: 'gasmask, respirator, gas helmet',\n",
       " 571: 'gas pump, gasoline pump, petrol pump, island dispenser',\n",
       " 572: 'goblet',\n",
       " 573: 'go-kart',\n",
       " 574: 'golf ball',\n",
       " 575: 'golfcart, golf cart',\n",
       " 576: 'gondola',\n",
       " 577: 'gong, tam-tam',\n",
       " 578: 'gown',\n",
       " 579: 'grand piano, grand',\n",
       " 580: 'greenhouse, nursery, glasshouse',\n",
       " 581: 'grille, radiator grille',\n",
       " 582: 'grocery store, grocery, food market, market',\n",
       " 583: 'guillotine',\n",
       " 584: 'hair slide',\n",
       " 585: 'hair spray',\n",
       " 586: 'half track',\n",
       " 587: 'hammer',\n",
       " 588: 'hamper',\n",
       " 589: 'hand blower, blow dryer, blow drier, hair dryer, hair drier',\n",
       " 590: 'hand-held computer, hand-held microcomputer',\n",
       " 591: 'handkerchief, hankie, hanky, hankey',\n",
       " 592: 'hard disc, hard disk, fixed disk',\n",
       " 593: 'harmonica, mouth organ, harp, mouth harp',\n",
       " 594: 'harp',\n",
       " 595: 'harvester, reaper',\n",
       " 596: 'hatchet',\n",
       " 597: 'holster',\n",
       " 598: 'home theater, home theatre',\n",
       " 599: 'honeycomb',\n",
       " 600: 'hook, claw',\n",
       " 601: 'hoopskirt, crinoline',\n",
       " 602: 'horizontal bar, high bar',\n",
       " 603: 'horse cart, horse-cart',\n",
       " 604: 'hourglass',\n",
       " 605: 'iPod',\n",
       " 606: 'iron, smoothing iron',\n",
       " 607: \"jack-o'-lantern\",\n",
       " 608: 'jean, blue jean, denim',\n",
       " 609: 'jeep, landrover',\n",
       " 610: 'jersey, T-shirt, tee shirt',\n",
       " 611: 'jigsaw puzzle',\n",
       " 612: 'jinrikisha, ricksha, rickshaw',\n",
       " 613: 'joystick',\n",
       " 614: 'kimono',\n",
       " 615: 'knee pad',\n",
       " 616: 'knot',\n",
       " 617: 'lab coat, laboratory coat',\n",
       " 618: 'ladle',\n",
       " 619: 'lampshade, lamp shade',\n",
       " 620: 'laptop, laptop computer',\n",
       " 621: 'lawn mower, mower',\n",
       " 622: 'lens cap, lens cover',\n",
       " 623: 'letter opener, paper knife, paperknife',\n",
       " 624: 'library',\n",
       " 625: 'lifeboat',\n",
       " 626: 'lighter, light, igniter, ignitor',\n",
       " 627: 'limousine, limo',\n",
       " 628: 'liner, ocean liner',\n",
       " 629: 'lipstick, lip rouge',\n",
       " 630: 'Loafer',\n",
       " 631: 'lotion',\n",
       " 632: 'loudspeaker, speaker, speaker unit, loudspeaker system, speaker system',\n",
       " 633: \"loupe, jeweler's loupe\",\n",
       " 634: 'lumbermill, sawmill',\n",
       " 635: 'magnetic compass',\n",
       " 636: 'mailbag, postbag',\n",
       " 637: 'mailbox, letter box',\n",
       " 638: 'maillot',\n",
       " 639: 'maillot, tank suit',\n",
       " 640: 'manhole cover',\n",
       " 641: 'maraca',\n",
       " 642: 'marimba, xylophone',\n",
       " 643: 'mask',\n",
       " 644: 'matchstick',\n",
       " 645: 'maypole',\n",
       " 646: 'maze, labyrinth',\n",
       " 647: 'measuring cup',\n",
       " 648: 'medicine chest, medicine cabinet',\n",
       " 649: 'megalith, megalithic structure',\n",
       " 650: 'microphone, mike',\n",
       " 651: 'microwave, microwave oven',\n",
       " 652: 'military uniform',\n",
       " 653: 'milk can',\n",
       " 654: 'minibus',\n",
       " 655: 'miniskirt, mini',\n",
       " 656: 'minivan',\n",
       " 657: 'missile',\n",
       " 658: 'mitten',\n",
       " 659: 'mixing bowl',\n",
       " 660: 'mobile home, manufactured home',\n",
       " 661: 'Model T',\n",
       " 662: 'modem',\n",
       " 663: 'monastery',\n",
       " 664: 'monitor',\n",
       " 665: 'moped',\n",
       " 666: 'mortar',\n",
       " 667: 'mortarboard',\n",
       " 668: 'mosque',\n",
       " 669: 'mosquito net',\n",
       " 670: 'motor scooter, scooter',\n",
       " 671: 'mountain bike, all-terrain bike, off-roader',\n",
       " 672: 'mountain tent',\n",
       " 673: 'mouse, computer mouse',\n",
       " 674: 'mousetrap',\n",
       " 675: 'moving van',\n",
       " 676: 'muzzle',\n",
       " 677: 'nail',\n",
       " 678: 'neck brace',\n",
       " 679: 'necklace',\n",
       " 680: 'nipple',\n",
       " 681: 'notebook, notebook computer',\n",
       " 682: 'obelisk',\n",
       " 683: 'oboe, hautboy, hautbois',\n",
       " 684: 'ocarina, sweet potato',\n",
       " 685: 'odometer, hodometer, mileometer, milometer',\n",
       " 686: 'oil filter',\n",
       " 687: 'organ, pipe organ',\n",
       " 688: 'oscilloscope, scope, cathode-ray oscilloscope, CRO',\n",
       " 689: 'overskirt',\n",
       " 690: 'oxcart',\n",
       " 691: 'oxygen mask',\n",
       " 692: 'packet',\n",
       " 693: 'paddle, boat paddle',\n",
       " 694: 'paddlewheel, paddle wheel',\n",
       " 695: 'padlock',\n",
       " 696: 'paintbrush',\n",
       " 697: \"pajama, pyjama, pj's, jammies\",\n",
       " 698: 'palace',\n",
       " 699: 'panpipe, pandean pipe, syrinx',\n",
       " 700: 'paper towel',\n",
       " 701: 'parachute, chute',\n",
       " 702: 'parallel bars, bars',\n",
       " 703: 'park bench',\n",
       " 704: 'parking meter',\n",
       " 705: 'passenger car, coach, carriage',\n",
       " 706: 'patio, terrace',\n",
       " 707: 'pay-phone, pay-station',\n",
       " 708: 'pedestal, plinth, footstall',\n",
       " 709: 'pencil box, pencil case',\n",
       " 710: 'pencil sharpener',\n",
       " 711: 'perfume, essence',\n",
       " 712: 'Petri dish',\n",
       " 713: 'photocopier',\n",
       " 714: 'pick, plectrum, plectron',\n",
       " 715: 'pickelhaube',\n",
       " 716: 'picket fence, paling',\n",
       " 717: 'pickup, pickup truck',\n",
       " 718: 'pier',\n",
       " 719: 'piggy bank, penny bank',\n",
       " 720: 'pill bottle',\n",
       " 721: 'pillow',\n",
       " 722: 'ping-pong ball',\n",
       " 723: 'pinwheel',\n",
       " 724: 'pirate, pirate ship',\n",
       " 725: 'pitcher, ewer',\n",
       " 726: \"plane, carpenter's plane, woodworking plane\",\n",
       " 727: 'planetarium',\n",
       " 728: 'plastic bag',\n",
       " 729: 'plate rack',\n",
       " 730: 'plow, plough',\n",
       " 731: \"plunger, plumber's helper\",\n",
       " 732: 'Polaroid camera, Polaroid Land camera',\n",
       " 733: 'pole',\n",
       " 734: 'police van, police wagon, paddy wagon, patrol wagon, wagon, black Maria',\n",
       " 735: 'poncho',\n",
       " 736: 'pool table, billiard table, snooker table',\n",
       " 737: 'pop bottle, soda bottle',\n",
       " 738: 'pot, flowerpot',\n",
       " 739: \"potter's wheel\",\n",
       " 740: 'power drill',\n",
       " 741: 'prayer rug, prayer mat',\n",
       " 742: 'printer',\n",
       " 743: 'prison, prison house',\n",
       " 744: 'projectile, missile',\n",
       " 745: 'projector',\n",
       " 746: 'puck, hockey puck',\n",
       " 747: 'punching bag, punch bag, punching ball, punchball',\n",
       " 748: 'purse',\n",
       " 749: 'quill, quill pen',\n",
       " 750: 'quilt, comforter, comfort, puff',\n",
       " 751: 'racer, race car, racing car',\n",
       " 752: 'racket, racquet',\n",
       " 753: 'radiator',\n",
       " 754: 'radio, wireless',\n",
       " 755: 'radio telescope, radio reflector',\n",
       " 756: 'rain barrel',\n",
       " 757: 'recreational vehicle, RV, R.V.',\n",
       " 758: 'reel',\n",
       " 759: 'reflex camera',\n",
       " 760: 'refrigerator, icebox',\n",
       " 761: 'remote control, remote',\n",
       " 762: 'restaurant, eating house, eating place, eatery',\n",
       " 763: 'revolver, six-gun, six-shooter',\n",
       " 764: 'rifle',\n",
       " 765: 'rocking chair, rocker',\n",
       " 766: 'rotisserie',\n",
       " 767: 'rubber eraser, rubber, pencil eraser',\n",
       " 768: 'rugby ball',\n",
       " 769: 'rule, ruler',\n",
       " 770: 'running shoe',\n",
       " 771: 'safe',\n",
       " 772: 'safety pin',\n",
       " 773: 'saltshaker, salt shaker',\n",
       " 774: 'sandal',\n",
       " 775: 'sarong',\n",
       " 776: 'sax, saxophone',\n",
       " 777: 'scabbard',\n",
       " 778: 'scale, weighing machine',\n",
       " 779: 'school bus',\n",
       " 780: 'schooner',\n",
       " 781: 'scoreboard',\n",
       " 782: 'screen, CRT screen',\n",
       " 783: 'screw',\n",
       " 784: 'screwdriver',\n",
       " 785: 'seat belt, seatbelt',\n",
       " 786: 'sewing machine',\n",
       " 787: 'shield, buckler',\n",
       " 788: 'shoe shop, shoe-shop, shoe store',\n",
       " 789: 'shoji',\n",
       " 790: 'shopping basket',\n",
       " 791: 'shopping cart',\n",
       " 792: 'shovel',\n",
       " 793: 'shower cap',\n",
       " 794: 'shower curtain',\n",
       " 795: 'ski',\n",
       " 796: 'ski mask',\n",
       " 797: 'sleeping bag',\n",
       " 798: 'slide rule, slipstick',\n",
       " 799: 'sliding door',\n",
       " 800: 'slot, one-armed bandit',\n",
       " 801: 'snorkel',\n",
       " 802: 'snowmobile',\n",
       " 803: 'snowplow, snowplough',\n",
       " 804: 'soap dispenser',\n",
       " 805: 'soccer ball',\n",
       " 806: 'sock',\n",
       " 807: 'solar dish, solar collector, solar furnace',\n",
       " 808: 'sombrero',\n",
       " 809: 'soup bowl',\n",
       " 810: 'space bar',\n",
       " 811: 'space heater',\n",
       " 812: 'space shuttle',\n",
       " 813: 'spatula',\n",
       " 814: 'speedboat',\n",
       " 815: \"spider web, spider's web\",\n",
       " 816: 'spindle',\n",
       " 817: 'sports car, sport car',\n",
       " 818: 'spotlight, spot',\n",
       " 819: 'stage',\n",
       " 820: 'steam locomotive',\n",
       " 821: 'steel arch bridge',\n",
       " 822: 'steel drum',\n",
       " 823: 'stethoscope',\n",
       " 824: 'stole',\n",
       " 825: 'stone wall',\n",
       " 826: 'stopwatch, stop watch',\n",
       " 827: 'stove',\n",
       " 828: 'strainer',\n",
       " 829: 'streetcar, tram, tramcar, trolley, trolley car',\n",
       " 830: 'stretcher',\n",
       " 831: 'studio couch, day bed',\n",
       " 832: 'stupa, tope',\n",
       " 833: 'submarine, pigboat, sub, U-boat',\n",
       " 834: 'suit, suit of clothes',\n",
       " 835: 'sundial',\n",
       " 836: 'sunglass',\n",
       " 837: 'sunglasses, dark glasses, shades',\n",
       " 838: 'sunscreen, sunblock, sun blocker',\n",
       " 839: 'suspension bridge',\n",
       " 840: 'swab, swob, mop',\n",
       " 841: 'sweatshirt',\n",
       " 842: 'swimming trunks, bathing trunks',\n",
       " 843: 'swing',\n",
       " 844: 'switch, electric switch, electrical switch',\n",
       " 845: 'syringe',\n",
       " 846: 'table lamp',\n",
       " 847: 'tank, army tank, armored combat vehicle, armoured combat vehicle',\n",
       " 848: 'tape player',\n",
       " 849: 'teapot',\n",
       " 850: 'teddy, teddy bear',\n",
       " 851: 'television, television system',\n",
       " 852: 'tennis ball',\n",
       " 853: 'thatch, thatched roof',\n",
       " 854: 'theater curtain, theatre curtain',\n",
       " 855: 'thimble',\n",
       " 856: 'thresher, thrasher, threshing machine',\n",
       " 857: 'throne',\n",
       " 858: 'tile roof',\n",
       " 859: 'toaster',\n",
       " 860: 'tobacco shop, tobacconist shop, tobacconist',\n",
       " 861: 'toilet seat',\n",
       " 862: 'torch',\n",
       " 863: 'totem pole',\n",
       " 864: 'tow truck, tow car, wrecker',\n",
       " 865: 'toyshop',\n",
       " 866: 'tractor',\n",
       " 867: 'trailer truck, tractor trailer, trucking rig, rig, articulated lorry, semi',\n",
       " 868: 'tray',\n",
       " 869: 'trench coat',\n",
       " 870: 'tricycle, trike, velocipede',\n",
       " 871: 'trimaran',\n",
       " 872: 'tripod',\n",
       " 873: 'triumphal arch',\n",
       " 874: 'trolleybus, trolley coach, trackless trolley',\n",
       " 875: 'trombone',\n",
       " 876: 'tub, vat',\n",
       " 877: 'turnstile',\n",
       " 878: 'typewriter keyboard',\n",
       " 879: 'umbrella',\n",
       " 880: 'unicycle, monocycle',\n",
       " 881: 'upright, upright piano',\n",
       " 882: 'vacuum, vacuum cleaner',\n",
       " 883: 'vase',\n",
       " 884: 'vault',\n",
       " 885: 'velvet',\n",
       " 886: 'vending machine',\n",
       " 887: 'vestment',\n",
       " 888: 'viaduct',\n",
       " 889: 'violin, fiddle',\n",
       " 890: 'volleyball',\n",
       " 891: 'waffle iron',\n",
       " 892: 'wall clock',\n",
       " 893: 'wallet, billfold, notecase, pocketbook',\n",
       " 894: 'wardrobe, closet, press',\n",
       " 895: 'warplane, military plane',\n",
       " 896: 'washbasin, handbasin, washbowl, lavabo, wash-hand basin',\n",
       " 897: 'washer, automatic washer, washing machine',\n",
       " 898: 'water bottle',\n",
       " 899: 'water jug',\n",
       " 900: 'water tower',\n",
       " 901: 'whiskey jug',\n",
       " 902: 'whistle',\n",
       " 903: 'wig',\n",
       " 904: 'window screen',\n",
       " 905: 'window shade',\n",
       " 906: 'Windsor tie',\n",
       " 907: 'wine bottle',\n",
       " 908: 'wing',\n",
       " 909: 'wok',\n",
       " 910: 'wooden spoon',\n",
       " 911: 'wool, woolen, woollen',\n",
       " 912: 'worm fence, snake fence, snake-rail fence, Virginia fence',\n",
       " 913: 'wreck',\n",
       " 914: 'yawl',\n",
       " 915: 'yurt',\n",
       " 916: 'web site, website, internet site, site',\n",
       " 917: 'comic book',\n",
       " 918: 'crossword puzzle, crossword',\n",
       " 919: 'street sign',\n",
       " 920: 'traffic light, traffic signal, stoplight',\n",
       " 921: 'book jacket, dust cover, dust jacket, dust wrapper',\n",
       " 922: 'menu',\n",
       " 923: 'plate',\n",
       " 924: 'guacamole',\n",
       " 925: 'consomme',\n",
       " 926: 'hot pot, hotpot',\n",
       " 927: 'trifle',\n",
       " 928: 'ice cream, icecream',\n",
       " 929: 'ice lolly, lolly, lollipop, popsicle',\n",
       " 930: 'French loaf',\n",
       " 931: 'bagel, beigel',\n",
       " 932: 'pretzel',\n",
       " 933: 'cheeseburger',\n",
       " 934: 'hotdog, hot dog, red hot',\n",
       " 935: 'mashed potato',\n",
       " 936: 'head cabbage',\n",
       " 937: 'broccoli',\n",
       " 938: 'cauliflower',\n",
       " 939: 'zucchini, courgette',\n",
       " 940: 'spaghetti squash',\n",
       " 941: 'acorn squash',\n",
       " 942: 'butternut squash',\n",
       " 943: 'cucumber, cuke',\n",
       " 944: 'artichoke, globe artichoke',\n",
       " 945: 'bell pepper',\n",
       " 946: 'cardoon',\n",
       " 947: 'mushroom',\n",
       " 948: 'Granny Smith',\n",
       " 949: 'strawberry',\n",
       " 950: 'orange',\n",
       " 951: 'lemon',\n",
       " 952: 'fig',\n",
       " 953: 'pineapple, ananas',\n",
       " 954: 'banana',\n",
       " 955: 'jackfruit, jak, jack',\n",
       " 956: 'custard apple',\n",
       " 957: 'pomegranate',\n",
       " 958: 'hay',\n",
       " 959: 'carbonara',\n",
       " 960: 'chocolate sauce, chocolate syrup',\n",
       " 961: 'dough',\n",
       " 962: 'meat loaf, meatloaf',\n",
       " 963: 'pizza, pizza pie',\n",
       " 964: 'potpie',\n",
       " 965: 'burrito',\n",
       " 966: 'red wine',\n",
       " 967: 'espresso',\n",
       " 968: 'cup',\n",
       " 969: 'eggnog',\n",
       " 970: 'alp',\n",
       " 971: 'bubble',\n",
       " 972: 'cliff, drop, drop-off',\n",
       " 973: 'coral reef',\n",
       " 974: 'geyser',\n",
       " 975: 'lakeside, lakeshore',\n",
       " 976: 'promontory, headland, head, foreland',\n",
       " 977: 'sandbar, sand bar',\n",
       " 978: 'seashore, coast, seacoast, sea-coast',\n",
       " 979: 'valley, vale',\n",
       " 980: 'volcano',\n",
       " 981: 'ballplayer, baseball player',\n",
       " 982: 'groom, bridegroom',\n",
       " 983: 'scuba diver',\n",
       " 984: 'rapeseed',\n",
       " 985: 'daisy',\n",
       " 986: \"yellow lady's slipper, yellow lady-slipper, Cypripedium calceolus, Cypripedium parviflorum\",\n",
       " 987: 'corn',\n",
       " 988: 'acorn',\n",
       " 989: 'hip, rose hip, rosehip',\n",
       " 990: 'buckeye, horse chestnut, conker',\n",
       " 991: 'coral fungus',\n",
       " 992: 'agaric',\n",
       " 993: 'gyromitra',\n",
       " 994: 'stinkhorn, carrion fungus',\n",
       " 995: 'earthstar',\n",
       " 996: 'hen-of-the-woods, hen of the woods, Polyporus frondosus, Grifola frondosa',\n",
       " 997: 'bolete',\n",
       " 998: 'ear, spike, capitulum',\n",
       " 999: 'toilet tissue, toilet paper, bathroom tissue'}"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "LABELS_URL = 'https://s3.amazonaws.com/outcome-blog/imagenet/labels.json'\n",
    "response = requests.get(LABELS_URL)  # Make an HTTP GET request and store the response.\n",
    "labels = {int(key): value for key, value in response.json().items()}\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.datasets as datasets\n",
    "\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Set PIL to be tolerant of image files that are truncated.\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "def VGG16_predict(img_path):\n",
    "    '''\n",
    "    Use pre-trained VGG-16 model to obtain index corresponding to \n",
    "    predicted ImageNet class for image at specified path\n",
    "    \n",
    "    Args:\n",
    "        img_path: path to an image\n",
    "        \n",
    "    Returns:\n",
    "        Index corresponding to VGG-16 model's prediction\n",
    "    '''\n",
    "    \n",
    "    ## Load and pre-process an image from the given img_path\n",
    "    ## Return the *index* of the predicted class for that image\n",
    "    img = Image.open(img_path)\n",
    "    normalize = transforms.Compose([transforms.Resize((224,224)),\n",
    "                                    transforms.ToTensor(),\n",
    "                                    transforms.Normalize(mean=[0.5, 0.5, 0.5],\n",
    "                                                         std=[0.5, 0.5, 0.5])])\n",
    "    img = normalize(img)\n",
    "    img = img.cuda()\n",
    "    prediction = VGG16(img.unsqueeze(dim=0))\n",
    "    prediction_index_tensor = torch.max(prediction.data, dim=1)[1]\n",
    "    prediction_index = prediction_index_tensor.cpu().numpy()[0]\n",
    "\n",
    "    return prediction_index # predicted class index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "st\\001.Affenpinscher\\Affenpinscher : 252 : affenpinscher, monkey pinscher, monkey dog\n",
      "st\\001.Affenpinscher\\Affenpinscher : 252 : affenpinscher, monkey pinscher, monkey dog\n",
      "st\\001.Affenpinscher\\Affenpinscher : 192 : cairn, cairn terrier\n",
      "st\\001.Affenpinscher\\Affenpinscher : 204 : Lhasa, Lhasa apso\n",
      "st\\001.Affenpinscher\\Affenpinscher : 200 : Tibetan terrier, chrysanthemum dog\n",
      "st\\001.Affenpinscher\\Affenpinscher : 204 : Lhasa, Lhasa apso\n",
      "st\\001.Affenpinscher\\Affenpinscher : 252 : affenpinscher, monkey pinscher, monkey dog\n",
      "st\\001.Affenpinscher\\Affenpinscher : 192 : cairn, cairn terrier\n",
      "test\\002.Afghan_hound\\Afghan_hound : 160 : Afghan hound, Afghan\n",
      "test\\002.Afghan_hound\\Afghan_hound : 160 : Afghan hound, Afghan\n",
      "test\\002.Afghan_hound\\Afghan_hound : 160 : Afghan hound, Afghan\n",
      "test\\002.Afghan_hound\\Afghan_hound : 219 : cocker spaniel, English cocker spaniel, cocker\n",
      "test\\002.Afghan_hound\\Afghan_hound : 160 : Afghan hound, Afghan\n",
      "test\\002.Afghan_hound\\Afghan_hound : 160 : English setter\n",
      "test\\002.Afghan_hound\\Afghan_hound : 160 : Afghan hound, Afghan\n",
      "test\\002.Afghan_hound\\Afghan_hound : 160 : Afghan hound, Afghan\n",
      ".Airedale_terrier\\Airedale_terrier : 189 : Lakeland terrier\n",
      ".Airedale_terrier\\Airedale_terrier : 191 : Airedale, Airedale terrier\n",
      ".Airedale_terrier\\Airedale_terrier : 191 : Lakeland terrier\n",
      ".Airedale_terrier\\Airedale_terrier : 191 : Airedale, Airedale terrier\n"
     ]
    }
   ],
   "source": [
    "def test_VGG16_predict(img_paths, testrange = 20):\n",
    "    for i in range(testrange):\n",
    "        print(img_paths[i][-44:-10], \":\", VGG16_predict(img_paths[i]), \":\", labels[VGG16_predict(img_paths[i])])\n",
    "\n",
    "test_VGG16_predict(dog_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151 : Chihuahua\n",
      "152 : Japanese spaniel\n",
      "153 : Maltese dog, Maltese terrier, Maltese\n",
      "154 : Pekinese, Pekingese, Peke\n",
      "155 : Shih-Tzu\n",
      "156 : Blenheim spaniel\n",
      "157 : papillon\n",
      "158 : toy terrier\n",
      "159 : Rhodesian ridgeback\n",
      "160 : Afghan hound, Afghan\n",
      "161 : basset, basset hound\n",
      "162 : beagle\n",
      "163 : bloodhound, sleuthhound\n",
      "164 : bluetick\n",
      "165 : black-and-tan coonhound\n",
      "166 : Walker hound, Walker foxhound\n",
      "167 : English foxhound\n",
      "168 : redbone\n",
      "169 : borzoi, Russian wolfhound\n",
      "170 : Irish wolfhound\n",
      "171 : Italian greyhound\n",
      "172 : whippet\n",
      "173 : Ibizan hound, Ibizan Podenco\n",
      "174 : Norwegian elkhound, elkhound\n",
      "175 : otterhound, otter hound\n",
      "176 : Saluki, gazelle hound\n",
      "177 : Scottish deerhound, deerhound\n",
      "178 : Weimaraner\n",
      "179 : Staffordshire bullterrier, Staffordshire bull terrier\n",
      "180 : American Staffordshire terrier, Staffordshire terrier, American pit bull terrier, pit bull terrier\n",
      "181 : Bedlington terrier\n",
      "182 : Border terrier\n",
      "183 : Kerry blue terrier\n",
      "184 : Irish terrier\n",
      "185 : Norfolk terrier\n",
      "186 : Norwich terrier\n",
      "187 : Yorkshire terrier\n",
      "188 : wire-haired fox terrier\n",
      "189 : Lakeland terrier\n",
      "190 : Sealyham terrier, Sealyham\n",
      "191 : Airedale, Airedale terrier\n",
      "192 : cairn, cairn terrier\n",
      "193 : Australian terrier\n",
      "194 : Dandie Dinmont, Dandie Dinmont terrier\n",
      "195 : Boston bull, Boston terrier\n",
      "196 : miniature schnauzer\n",
      "197 : giant schnauzer\n",
      "198 : standard schnauzer\n",
      "199 : Scotch terrier, Scottish terrier, Scottie\n",
      "200 : Tibetan terrier, chrysanthemum dog\n",
      "201 : silky terrier, Sydney silky\n",
      "202 : soft-coated wheaten terrier\n",
      "203 : West Highland white terrier\n",
      "204 : Lhasa, Lhasa apso\n",
      "205 : flat-coated retriever\n",
      "206 : curly-coated retriever\n",
      "207 : golden retriever\n",
      "208 : Labrador retriever\n",
      "209 : Chesapeake Bay retriever\n",
      "210 : German short-haired pointer\n",
      "211 : vizsla, Hungarian pointer\n",
      "212 : English setter\n",
      "213 : Irish setter, red setter\n",
      "214 : Gordon setter\n",
      "215 : Brittany spaniel\n",
      "216 : clumber, clumber spaniel\n",
      "217 : English springer, English springer spaniel\n",
      "218 : Welsh springer spaniel\n",
      "219 : cocker spaniel, English cocker spaniel, cocker\n",
      "220 : Sussex spaniel\n",
      "221 : Irish water spaniel\n",
      "222 : kuvasz\n",
      "223 : schipperke\n",
      "224 : groenendael\n",
      "225 : malinois\n",
      "226 : briard\n",
      "227 : kelpie\n",
      "228 : komondor\n",
      "229 : Old English sheepdog, bobtail\n",
      "230 : Shetland sheepdog, Shetland sheep dog, Shetland\n",
      "231 : collie\n",
      "232 : Border collie\n",
      "233 : Bouvier des Flandres, Bouviers des Flandres\n",
      "234 : Rottweiler\n",
      "235 : German shepherd, German shepherd dog, German police dog, alsatian\n",
      "236 : Doberman, Doberman pinscher\n",
      "237 : miniature pinscher\n",
      "238 : Greater Swiss Mountain dog\n",
      "239 : Bernese mountain dog\n",
      "240 : Appenzeller\n",
      "241 : EntleBucher\n",
      "242 : boxer\n",
      "243 : bull mastiff\n",
      "244 : Tibetan mastiff\n",
      "245 : French bulldog\n",
      "246 : Great Dane\n",
      "247 : Saint Bernard, St Bernard\n",
      "248 : Eskimo dog, husky\n",
      "249 : malamute, malemute, Alaskan malamute\n",
      "250 : Siberian husky\n",
      "251 : dalmatian, coach dog, carriage dog\n",
      "252 : affenpinscher, monkey pinscher, monkey dog\n",
      "253 : basenji\n",
      "254 : pug, pug-dog\n",
      "255 : Leonberg\n",
      "256 : Newfoundland, Newfoundland dog\n",
      "257 : Great Pyrenees\n",
      "258 : Samoyed, Samoyede\n",
      "259 : Pomeranian\n",
      "260 : chow, chow chow\n",
      "261 : keeshond\n",
      "262 : Brabancon griffon\n",
      "263 : Pembroke, Pembroke Welsh corgi\n",
      "264 : Cardigan, Cardigan Welsh corgi\n",
      "265 : toy poodle\n",
      "266 : miniature poodle\n",
      "267 : standard poodle\n",
      "268 : Mexican hairless\n"
     ]
    }
   ],
   "source": [
    "for i in range(151, 269):\n",
    "    print(i, \":\", labels[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "### returns \"True\" if a dog is detected in the image stored at img_path\n",
    "def dog_detector(img_path):\n",
    "    if VGG16_predict(img_path) >=151 and VGG16_predict(img_path) <= 268:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "### on the images in human_files_short and dog_files_short.\n",
    "def dog_detect_percentage(img_path):\n",
    "    dog_detect_count = 0\n",
    "    for i in range(len(img_path)):\n",
    "        dog_detect_count += dog_detector(img_path[i])\n",
    "    print (\"Dog files detected in dataset:\", (dog_detect_count/len(img_path)*100), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dog files detected in dataset: 0.0 %\n"
     ]
    }
   ],
   "source": [
    "dog_detect_percentage(human_files_short)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dog files detected in dataset: 93.0 %\n"
     ]
    }
   ],
   "source": [
    "dog_detect_percentage(dog_files_short)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "#VGG11 = models.vgg11(pretrained=True)\n",
    "#VGG13 = models.vgg13(pretrained=True)\n",
    "#VGG16 = models.vgg16(pretrained=True)\n",
    "VGG19 = models.vgg19(pretrained=True)\n",
    "#VGG11_BN = models.vgg11_bn(pretrained=True)\n",
    "#VGG13_BN = models.vgg13_bn(pretrained=True)\n",
    "#VGG16_BN = models.vgg16_bn(pretrained=True)\n",
    "#VGG19_BN = models.vgg19_bn(pretrained=True)\n",
    "\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "if use_cuda:\n",
    "    #VGG11 = VGG11.cuda()\n",
    "    #VGG13 = VGG13.cuda()\n",
    "    #VGG16 = VGG16.cuda()\n",
    "    VGG19 = VGG19.cuda()\n",
    "    #VGG11_BN = VGG11_BN.cuda()\n",
    "    #VGG13_BN = VGG13_BN.cuda()\n",
    "    #VGG16_BN = VGG16_BN.cuda()\n",
    "    #VGG19_BN = VGG19_BN.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def VGG_predict(img_path, vgg='VGG19'):\n",
    "\n",
    "    img = Image.open(img_path)\n",
    "    normalize = transforms.Compose([transforms.Resize((224,224)),\n",
    "                                    transforms.ToTensor(),\n",
    "                                    transforms.Normalize(mean=[0.5, 0.5, 0.5],\n",
    "                                                         std=[0.5, 0.5, 0.5])])\n",
    "    img = normalize(img)\n",
    "    img = img.cuda()\n",
    "    \n",
    "    if vgg == 'VGG11':\n",
    "        prediction = VGG11(img.unsqueeze(dim=0))\n",
    "    elif vgg == 'VGG13':\n",
    "        prediction = VGG13(img.unsqueeze(dim=0))\n",
    "    elif vgg == 'VGG16':\n",
    "        prediction = VGG16(img.unsqueeze(dim=0))    \n",
    "    elif vgg == 'VGG19':\n",
    "        prediction = VGG19(img.unsqueeze(dim=0))\n",
    "    elif vgg == 'VGG11_BN':\n",
    "        prediction = VGG11_BN(img.unsqueeze(dim=0))\n",
    "    elif vgg == 'VGG13_BN':\n",
    "        prediction = VGG13_BN(img.unsqueeze(dim=0))\n",
    "    elif vgg == 'VGG16_BN':\n",
    "        prediction = VGG16_BN(img.unsqueeze(dim=0))    \n",
    "    elif vgg == 'VGG19_BN':\n",
    "        prediction = VGG19_BN(img.unsqueeze(dim=0))\n",
    "    else:\n",
    "        print(\"Unsupported VGG version input\")\n",
    "        \n",
    "    prediction_index_tensor = torch.max(prediction.data, dim=1)[1]\n",
    "    prediction_index = prediction_index_tensor.cpu().numpy()[0]\n",
    "\n",
    "    return prediction_index # predicted class index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "st\\001.Affenpinscher\\Affenpinscher : 252 : affenpinscher, monkey pinscher, monkey dog\n",
      "st\\001.Affenpinscher\\Affenpinscher : 252 : affenpinscher, monkey pinscher, monkey dog\n",
      "st\\001.Affenpinscher\\Affenpinscher : 204 : Lhasa, Lhasa apso\n",
      "st\\001.Affenpinscher\\Affenpinscher : 252 : affenpinscher, monkey pinscher, monkey dog\n",
      "st\\001.Affenpinscher\\Affenpinscher : 200 : Tibetan terrier, chrysanthemum dog\n",
      "st\\001.Affenpinscher\\Affenpinscher : 204 : Tibetan terrier, chrysanthemum dog\n",
      "st\\001.Affenpinscher\\Affenpinscher : 252 : affenpinscher, monkey pinscher, monkey dog\n",
      "st\\001.Affenpinscher\\Affenpinscher : 192 : cairn, cairn terrier\n",
      "test\\002.Afghan_hound\\Afghan_hound : 160 : Afghan hound, Afghan\n",
      "test\\002.Afghan_hound\\Afghan_hound : 160 : Afghan hound, Afghan\n",
      "test\\002.Afghan_hound\\Afghan_hound : 160 : Afghan hound, Afghan\n",
      "test\\002.Afghan_hound\\Afghan_hound : 219 : cocker spaniel, English cocker spaniel, cocker\n",
      "test\\002.Afghan_hound\\Afghan_hound : 226 : Afghan hound, Afghan\n",
      "test\\002.Afghan_hound\\Afghan_hound : 212 : Afghan hound, Afghan\n",
      "test\\002.Afghan_hound\\Afghan_hound : 160 : Leonberg\n",
      "test\\002.Afghan_hound\\Afghan_hound : 160 : Afghan hound, Afghan\n",
      ".Airedale_terrier\\Airedale_terrier : 189 : Airedale, Airedale terrier\n",
      ".Airedale_terrier\\Airedale_terrier : 191 : Airedale, Airedale terrier\n",
      ".Airedale_terrier\\Airedale_terrier : 189 : Airedale, Airedale terrier\n",
      ".Airedale_terrier\\Airedale_terrier : 191 : Airedale, Airedale terrier\n"
     ]
    }
   ],
   "source": [
    "def test_VGG_predict(img_paths, vgg='VGG16', testrange = 20):\n",
    "    for i in range(testrange):\n",
    "        print(img_paths[i][-44:-10], \":\", VGG_predict(img_paths[i], vgg), \":\", labels[VGG_predict(img_paths[i], vgg)])\n",
    "        \n",
    "test_VGG_predict(dog_files_short, 'VGG16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def VGG_dog_detector(img_path, vgg='VGG19'):\n",
    "    if VGG_predict(img_path, vgg) >=151 and VGG_predict(img_path, vgg) <= 268:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "def VGG_dog_detect_percentage(img_path, vgg='VGG16'):\n",
    "    dog_detect_count = 0\n",
    "    for i in range(len(img_path)):\n",
    "        dog_detect_count += VGG_dog_detector(img_path[i], vgg)\n",
    "    print (\"Dog files detected in dataset:\", (dog_detect_count/len(img_path)*100), \"%\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dog files detected in dataset: 93.0 %\n"
     ]
    }
   ],
   "source": [
    "VGG_dog_detect_percentage(dog_files_short, 'VGG13')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dog files detected in dataset: 50.0 %\n"
     ]
    }
   ],
   "source": [
    "VGG_dog_detect_percentage(dog_files_short, 'VGG13_BN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dog files detected in dataset: 96.0 %\n"
     ]
    }
   ],
   "source": [
    "VGG_dog_detect_percentage(dog_files_short, 'VGG16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dog files detected in dataset: 57.99999999999999 %\n"
     ]
    }
   ],
   "source": [
    "VGG_dog_detect_percentage(dog_files_short, 'VGG16_BN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dog files detected in dataset: 95.0 %\n"
     ]
    }
   ],
   "source": [
    "VGG_dog_detect_percentage(dog_files_short, 'VGG19')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dog files detected in dataset: 64.0 %\n"
     ]
    }
   ],
   "source": [
    "VGG_dog_detect_percentage(dog_files_short, 'VGG19_BN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Normalization appears to greatly reduce dog detection performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dog files detected in dataset: 97.54520416716561 %\n"
     ]
    }
   ],
   "source": [
    "VGG_dog_detect_percentage(dog_files, 'VGG13')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dog files detected in dataset: 98.3594779068375 %\n"
     ]
    }
   ],
   "source": [
    "VGG_dog_detect_percentage(dog_files, 'VGG16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dog files detected in dataset: 98.38342713447491 %\n"
     ]
    }
   ],
   "source": [
    "VGG_dog_detect_percentage(dog_files, 'VGG19')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SE-ResNext50 and NasNet-Mobile Dog Breed Classifiers (without pretraining)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torch.optim as optim\n",
    "\n",
    "use_cuda = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SE-ResNext50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "\n",
    "train_dir = r\"D:\\Python\\deep-learning-v2-pytorch\\project-dog-classification\\dogImages\\train\"\n",
    "valid_dir = r\"D:\\Python\\deep-learning-v2-pytorch\\project-dog-classification\\dogImages\\valid\"\n",
    "test_dir = r\"D:\\Python\\deep-learning-v2-pytorch\\project-dog-classification\\dogImages\\test\"\n",
    "\n",
    "transform_SEResNext50 = transforms.Compose([transforms.Resize((224,224)), \n",
    "                                transforms.ToTensor(), \n",
    "                                transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])])\n",
    "\n",
    "train_set_SEResNext50 = datasets.ImageFolder(train_dir, transform=transform_SEResNext50)\n",
    "train_loader_SEResNext50 = torch.utils.data.DataLoader(train_set_SEResNext50, shuffle=True, batch_size=batch_size)\n",
    "#train_images, train_labels = next(iter(train_loader))\n",
    "\n",
    "valid_set_SEResNext50 = datasets.ImageFolder(valid_dir, transform=transform_SEResNext50)\n",
    "valid_loader_SEResNext50 = torch.utils.data.DataLoader(valid_set_SEResNext50, shuffle=True, batch_size=batch_size)\n",
    "#valid_images, valid_labels = next(iter(valid_loader))\n",
    "\n",
    "test_set_SEResNext50 = datasets.ImageFolder(test_dir, transform=transform_SEResNext50)\n",
    "test_loader_SEResNext50 = torch.utils.data.DataLoader(test_set_SEResNext50, shuffle=True, batch_size=batch_size)\n",
    "#test_images, test_labels = next(iter(test_loader))\n",
    "\n",
    "loaders_SEResNext50={'train':train_loader_SEResNext50, 'valid': valid_loader_SEResNext50, 'test':test_loader_SEResNext50}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division, absolute_import\n",
    "from collections import OrderedDict\n",
    "import math\n",
    "\n",
    "import torch.nn as nn\n",
    "from torch.utils import model_zoo\n",
    "\n",
    "\n",
    "class SEModule(nn.Module):\n",
    "\n",
    "    def __init__(self, channels, reduction):\n",
    "        super(SEModule, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc1 = nn.Conv2d(channels, channels // reduction, kernel_size=1,\n",
    "                             padding=0)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.fc2 = nn.Conv2d(channels // reduction, channels, kernel_size=1,\n",
    "                             padding=0)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        module_input = x\n",
    "        x = self.avg_pool(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return module_input * x\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    \"\"\"\n",
    "    Base class for bottlenecks that implements `forward()` method.\n",
    "    \"\"\"\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out = self.se_module(out) + residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class SEResNeXtBottleneck(Bottleneck):\n",
    "    \"\"\"\n",
    "    ResNeXt bottleneck type C with a Squeeze-and-Excitation module.\n",
    "    \"\"\"\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, groups, reduction, stride=1,\n",
    "                 downsample=None, base_width=4):\n",
    "        super(SEResNeXtBottleneck, self).__init__()\n",
    "        width = math.floor(planes * (base_width / 64)) * groups\n",
    "        self.conv1 = nn.Conv2d(inplanes, width, kernel_size=1, bias=False,\n",
    "                               stride=1)\n",
    "        self.bn1 = nn.BatchNorm2d(width)\n",
    "        self.conv2 = nn.Conv2d(width, width, kernel_size=3, stride=stride,\n",
    "                               padding=1, groups=groups, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(width)\n",
    "        self.conv3 = nn.Conv2d(width, planes * 4, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(planes * 4)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.se_module = SEModule(planes * 4, reduction=reduction)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "\n",
    "class SENet(nn.Module):\n",
    "\n",
    "    def __init__(self, block, layers, groups, reduction, dropout_p=0.2,\n",
    "                 inplanes=128, input_3x3=True, downsample_kernel_size=3,\n",
    "                 downsample_padding=1, num_classes=1000):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        block (nn.Module): Bottleneck class.\n",
    "            - For SENet154: SEBottleneck\n",
    "            - For SE-ResNet models: SEResNetBottleneck\n",
    "            - For SE-ResNeXt models:  SEResNeXtBottleneck\n",
    "        layers (list of ints): Number of residual blocks for 4 layers of the\n",
    "            network (layer1...layer4).\n",
    "        groups (int): Number of groups for the 3x3 convolution in each\n",
    "            bottleneck block.\n",
    "            - For SENet154: 64\n",
    "            - For SE-ResNet models: 1\n",
    "            - For SE-ResNeXt models:  32\n",
    "        reduction (int): Reduction ratio for Squeeze-and-Excitation modules.\n",
    "            - For all models: 16\n",
    "        dropout_p (float or None): Drop probability for the Dropout layer.\n",
    "            If `None` the Dropout layer is not used.\n",
    "            - For SENet154: 0.2\n",
    "            - For SE-ResNet models: None\n",
    "            - For SE-ResNeXt models: None\n",
    "        inplanes (int):  Number of input channels for layer1.\n",
    "            - For SENet154: 128\n",
    "            - For SE-ResNet models: 64\n",
    "            - For SE-ResNeXt models: 64\n",
    "        input_3x3 (bool): If `True`, use three 3x3 convolutions instead of\n",
    "            a single 7x7 convolution in layer0.\n",
    "            - For SENet154: True\n",
    "            - For SE-ResNet models: False\n",
    "            - For SE-ResNeXt models: False\n",
    "        downsample_kernel_size (int): Kernel size for downsampling convolutions\n",
    "            in layer2, layer3 and layer4.\n",
    "            - For SENet154: 3\n",
    "            - For SE-ResNet models: 1\n",
    "            - For SE-ResNeXt models: 1\n",
    "        downsample_padding (int): Padding for downsampling convolutions in\n",
    "            layer2, layer3 and layer4.\n",
    "            - For SENet154: 1\n",
    "            - For SE-ResNet models: 0\n",
    "            - For SE-ResNeXt models: 0\n",
    "        num_classes (int): Number of outputs in `last_linear` layer.\n",
    "            - For all models: 1000\n",
    "        \"\"\"\n",
    "        super(SENet, self).__init__()\n",
    "        self.inplanes = inplanes\n",
    "        if input_3x3:\n",
    "            layer0_modules = [\n",
    "                ('conv1', nn.Conv2d(3, 64, 3, stride=2, padding=1,\n",
    "                                    bias=False)),\n",
    "                ('bn1', nn.BatchNorm2d(64)),\n",
    "                ('relu1', nn.ReLU(inplace=True)),\n",
    "                ('conv2', nn.Conv2d(64, 64, 3, stride=1, padding=1,\n",
    "                                    bias=False)),\n",
    "                ('bn2', nn.BatchNorm2d(64)),\n",
    "                ('relu2', nn.ReLU(inplace=True)),\n",
    "                ('conv3', nn.Conv2d(64, inplanes, 3, stride=1, padding=1,\n",
    "                                    bias=False)),\n",
    "                ('bn3', nn.BatchNorm2d(inplanes)),\n",
    "                ('relu3', nn.ReLU(inplace=True)),\n",
    "            ]\n",
    "        else:\n",
    "            layer0_modules = [\n",
    "                ('conv1', nn.Conv2d(3, inplanes, kernel_size=7, stride=2,\n",
    "                                    padding=3, bias=False)),\n",
    "                ('bn1', nn.BatchNorm2d(inplanes)),\n",
    "                ('relu1', nn.ReLU(inplace=True)),\n",
    "            ]\n",
    "        # To preserve compatibility with Caffe weights `ceil_mode=True`\n",
    "        # is used instead of `padding=1`.\n",
    "        layer0_modules.append(('pool', nn.MaxPool2d(3, stride=2,\n",
    "                                                    ceil_mode=True)))\n",
    "        self.layer0 = nn.Sequential(OrderedDict(layer0_modules))\n",
    "        self.layer1 = self._make_layer(\n",
    "            block,\n",
    "            planes=64,\n",
    "            blocks=layers[0],\n",
    "            groups=groups,\n",
    "            reduction=reduction,\n",
    "            downsample_kernel_size=1,\n",
    "            downsample_padding=0\n",
    "        )\n",
    "        self.layer2 = self._make_layer(\n",
    "            block,\n",
    "            planes=128,\n",
    "            blocks=layers[1],\n",
    "            stride=2,\n",
    "            groups=groups,\n",
    "            reduction=reduction,\n",
    "            downsample_kernel_size=downsample_kernel_size,\n",
    "            downsample_padding=downsample_padding\n",
    "        )\n",
    "        self.layer3 = self._make_layer(\n",
    "            block,\n",
    "            planes=256,\n",
    "            blocks=layers[2],\n",
    "            stride=2,\n",
    "            groups=groups,\n",
    "            reduction=reduction,\n",
    "            downsample_kernel_size=downsample_kernel_size,\n",
    "            downsample_padding=downsample_padding\n",
    "        )\n",
    "        self.layer4 = self._make_layer(\n",
    "            block,\n",
    "            planes=512,\n",
    "            blocks=layers[3],\n",
    "            stride=2,\n",
    "            groups=groups,\n",
    "            reduction=reduction,\n",
    "            downsample_kernel_size=downsample_kernel_size,\n",
    "            downsample_padding=downsample_padding\n",
    "        )\n",
    "        self.avg_pool = nn.AvgPool2d(7, stride=1)\n",
    "        self.dropout = nn.Dropout(dropout_p) if dropout_p is not None else None\n",
    "        self.last_linear = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, groups, reduction, stride=1,\n",
    "                    downsample_kernel_size=1, downsample_padding=0):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
    "                          kernel_size=downsample_kernel_size, stride=stride,\n",
    "                          padding=downsample_padding, bias=False),\n",
    "                nn.BatchNorm2d(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, groups, reduction, stride,\n",
    "                            downsample))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes, groups, reduction))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def features(self, x):\n",
    "        x = self.layer0(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        return x\n",
    "\n",
    "    def logits(self, x):\n",
    "        x = self.avg_pool(x)\n",
    "        if self.dropout is not None:\n",
    "            x = self.dropout(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.last_linear(x)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.logits(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def se_resnext50_32x4d(num_classes=1000):\n",
    "    model = SENet(SEResNeXtBottleneck, [3, 4, 6, 3], groups=32, reduction=16,\n",
    "                  dropout_p=None, inplanes=64, input_3x3=False,\n",
    "                  downsample_kernel_size=1, downsample_padding=0,\n",
    "                  num_classes=num_classes)\n",
    "    return model\n",
    "\n",
    "\n",
    "def se_resnext101_32x4d(num_classes=1000):\n",
    "    model = SENet(SEResNeXtBottleneck, [3, 4, 23, 3], groups=32, reduction=16,\n",
    "                  dropout_p=None, inplanes=64, input_3x3=False,\n",
    "                  downsample_kernel_size=1, downsample_padding=0,\n",
    "                  num_classes=num_classes)\n",
    "    return model\n",
    "\n",
    "# instantiate the CNN\n",
    "model_SEResNext50 = se_resnext50_32x4d(num_classes=133)\n",
    "\n",
    "# move tensors to GPU if CUDA is available\n",
    "if use_cuda:\n",
    "    model_SEResNext50.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion_SEResNext50 = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer_SEResNext50 = optim.SGD(model_SEResNext50.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# the following import is required for training to be robust to truncated images\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "import time\n",
    "\n",
    "def train(n_epochs, loaders, model, optimizer, criterion, use_cuda, save_path):\n",
    "    \"\"\"returns trained model\"\"\"\n",
    "    # initialize tracker for minimum validation loss\n",
    "   \n",
    "    valid_loss_min = np.Inf \n",
    "    \n",
    "    for epoch in range(1, n_epochs+1):\n",
    "                \n",
    "        start = time.time()\n",
    "        \n",
    "        # initialize variables to monitor training and validation loss\n",
    "        train_loss = 0.0\n",
    "        valid_loss = 0.0\n",
    "        \n",
    "        ###################\n",
    "        # train the model #\n",
    "        ###################\n",
    "        model.train()\n",
    "        for batch_idx, (data, target) in enumerate(loaders['train']):\n",
    "            # move to GPU\n",
    "            if use_cuda:\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "            ## find the loss and update the model parameters accordingly\n",
    "            ## record the average training loss, using something like\n",
    "            ## train_loss = train_loss + ((1 / (batch_idx + 1)) * (loss.data - train_loss))\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += ((1 / (batch_idx + 1)) * (loss.data - train_loss))\n",
    "                        \n",
    "            if batch_idx % 200 == 0:\n",
    "                print(epoch, ':', batch_idx, 'train_loss:', train_loss)\n",
    "                \n",
    "        end = time.time()\n",
    "        print('Elapsed Epoch Training Time:', end - start)\n",
    "            \n",
    "            \n",
    "        ######################    \n",
    "        # validate the model #\n",
    "        ######################\n",
    "        model.eval()\n",
    "        for batch_idx, (data, target) in enumerate(loaders['valid']):\n",
    "            # move to GPU\n",
    "            if use_cuda:\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "            ## update the average validation loss\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            valid_loss += ((1 / (batch_idx + 1)) * (loss.data - valid_loss))\n",
    "      \n",
    "        # print training/validation statistics \n",
    "        print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n",
    "            epoch, \n",
    "            train_loss,\n",
    "            valid_loss\n",
    "            ))\n",
    "        \n",
    "        # save the model if validation loss has decreased\n",
    "        if valid_loss <= valid_loss_min:\n",
    "            print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
    "            valid_loss_min,\n",
    "            valid_loss))\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "            valid_loss_min = valid_loss\n",
    "     \n",
    "    # return trained model\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 : 0 train_loss: tensor(4.0100, device='cuda:0')\n",
      "1 : 100 train_loss: tensor(4.2383, device='cuda:0')\n",
      "1 : 200 train_loss: tensor(4.2141, device='cuda:0')\n",
      "1 : 300 train_loss: tensor(4.2021, device='cuda:0')\n",
      "1 : 400 train_loss: tensor(4.1913, device='cuda:0')\n",
      "Elapsed Epoch Training Time: 190.8930904865265\n",
      "Epoch: 1 \tTraining Loss: 4.189122 \tValidation Loss: 4.479331\n",
      "Validation loss decreased (inf --> 4.479331).  Saving model ...\n",
      "2 : 0 train_loss: tensor(4.3610, device='cuda:0')\n",
      "2 : 100 train_loss: tensor(4.1123, device='cuda:0')\n",
      "2 : 200 train_loss: tensor(4.0983, device='cuda:0')\n",
      "2 : 300 train_loss: tensor(4.0929, device='cuda:0')\n",
      "2 : 400 train_loss: tensor(4.0757, device='cuda:0')\n",
      "Elapsed Epoch Training Time: 196.31233763694763\n",
      "Epoch: 2 \tTraining Loss: 4.073340 \tValidation Loss: 4.838991\n",
      "3 : 0 train_loss: tensor(3.9705, device='cuda:0')\n",
      "3 : 100 train_loss: tensor(3.9702, device='cuda:0')\n",
      "3 : 200 train_loss: tensor(3.9625, device='cuda:0')\n",
      "3 : 300 train_loss: tensor(3.9627, device='cuda:0')\n",
      "3 : 400 train_loss: tensor(3.9578, device='cuda:0')\n",
      "Elapsed Epoch Training Time: 190.97838187217712\n",
      "Epoch: 3 \tTraining Loss: 3.957649 \tValidation Loss: 4.585129\n",
      "4 : 0 train_loss: tensor(3.4167, device='cuda:0')\n",
      "4 : 100 train_loss: tensor(3.8238, device='cuda:0')\n",
      "4 : 200 train_loss: tensor(3.8520, device='cuda:0')\n",
      "4 : 300 train_loss: tensor(3.8410, device='cuda:0')\n",
      "4 : 400 train_loss: tensor(3.8321, device='cuda:0')\n",
      "Elapsed Epoch Training Time: 193.94391632080078\n",
      "Epoch: 4 \tTraining Loss: 3.832819 \tValidation Loss: 5.034349\n",
      "5 : 0 train_loss: tensor(4.1737, device='cuda:0')\n",
      "5 : 100 train_loss: tensor(3.7261, device='cuda:0')\n",
      "5 : 200 train_loss: tensor(3.7285, device='cuda:0')\n",
      "5 : 300 train_loss: tensor(3.7449, device='cuda:0')\n",
      "5 : 400 train_loss: tensor(3.7365, device='cuda:0')\n",
      "Elapsed Epoch Training Time: 187.2324390411377\n",
      "Epoch: 5 \tTraining Loss: 3.734715 \tValidation Loss: 4.656174\n",
      "6 : 0 train_loss: tensor(3.5496, device='cuda:0')\n",
      "6 : 100 train_loss: tensor(3.6391, device='cuda:0')\n",
      "6 : 200 train_loss: tensor(3.6089, device='cuda:0')\n",
      "6 : 300 train_loss: tensor(3.6084, device='cuda:0')\n",
      "6 : 400 train_loss: tensor(3.6167, device='cuda:0')\n",
      "Elapsed Epoch Training Time: 190.1015269756317\n",
      "Epoch: 6 \tTraining Loss: 3.615679 \tValidation Loss: 6.188782\n",
      "7 : 0 train_loss: tensor(3.3915, device='cuda:0')\n",
      "7 : 100 train_loss: tensor(3.5179, device='cuda:0')\n",
      "7 : 200 train_loss: tensor(3.5139, device='cuda:0')\n",
      "7 : 300 train_loss: tensor(3.5046, device='cuda:0')\n",
      "7 : 400 train_loss: tensor(3.5212, device='cuda:0')\n",
      "Elapsed Epoch Training Time: 193.69586396217346\n",
      "Epoch: 7 \tTraining Loss: 3.518231 \tValidation Loss: 4.315127\n",
      "Validation loss decreased (4.479331 --> 4.315127).  Saving model ...\n",
      "8 : 0 train_loss: tensor(3.4500, device='cuda:0')\n",
      "8 : 100 train_loss: tensor(3.3546, device='cuda:0')\n",
      "8 : 200 train_loss: tensor(3.3891, device='cuda:0')\n",
      "8 : 300 train_loss: tensor(3.3918, device='cuda:0')\n",
      "8 : 400 train_loss: tensor(3.3914, device='cuda:0')\n",
      "Elapsed Epoch Training Time: 196.03846907615662\n",
      "Epoch: 8 \tTraining Loss: 3.390189 \tValidation Loss: 4.331253\n",
      "9 : 0 train_loss: tensor(2.8274, device='cuda:0')\n",
      "9 : 100 train_loss: tensor(3.2023, device='cuda:0')\n",
      "9 : 200 train_loss: tensor(3.2032, device='cuda:0')\n",
      "9 : 300 train_loss: tensor(3.2229, device='cuda:0')\n",
      "9 : 400 train_loss: tensor(3.2465, device='cuda:0')\n",
      "Elapsed Epoch Training Time: 190.10153198242188\n",
      "Epoch: 9 \tTraining Loss: 3.250428 \tValidation Loss: 4.843374\n",
      "10 : 0 train_loss: tensor(3.3980, device='cuda:0')\n",
      "10 : 100 train_loss: tensor(3.1319, device='cuda:0')\n",
      "10 : 200 train_loss: tensor(3.1202, device='cuda:0')\n",
      "10 : 300 train_loss: tensor(3.1215, device='cuda:0')\n",
      "10 : 400 train_loss: tensor(3.1192, device='cuda:0')\n",
      "Elapsed Epoch Training Time: 194.4076430797577\n",
      "Epoch: 10 \tTraining Loss: 3.121714 \tValidation Loss: 4.974743\n",
      "11 : 0 train_loss: tensor(3.0366, device='cuda:0')\n",
      "11 : 100 train_loss: tensor(2.9717, device='cuda:0')\n",
      "11 : 200 train_loss: tensor(2.9410, device='cuda:0')\n",
      "11 : 300 train_loss: tensor(2.9591, device='cuda:0')\n",
      "11 : 400 train_loss: tensor(2.9739, device='cuda:0')\n",
      "Elapsed Epoch Training Time: 195.4140763282776\n",
      "Epoch: 11 \tTraining Loss: 2.978927 \tValidation Loss: 7.936401\n",
      "12 : 0 train_loss: tensor(2.5417, device='cuda:0')\n",
      "12 : 100 train_loss: tensor(2.7812, device='cuda:0')\n",
      "12 : 200 train_loss: tensor(2.8265, device='cuda:0')\n",
      "12 : 300 train_loss: tensor(2.8528, device='cuda:0')\n",
      "12 : 400 train_loss: tensor(2.8531, device='cuda:0')\n",
      "Elapsed Epoch Training Time: 191.11710214614868\n",
      "Epoch: 12 \tTraining Loss: 2.857052 \tValidation Loss: 4.560429\n",
      "13 : 0 train_loss: tensor(2.2314, device='cuda:0')\n",
      "13 : 100 train_loss: tensor(2.6444, device='cuda:0')\n",
      "13 : 200 train_loss: tensor(2.6700, device='cuda:0')\n",
      "13 : 300 train_loss: tensor(2.6733, device='cuda:0')\n",
      "13 : 400 train_loss: tensor(2.6893, device='cuda:0')\n",
      "Elapsed Epoch Training Time: 192.19075512886047\n",
      "Epoch: 13 \tTraining Loss: 2.692783 \tValidation Loss: 5.224927\n",
      "14 : 0 train_loss: tensor(2.6916, device='cuda:0')\n",
      "14 : 100 train_loss: tensor(2.4795, device='cuda:0')\n",
      "14 : 200 train_loss: tensor(2.4838, device='cuda:0')\n",
      "14 : 300 train_loss: tensor(2.5006, device='cuda:0')\n",
      "14 : 400 train_loss: tensor(2.5083, device='cuda:0')\n",
      "Elapsed Epoch Training Time: 192.64653515815735\n",
      "Epoch: 14 \tTraining Loss: 2.511164 \tValidation Loss: 5.502448\n",
      "15 : 0 train_loss: tensor(2.0610, device='cuda:0')\n",
      "15 : 100 train_loss: tensor(2.2651, device='cuda:0')\n",
      "15 : 200 train_loss: tensor(2.3342, device='cuda:0')\n",
      "15 : 300 train_loss: tensor(2.3552, device='cuda:0')\n",
      "15 : 400 train_loss: tensor(2.3920, device='cuda:0')\n",
      "Elapsed Epoch Training Time: 190.89541244506836\n",
      "Epoch: 15 \tTraining Loss: 2.392924 \tValidation Loss: 3.964932\n",
      "Validation loss decreased (4.315127 --> 3.964932).  Saving model ...\n",
      "16 : 0 train_loss: tensor(2.8353, device='cuda:0')\n",
      "16 : 100 train_loss: tensor(2.2153, device='cuda:0')\n",
      "16 : 200 train_loss: tensor(2.2013, device='cuda:0')\n",
      "16 : 300 train_loss: tensor(2.2155, device='cuda:0')\n",
      "16 : 400 train_loss: tensor(2.2301, device='cuda:0')\n",
      "Elapsed Epoch Training Time: 194.84533071517944\n",
      "Epoch: 16 \tTraining Loss: 2.234220 \tValidation Loss: 5.886800\n",
      "17 : 0 train_loss: tensor(1.9387, device='cuda:0')\n",
      "17 : 100 train_loss: tensor(2.0674, device='cuda:0')\n",
      "17 : 200 train_loss: tensor(2.0351, device='cuda:0')\n",
      "17 : 300 train_loss: tensor(2.0465, device='cuda:0')\n",
      "17 : 400 train_loss: tensor(2.0700, device='cuda:0')\n",
      "Elapsed Epoch Training Time: 437.9658546447754\n",
      "Epoch: 17 \tTraining Loss: 2.070130 \tValidation Loss: 5.498390\n",
      "18 : 0 train_loss: tensor(2.0238, device='cuda:0')\n",
      "18 : 100 train_loss: tensor(1.8591, device='cuda:0')\n",
      "18 : 200 train_loss: tensor(1.8628, device='cuda:0')\n",
      "18 : 300 train_loss: tensor(1.8683, device='cuda:0')\n",
      "18 : 400 train_loss: tensor(1.9044, device='cuda:0')\n",
      "Elapsed Epoch Training Time: 515.584947347641\n",
      "Epoch: 18 \tTraining Loss: 1.912926 \tValidation Loss: 5.369614\n",
      "19 : 0 train_loss: tensor(1.8331, device='cuda:0')\n",
      "19 : 100 train_loss: tensor(1.7535, device='cuda:0')\n",
      "19 : 200 train_loss: tensor(1.7634, device='cuda:0')\n",
      "19 : 300 train_loss: tensor(1.7656, device='cuda:0')\n",
      "19 : 400 train_loss: tensor(1.8028, device='cuda:0')\n",
      "Elapsed Epoch Training Time: 517.6306703090668\n",
      "Epoch: 19 \tTraining Loss: 1.811196 \tValidation Loss: 7.779504\n",
      "20 : 0 train_loss: tensor(1.5721, device='cuda:0')\n",
      "20 : 100 train_loss: tensor(1.5784, device='cuda:0')\n",
      "20 : 200 train_loss: tensor(1.6007, device='cuda:0')\n",
      "20 : 300 train_loss: tensor(1.6181, device='cuda:0')\n",
      "20 : 400 train_loss: tensor(1.6299, device='cuda:0')\n",
      "Elapsed Epoch Training Time: 518.4429874420166\n",
      "Epoch: 20 \tTraining Loss: 1.639885 \tValidation Loss: 5.261305\n"
     ]
    }
   ],
   "source": [
    "model_SEResNext50.load_state_dict(torch.load('model_SEResNext50.pt'))\n",
    "\n",
    "# train the model\n",
    "model_SEResNext50 = train(20, loaders_SEResNext50, model_SEResNext50, optimizer_SEResNext50, \n",
    "                      criterion_SEResNext50, use_cuda, 'model_SEResNext50.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(loaders, model, criterion, use_cuda):\n",
    "\n",
    "    # monitor test loss and accuracy\n",
    "    test_loss = 0.\n",
    "    correct = 0.\n",
    "    total = 0.\n",
    "\n",
    "    model.eval()\n",
    "    for batch_idx, (data, target) in enumerate(loaders['test']):\n",
    "        # move to GPU\n",
    "        if use_cuda:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        # forward pass: compute predicted outputs by passing inputs to the model\n",
    "        output = model(data)\n",
    "        # calculate the loss\n",
    "        loss = criterion(output, target)\n",
    "        # update average test loss \n",
    "        test_loss = test_loss + ((1 / (batch_idx + 1)) * (loss.data - test_loss))\n",
    "        # convert output probabilities to predicted class\n",
    "        pred = output.data.max(1, keepdim=True)[1]\n",
    "        # compare predictions to true label\n",
    "        correct += np.sum(np.squeeze(pred.eq(target.data.view_as(pred))).cpu().numpy())\n",
    "        total += data.size(0)\n",
    "            \n",
    "    print('Test Loss: {:.6f}\\n'.format(test_loss))\n",
    "\n",
    "    print('\\nTest Accuracy: %2d%% (%2d/%2d)' % (\n",
    "        100. * correct / total, correct, total))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 4.050294\n",
      "\n",
      "\n",
      "Test Accuracy: 11% (98/836)\n"
     ]
    }
   ],
   "source": [
    "# call test function    \n",
    "test(loaders_SEResNext50, model_SEResNext50, criterion_SEResNext50, use_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 4.022505\n",
      "\n",
      "\n",
      "Test Accuracy: 11% (98/836)\n"
     ]
    }
   ],
   "source": [
    "# load the model that got the best validation accuracy\n",
    "model_SEResNext50.load_state_dict(torch.load('model_SEResNext50.pt'))\n",
    "# call test function    \n",
    "test(loaders_SEResNext50, model_SEResNext50, criterion_SEResNext50, use_cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NasNet Mobile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "\n",
    "train_dir = r\"D:\\Python\\deep-learning-v2-pytorch\\project-dog-classification\\dogImages\\train\"\n",
    "valid_dir = r\"D:\\Python\\deep-learning-v2-pytorch\\project-dog-classification\\dogImages\\valid\"\n",
    "test_dir = r\"D:\\Python\\deep-learning-v2-pytorch\\project-dog-classification\\dogImages\\test\"\n",
    "\n",
    "transform_NasNetAMobile = transforms.Compose([transforms.Resize((224,224)), \n",
    "                                transforms.ToTensor(), \n",
    "                                transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])])\n",
    "\n",
    "train_set_NasNetAMobile = datasets.ImageFolder(train_dir, transform=transform_NasNetAMobile)\n",
    "train_loader_NasNetAMobile = torch.utils.data.DataLoader(train_set_NasNetAMobile, shuffle=True, batch_size=batch_size)\n",
    "#train_images, train_labels = next(iter(train_loader))\n",
    "\n",
    "valid_set_NasNetAMobile = datasets.ImageFolder(valid_dir, transform=transform_NasNetAMobile)\n",
    "valid_loader_NasNetAMobile = torch.utils.data.DataLoader(valid_set_NasNetAMobile, shuffle=True, batch_size=batch_size)\n",
    "#valid_images, valid_labels = next(iter(valid_loader))\n",
    "\n",
    "test_set_NasNetAMobile = datasets.ImageFolder(test_dir, transform=transform_NasNetAMobile)\n",
    "test_loader_NasNetAMobile = torch.utils.data.DataLoader(test_set_NasNetAMobile, shuffle=True, batch_size=batch_size)\n",
    "#test_images, test_labels = next(iter(test_loader))\n",
    "\n",
    "loaders_NasNetAMobile={'train':train_loader_NasNetAMobile, 'valid': valid_loader_NasNetAMobile, 'test':test_loader_NasNetAMobile}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division, absolute_import\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class MaxPoolPad(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(MaxPoolPad, self).__init__()\n",
    "        self.pad = nn.ZeroPad2d((1, 0, 1, 0))\n",
    "        self.pool = nn.MaxPool2d(3, stride=2, padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pad(x)\n",
    "        x = self.pool(x)\n",
    "        x = x[:, :, 1:, 1:].contiguous()\n",
    "        return x\n",
    "\n",
    "\n",
    "class AvgPoolPad(nn.Module):\n",
    "\n",
    "    def __init__(self, stride=2, padding=1):\n",
    "        super(AvgPoolPad, self).__init__()\n",
    "        self.pad = nn.ZeroPad2d((1, 0, 1, 0))\n",
    "        self.pool = nn.AvgPool2d(3, stride=stride, padding=padding, count_include_pad=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pad(x)\n",
    "        x = self.pool(x)\n",
    "        x = x[:, :, 1:, 1:].contiguous()\n",
    "        return x\n",
    "\n",
    "\n",
    "class SeparableConv2d(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, dw_kernel, dw_stride, dw_padding, bias=False):\n",
    "        super(SeparableConv2d, self).__init__()\n",
    "        self.depthwise_conv2d = nn.Conv2d(in_channels, in_channels, dw_kernel,\n",
    "                                          stride=dw_stride,\n",
    "                                          padding=dw_padding,\n",
    "                                          bias=bias,\n",
    "                                          groups=in_channels)\n",
    "        self.pointwise_conv2d = nn.Conv2d(in_channels, out_channels, 1, stride=1, bias=bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.depthwise_conv2d(x)\n",
    "        x = self.pointwise_conv2d(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class BranchSeparables(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, name=None, bias=False):\n",
    "        super(BranchSeparables, self).__init__()\n",
    "        self.relu = nn.ReLU()\n",
    "        self.separable_1 = SeparableConv2d(in_channels, in_channels, kernel_size, stride, padding, bias=bias)\n",
    "        self.bn_sep_1 = nn.BatchNorm2d(in_channels, eps=0.001, momentum=0.1, affine=True)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.separable_2 = SeparableConv2d(in_channels, out_channels, kernel_size, 1, padding, bias=bias)\n",
    "        self.bn_sep_2 = nn.BatchNorm2d(out_channels, eps=0.001, momentum=0.1, affine=True)\n",
    "        self.name = name\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(x)\n",
    "        if self.name == 'specific':\n",
    "            x = nn.ZeroPad2d((1, 0, 1, 0))(x)\n",
    "        x = self.separable_1(x)\n",
    "        if self.name == 'specific':\n",
    "            x = x[:, :, 1:, 1:].contiguous()\n",
    "\n",
    "        x = self.bn_sep_1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.separable_2(x)\n",
    "        x = self.bn_sep_2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class BranchSeparablesStem(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, bias=False):\n",
    "        super(BranchSeparablesStem, self).__init__()\n",
    "        self.relu = nn.ReLU()\n",
    "        self.separable_1 = SeparableConv2d(in_channels, out_channels, kernel_size, stride, padding, bias=bias)\n",
    "        self.bn_sep_1 = nn.BatchNorm2d(out_channels, eps=0.001, momentum=0.1, affine=True)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.separable_2 = SeparableConv2d(out_channels, out_channels, kernel_size, 1, padding, bias=bias)\n",
    "        self.bn_sep_2 = nn.BatchNorm2d(out_channels, eps=0.001, momentum=0.1, affine=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(x)\n",
    "        x = self.separable_1(x)\n",
    "        x = self.bn_sep_1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.separable_2(x)\n",
    "        x = self.bn_sep_2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class BranchSeparablesReduction(BranchSeparables):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, z_padding=1, bias=False):\n",
    "        BranchSeparables.__init__(self, in_channels, out_channels, kernel_size, stride, padding, bias)\n",
    "        self.padding = nn.ZeroPad2d((z_padding, 0, z_padding, 0))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(x)\n",
    "        x = self.padding(x)\n",
    "        x = self.separable_1(x)\n",
    "        x = x[:, :, 1:, 1:].contiguous()\n",
    "        x = self.bn_sep_1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.separable_2(x)\n",
    "        x = self.bn_sep_2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class CellStem0(nn.Module):\n",
    "    def __init__(self, stem_filters, num_filters=42):\n",
    "        super(CellStem0, self).__init__()\n",
    "        self.num_filters = num_filters\n",
    "        self.stem_filters = stem_filters\n",
    "        self.conv_1x1 = nn.Sequential()\n",
    "        self.conv_1x1.add_module('relu', nn.ReLU())\n",
    "        self.conv_1x1.add_module('conv', nn.Conv2d(self.stem_filters, self.num_filters, 1, stride=1, bias=False))\n",
    "        self.conv_1x1.add_module('bn', nn.BatchNorm2d(self.num_filters, eps=0.001, momentum=0.1, affine=True))\n",
    "\n",
    "        self.comb_iter_0_left = BranchSeparables(self.num_filters, self.num_filters, 5, 2, 2)\n",
    "        self.comb_iter_0_right = BranchSeparablesStem(self.stem_filters, self.num_filters, 7, 2, 3, bias=False)\n",
    "\n",
    "        self.comb_iter_1_left = nn.MaxPool2d(3, stride=2, padding=1)\n",
    "        self.comb_iter_1_right = BranchSeparablesStem(self.stem_filters, self.num_filters, 7, 2, 3, bias=False)\n",
    "\n",
    "        self.comb_iter_2_left = nn.AvgPool2d(3, stride=2, padding=1, count_include_pad=False)\n",
    "        self.comb_iter_2_right = BranchSeparablesStem(self.stem_filters, self.num_filters, 5, 2, 2, bias=False)\n",
    "\n",
    "        self.comb_iter_3_right = nn.AvgPool2d(3, stride=1, padding=1, count_include_pad=False)\n",
    "\n",
    "        self.comb_iter_4_left = BranchSeparables(self.num_filters, self.num_filters, 3, 1, 1, bias=False)\n",
    "        self.comb_iter_4_right = nn.MaxPool2d(3, stride=2, padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.conv_1x1(x)\n",
    "\n",
    "        x_comb_iter_0_left = self.comb_iter_0_left(x1)\n",
    "        x_comb_iter_0_right = self.comb_iter_0_right(x)\n",
    "        x_comb_iter_0 = x_comb_iter_0_left + x_comb_iter_0_right\n",
    "\n",
    "        x_comb_iter_1_left = self.comb_iter_1_left(x1)\n",
    "        x_comb_iter_1_right = self.comb_iter_1_right(x)\n",
    "        x_comb_iter_1 = x_comb_iter_1_left + x_comb_iter_1_right\n",
    "\n",
    "        x_comb_iter_2_left = self.comb_iter_2_left(x1)\n",
    "        x_comb_iter_2_right = self.comb_iter_2_right(x)\n",
    "        x_comb_iter_2 = x_comb_iter_2_left + x_comb_iter_2_right\n",
    "\n",
    "        x_comb_iter_3_right = self.comb_iter_3_right(x_comb_iter_0)\n",
    "        x_comb_iter_3 = x_comb_iter_3_right + x_comb_iter_1\n",
    "\n",
    "        x_comb_iter_4_left = self.comb_iter_4_left(x_comb_iter_0)\n",
    "        x_comb_iter_4_right = self.comb_iter_4_right(x1)\n",
    "        x_comb_iter_4 = x_comb_iter_4_left + x_comb_iter_4_right\n",
    "\n",
    "        x_out = torch.cat([x_comb_iter_1, x_comb_iter_2, x_comb_iter_3, x_comb_iter_4], 1)\n",
    "        return x_out\n",
    "\n",
    "\n",
    "class CellStem1(nn.Module):\n",
    "\n",
    "    def __init__(self, stem_filters, num_filters):\n",
    "        super(CellStem1, self).__init__()\n",
    "        self.num_filters = num_filters\n",
    "        self.stem_filters = stem_filters\n",
    "        self.conv_1x1 = nn.Sequential()\n",
    "        self.conv_1x1.add_module('relu', nn.ReLU())\n",
    "        self.conv_1x1.add_module('conv', nn.Conv2d(2*self.num_filters, self.num_filters, 1, stride=1, bias=False))\n",
    "        self.conv_1x1.add_module('bn', nn.BatchNorm2d(self.num_filters, eps=0.001, momentum=0.1, affine=True))\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        self.path_1 = nn.Sequential()\n",
    "        self.path_1.add_module('avgpool', nn.AvgPool2d(1, stride=2, count_include_pad=False))\n",
    "        self.path_1.add_module('conv', nn.Conv2d(self.stem_filters, self.num_filters//2, 1, stride=1, bias=False))\n",
    "        self.path_2 = nn.ModuleList()\n",
    "        self.path_2.add_module('pad', nn.ZeroPad2d((0, 1, 0, 1)))\n",
    "        self.path_2.add_module('avgpool', nn.AvgPool2d(1, stride=2, count_include_pad=False))\n",
    "        self.path_2.add_module('conv', nn.Conv2d(self.stem_filters, self.num_filters//2, 1, stride=1, bias=False))\n",
    "\n",
    "        self.final_path_bn = nn.BatchNorm2d(self.num_filters, eps=0.001, momentum=0.1, affine=True)\n",
    "\n",
    "        self.comb_iter_0_left = BranchSeparables(self.num_filters, self.num_filters, 5, 2, 2, name='specific', bias=False)\n",
    "        self.comb_iter_0_right = BranchSeparables(self.num_filters, self.num_filters, 7, 2, 3, name='specific', bias=False)\n",
    "\n",
    "        # self.comb_iter_1_left = nn.MaxPool2d(3, stride=2, padding=1)\n",
    "        self.comb_iter_1_left = MaxPoolPad()\n",
    "        self.comb_iter_1_right = BranchSeparables(self.num_filters, self.num_filters, 7, 2, 3, name='specific', bias=False)\n",
    "\n",
    "        # self.comb_iter_2_left = nn.AvgPool2d(3, stride=2, padding=1, count_include_pad=False)\n",
    "        self.comb_iter_2_left = AvgPoolPad()\n",
    "        self.comb_iter_2_right = BranchSeparables(self.num_filters, self.num_filters, 5, 2, 2, name='specific', bias=False)\n",
    "\n",
    "        self.comb_iter_3_right = nn.AvgPool2d(3, stride=1, padding=1, count_include_pad=False)\n",
    "\n",
    "        self.comb_iter_4_left = BranchSeparables(self.num_filters, self.num_filters, 3, 1, 1, name='specific', bias=False)\n",
    "        # self.comb_iter_4_right = nn.MaxPool2d(3, stride=2, padding=1)\n",
    "        self.comb_iter_4_right = MaxPoolPad()\n",
    "\n",
    "    def forward(self, x_conv0, x_stem_0):\n",
    "        x_left = self.conv_1x1(x_stem_0)\n",
    "\n",
    "        x_relu = self.relu(x_conv0)\n",
    "        # path 1\n",
    "        x_path1 = self.path_1(x_relu)\n",
    "        # path 2\n",
    "        x_path2 = self.path_2.pad(x_relu)\n",
    "        x_path2 = x_path2[:, :, 1:, 1:]\n",
    "        x_path2 = self.path_2.avgpool(x_path2)\n",
    "        x_path2 = self.path_2.conv(x_path2)\n",
    "        # final path\n",
    "        x_right = self.final_path_bn(torch.cat([x_path1, x_path2], 1))\n",
    "\n",
    "        x_comb_iter_0_left = self.comb_iter_0_left(x_left)\n",
    "        x_comb_iter_0_right = self.comb_iter_0_right(x_right)\n",
    "        x_comb_iter_0 = x_comb_iter_0_left + x_comb_iter_0_right\n",
    "\n",
    "        x_comb_iter_1_left = self.comb_iter_1_left(x_left)\n",
    "        x_comb_iter_1_right = self.comb_iter_1_right(x_right)\n",
    "        x_comb_iter_1 = x_comb_iter_1_left + x_comb_iter_1_right\n",
    "\n",
    "        x_comb_iter_2_left = self.comb_iter_2_left(x_left)\n",
    "        x_comb_iter_2_right = self.comb_iter_2_right(x_right)\n",
    "        x_comb_iter_2 = x_comb_iter_2_left + x_comb_iter_2_right\n",
    "\n",
    "        x_comb_iter_3_right = self.comb_iter_3_right(x_comb_iter_0)\n",
    "        x_comb_iter_3 = x_comb_iter_3_right + x_comb_iter_1\n",
    "\n",
    "        x_comb_iter_4_left = self.comb_iter_4_left(x_comb_iter_0)\n",
    "        x_comb_iter_4_right = self.comb_iter_4_right(x_left)\n",
    "        x_comb_iter_4 = x_comb_iter_4_left + x_comb_iter_4_right\n",
    "\n",
    "        x_out = torch.cat([x_comb_iter_1, x_comb_iter_2, x_comb_iter_3, x_comb_iter_4], 1)\n",
    "        return x_out\n",
    "\n",
    "\n",
    "class FirstCell(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels_left, out_channels_left, in_channels_right, out_channels_right):\n",
    "        super(FirstCell, self).__init__()\n",
    "        self.conv_1x1 = nn.Sequential()\n",
    "        self.conv_1x1.add_module('relu', nn.ReLU())\n",
    "        self.conv_1x1.add_module('conv', nn.Conv2d(in_channels_right, out_channels_right, 1, stride=1, bias=False))\n",
    "        self.conv_1x1.add_module('bn', nn.BatchNorm2d(out_channels_right, eps=0.001, momentum=0.1, affine=True))\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        self.path_1 = nn.Sequential()\n",
    "        self.path_1.add_module('avgpool', nn.AvgPool2d(1, stride=2, count_include_pad=False))\n",
    "        self.path_1.add_module('conv', nn.Conv2d(in_channels_left, out_channels_left, 1, stride=1, bias=False))\n",
    "        self.path_2 = nn.ModuleList()\n",
    "        self.path_2.add_module('pad', nn.ZeroPad2d((0, 1, 0, 1)))\n",
    "        self.path_2.add_module('avgpool', nn.AvgPool2d(1, stride=2, count_include_pad=False))\n",
    "        self.path_2.add_module('conv', nn.Conv2d(in_channels_left, out_channels_left, 1, stride=1, bias=False))\n",
    "\n",
    "        self.final_path_bn = nn.BatchNorm2d(out_channels_left * 2, eps=0.001, momentum=0.1, affine=True)\n",
    "\n",
    "        self.comb_iter_0_left = BranchSeparables(out_channels_right, out_channels_right, 5, 1, 2, bias=False)\n",
    "        self.comb_iter_0_right = BranchSeparables(out_channels_right, out_channels_right, 3, 1, 1, bias=False)\n",
    "\n",
    "        self.comb_iter_1_left = BranchSeparables(out_channels_right, out_channels_right, 5, 1, 2, bias=False)\n",
    "        self.comb_iter_1_right = BranchSeparables(out_channels_right, out_channels_right, 3, 1, 1, bias=False)\n",
    "\n",
    "        self.comb_iter_2_left = nn.AvgPool2d(3, stride=1, padding=1, count_include_pad=False)\n",
    "\n",
    "        self.comb_iter_3_left = nn.AvgPool2d(3, stride=1, padding=1, count_include_pad=False)\n",
    "        self.comb_iter_3_right = nn.AvgPool2d(3, stride=1, padding=1, count_include_pad=False)\n",
    "\n",
    "        self.comb_iter_4_left = BranchSeparables(out_channels_right, out_channels_right, 3, 1, 1, bias=False)\n",
    "\n",
    "    def forward(self, x, x_prev):\n",
    "        x_relu = self.relu(x_prev)\n",
    "        # path 1\n",
    "        x_path1 = self.path_1(x_relu)\n",
    "        # path 2\n",
    "        x_path2 = self.path_2.pad(x_relu)\n",
    "        x_path2 = x_path2[:, :, 1:, 1:]\n",
    "        x_path2 = self.path_2.avgpool(x_path2)\n",
    "        x_path2 = self.path_2.conv(x_path2)\n",
    "        # final path\n",
    "        x_left = self.final_path_bn(torch.cat([x_path1, x_path2], 1))\n",
    "\n",
    "        x_right = self.conv_1x1(x)\n",
    "\n",
    "        x_comb_iter_0_left = self.comb_iter_0_left(x_right)\n",
    "        x_comb_iter_0_right = self.comb_iter_0_right(x_left)\n",
    "        x_comb_iter_0 = x_comb_iter_0_left + x_comb_iter_0_right\n",
    "\n",
    "        x_comb_iter_1_left = self.comb_iter_1_left(x_left)\n",
    "        x_comb_iter_1_right = self.comb_iter_1_right(x_left)\n",
    "        x_comb_iter_1 = x_comb_iter_1_left + x_comb_iter_1_right\n",
    "\n",
    "        x_comb_iter_2_left = self.comb_iter_2_left(x_right)\n",
    "        x_comb_iter_2 = x_comb_iter_2_left + x_left\n",
    "\n",
    "        x_comb_iter_3_left = self.comb_iter_3_left(x_left)\n",
    "        x_comb_iter_3_right = self.comb_iter_3_right(x_left)\n",
    "        x_comb_iter_3 = x_comb_iter_3_left + x_comb_iter_3_right\n",
    "\n",
    "        x_comb_iter_4_left = self.comb_iter_4_left(x_right)\n",
    "        x_comb_iter_4 = x_comb_iter_4_left + x_right\n",
    "\n",
    "        x_out = torch.cat([x_left, x_comb_iter_0, x_comb_iter_1, x_comb_iter_2, x_comb_iter_3, x_comb_iter_4], 1)\n",
    "        return x_out\n",
    "\n",
    "\n",
    "class NormalCell(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels_left, out_channels_left, in_channels_right, out_channels_right):\n",
    "        super(NormalCell, self).__init__()\n",
    "        self.conv_prev_1x1 = nn.Sequential()\n",
    "        self.conv_prev_1x1.add_module('relu', nn.ReLU())\n",
    "        self.conv_prev_1x1.add_module('conv', nn.Conv2d(in_channels_left, out_channels_left, 1, stride=1, bias=False))\n",
    "        self.conv_prev_1x1.add_module('bn', nn.BatchNorm2d(out_channels_left, eps=0.001, momentum=0.1, affine=True))\n",
    "\n",
    "        self.conv_1x1 = nn.Sequential()\n",
    "        self.conv_1x1.add_module('relu', nn.ReLU())\n",
    "        self.conv_1x1.add_module('conv', nn.Conv2d(in_channels_right, out_channels_right, 1, stride=1, bias=False))\n",
    "        self.conv_1x1.add_module('bn', nn.BatchNorm2d(out_channels_right, eps=0.001, momentum=0.1, affine=True))\n",
    "\n",
    "        self.comb_iter_0_left = BranchSeparables(out_channels_right, out_channels_right, 5, 1, 2, bias=False)\n",
    "        self.comb_iter_0_right = BranchSeparables(out_channels_left, out_channels_left, 3, 1, 1, bias=False)\n",
    "\n",
    "        self.comb_iter_1_left = BranchSeparables(out_channels_left, out_channels_left, 5, 1, 2, bias=False)\n",
    "        self.comb_iter_1_right = BranchSeparables(out_channels_left, out_channels_left, 3, 1, 1, bias=False)\n",
    "\n",
    "        self.comb_iter_2_left = nn.AvgPool2d(3, stride=1, padding=1, count_include_pad=False)\n",
    "\n",
    "        self.comb_iter_3_left = nn.AvgPool2d(3, stride=1, padding=1, count_include_pad=False)\n",
    "        self.comb_iter_3_right = nn.AvgPool2d(3, stride=1, padding=1, count_include_pad=False)\n",
    "\n",
    "        self.comb_iter_4_left = BranchSeparables(out_channels_right, out_channels_right, 3, 1, 1, bias=False)\n",
    "\n",
    "    def forward(self, x, x_prev):\n",
    "        x_left = self.conv_prev_1x1(x_prev)\n",
    "        x_right = self.conv_1x1(x)\n",
    "\n",
    "        x_comb_iter_0_left = self.comb_iter_0_left(x_right)\n",
    "        x_comb_iter_0_right = self.comb_iter_0_right(x_left)\n",
    "        x_comb_iter_0 = x_comb_iter_0_left + x_comb_iter_0_right\n",
    "\n",
    "        x_comb_iter_1_left = self.comb_iter_1_left(x_left)\n",
    "        x_comb_iter_1_right = self.comb_iter_1_right(x_left)\n",
    "        x_comb_iter_1 = x_comb_iter_1_left + x_comb_iter_1_right\n",
    "\n",
    "        x_comb_iter_2_left = self.comb_iter_2_left(x_right)\n",
    "        x_comb_iter_2 = x_comb_iter_2_left + x_left\n",
    "\n",
    "        x_comb_iter_3_left = self.comb_iter_3_left(x_left)\n",
    "        x_comb_iter_3_right = self.comb_iter_3_right(x_left)\n",
    "        x_comb_iter_3 = x_comb_iter_3_left + x_comb_iter_3_right\n",
    "\n",
    "        x_comb_iter_4_left = self.comb_iter_4_left(x_right)\n",
    "        x_comb_iter_4 = x_comb_iter_4_left + x_right\n",
    "\n",
    "        x_out = torch.cat([x_left, x_comb_iter_0, x_comb_iter_1, x_comb_iter_2, x_comb_iter_3, x_comb_iter_4], 1)\n",
    "        return x_out\n",
    "\n",
    "\n",
    "class ReductionCell0(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels_left, out_channels_left, in_channels_right, out_channels_right):\n",
    "        super(ReductionCell0, self).__init__()\n",
    "        self.conv_prev_1x1 = nn.Sequential()\n",
    "        self.conv_prev_1x1.add_module('relu', nn.ReLU())\n",
    "        self.conv_prev_1x1.add_module('conv', nn.Conv2d(in_channels_left, out_channels_left, 1, stride=1, bias=False))\n",
    "        self.conv_prev_1x1.add_module('bn', nn.BatchNorm2d(out_channels_left, eps=0.001, momentum=0.1, affine=True))\n",
    "\n",
    "        self.conv_1x1 = nn.Sequential()\n",
    "        self.conv_1x1.add_module('relu', nn.ReLU())\n",
    "        self.conv_1x1.add_module('conv', nn.Conv2d(in_channels_right, out_channels_right, 1, stride=1, bias=False))\n",
    "        self.conv_1x1.add_module('bn', nn.BatchNorm2d(out_channels_right, eps=0.001, momentum=0.1, affine=True))\n",
    "\n",
    "        self.comb_iter_0_left = BranchSeparablesReduction(out_channels_right, out_channels_right, 5, 2, 2, bias=False)\n",
    "        self.comb_iter_0_right = BranchSeparablesReduction(out_channels_right, out_channels_right, 7, 2, 3, bias=False)\n",
    "\n",
    "        self.comb_iter_1_left = MaxPoolPad()\n",
    "        self.comb_iter_1_right = BranchSeparablesReduction(out_channels_right, out_channels_right, 7, 2, 3, bias=False)\n",
    "\n",
    "        self.comb_iter_2_left = AvgPoolPad()\n",
    "        self.comb_iter_2_right = BranchSeparablesReduction(out_channels_right, out_channels_right, 5, 2, 2, bias=False)\n",
    "\n",
    "        self.comb_iter_3_right = nn.AvgPool2d(3, stride=1, padding=1, count_include_pad=False)\n",
    "\n",
    "        self.comb_iter_4_left = BranchSeparablesReduction(out_channels_right, out_channels_right, 3, 1, 1, bias=False)\n",
    "        self.comb_iter_4_right = MaxPoolPad()\n",
    "\n",
    "    def forward(self, x, x_prev):\n",
    "        x_left = self.conv_prev_1x1(x_prev)\n",
    "        x_right = self.conv_1x1(x)\n",
    "\n",
    "        x_comb_iter_0_left = self.comb_iter_0_left(x_right)\n",
    "        x_comb_iter_0_right = self.comb_iter_0_right(x_left)\n",
    "        x_comb_iter_0 = x_comb_iter_0_left + x_comb_iter_0_right\n",
    "\n",
    "        x_comb_iter_1_left = self.comb_iter_1_left(x_right)\n",
    "        x_comb_iter_1_right = self.comb_iter_1_right(x_left)\n",
    "        x_comb_iter_1 = x_comb_iter_1_left + x_comb_iter_1_right\n",
    "\n",
    "        x_comb_iter_2_left = self.comb_iter_2_left(x_right)\n",
    "        x_comb_iter_2_right = self.comb_iter_2_right(x_left)\n",
    "        x_comb_iter_2 = x_comb_iter_2_left + x_comb_iter_2_right\n",
    "\n",
    "        x_comb_iter_3_right = self.comb_iter_3_right(x_comb_iter_0)\n",
    "        x_comb_iter_3 = x_comb_iter_3_right + x_comb_iter_1\n",
    "\n",
    "        x_comb_iter_4_left = self.comb_iter_4_left(x_comb_iter_0)\n",
    "        x_comb_iter_4_right = self.comb_iter_4_right(x_right)\n",
    "        x_comb_iter_4 = x_comb_iter_4_left + x_comb_iter_4_right\n",
    "\n",
    "        x_out = torch.cat([x_comb_iter_1, x_comb_iter_2, x_comb_iter_3, x_comb_iter_4], 1)\n",
    "        return x_out\n",
    "\n",
    "\n",
    "class ReductionCell1(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels_left, out_channels_left, in_channels_right, out_channels_right):\n",
    "        super(ReductionCell1, self).__init__()\n",
    "        self.conv_prev_1x1 = nn.Sequential()\n",
    "        self.conv_prev_1x1.add_module('relu', nn.ReLU())\n",
    "        self.conv_prev_1x1.add_module('conv', nn.Conv2d(in_channels_left, out_channels_left, 1, stride=1, bias=False))\n",
    "        self.conv_prev_1x1.add_module('bn', nn.BatchNorm2d(out_channels_left, eps=0.001, momentum=0.1, affine=True))\n",
    "\n",
    "        self.conv_1x1 = nn.Sequential()\n",
    "        self.conv_1x1.add_module('relu', nn.ReLU())\n",
    "        self.conv_1x1.add_module('conv', nn.Conv2d(in_channels_right, out_channels_right, 1, stride=1, bias=False))\n",
    "        self.conv_1x1.add_module('bn', nn.BatchNorm2d(out_channels_right, eps=0.001, momentum=0.1, affine=True))\n",
    "\n",
    "        self.comb_iter_0_left = BranchSeparables(out_channels_right, out_channels_right, 5, 2, 2, name='specific', bias=False)\n",
    "        self.comb_iter_0_right = BranchSeparables(out_channels_right, out_channels_right, 7, 2, 3, name='specific', bias=False)\n",
    "\n",
    "        # self.comb_iter_1_left = nn.MaxPool2d(3, stride=2, padding=1)\n",
    "        self.comb_iter_1_left = MaxPoolPad()\n",
    "        self.comb_iter_1_right = BranchSeparables(out_channels_right, out_channels_right, 7, 2, 3, name='specific', bias=False)\n",
    "\n",
    "        # self.comb_iter_2_left = nn.AvgPool2d(3, stride=2, padding=1, count_include_pad=False)\n",
    "        self.comb_iter_2_left = AvgPoolPad()\n",
    "        self.comb_iter_2_right = BranchSeparables(out_channels_right, out_channels_right, 5, 2, 2, name='specific', bias=False)\n",
    "\n",
    "        self.comb_iter_3_right = nn.AvgPool2d(3, stride=1, padding=1, count_include_pad=False)\n",
    "\n",
    "        self.comb_iter_4_left = BranchSeparables(out_channels_right, out_channels_right, 3, 1, 1, name='specific', bias=False)\n",
    "        # self.comb_iter_4_right = nn.MaxPool2d(3, stride=2, padding=1)\n",
    "        self.comb_iter_4_right =MaxPoolPad()\n",
    "\n",
    "    def forward(self, x, x_prev):\n",
    "        x_left = self.conv_prev_1x1(x_prev)\n",
    "        x_right = self.conv_1x1(x)\n",
    "\n",
    "        x_comb_iter_0_left = self.comb_iter_0_left(x_right)\n",
    "        x_comb_iter_0_right = self.comb_iter_0_right(x_left)\n",
    "        x_comb_iter_0 = x_comb_iter_0_left + x_comb_iter_0_right\n",
    "\n",
    "        x_comb_iter_1_left = self.comb_iter_1_left(x_right)\n",
    "        x_comb_iter_1_right = self.comb_iter_1_right(x_left)\n",
    "        x_comb_iter_1 = x_comb_iter_1_left + x_comb_iter_1_right\n",
    "\n",
    "        x_comb_iter_2_left = self.comb_iter_2_left(x_right)\n",
    "        x_comb_iter_2_right = self.comb_iter_2_right(x_left)\n",
    "        x_comb_iter_2 = x_comb_iter_2_left + x_comb_iter_2_right\n",
    "\n",
    "        x_comb_iter_3_right = self.comb_iter_3_right(x_comb_iter_0)\n",
    "        x_comb_iter_3 = x_comb_iter_3_right + x_comb_iter_1\n",
    "\n",
    "        x_comb_iter_4_left = self.comb_iter_4_left(x_comb_iter_0)\n",
    "        x_comb_iter_4_right = self.comb_iter_4_right(x_right)\n",
    "        x_comb_iter_4 = x_comb_iter_4_left + x_comb_iter_4_right\n",
    "\n",
    "        x_out = torch.cat([x_comb_iter_1, x_comb_iter_2, x_comb_iter_3, x_comb_iter_4], 1)\n",
    "        return x_out\n",
    "\n",
    "\n",
    "class NASNetAMobile(nn.Module):\n",
    "    \"\"\"NASNetAMobile (4 @ 1056) \"\"\"\n",
    "\n",
    "    def __init__(self, num_classes=1000, stem_filters=32, penultimate_filters=1056, filters_multiplier=2):\n",
    "        super(NASNetAMobile, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.stem_filters = stem_filters\n",
    "        self.penultimate_filters = penultimate_filters\n",
    "        self.filters_multiplier = filters_multiplier\n",
    "\n",
    "        filters = self.penultimate_filters // 24\n",
    "        # 24 is default value for the architecture\n",
    "\n",
    "        self.conv0 = nn.Sequential()\n",
    "        self.conv0.add_module('conv', nn.Conv2d(in_channels=3, out_channels=self.stem_filters, kernel_size=3, padding=0, stride=2,\n",
    "                                                bias=False))\n",
    "        self.conv0.add_module('bn', nn.BatchNorm2d(self.stem_filters, eps=0.001, momentum=0.1, affine=True))\n",
    "\n",
    "        self.cell_stem_0 = CellStem0(self.stem_filters, num_filters=filters // (filters_multiplier ** 2))\n",
    "        self.cell_stem_1 = CellStem1(self.stem_filters, num_filters=filters // filters_multiplier)\n",
    "\n",
    "        self.cell_0 = FirstCell(in_channels_left=filters, out_channels_left=filters//2, # 1, 0.5\n",
    "                                in_channels_right=2*filters, out_channels_right=filters) # 2, 1\n",
    "        self.cell_1 = NormalCell(in_channels_left=2*filters, out_channels_left=filters, # 2, 1\n",
    "                                 in_channels_right=6*filters, out_channels_right=filters) # 6, 1\n",
    "        self.cell_2 = NormalCell(in_channels_left=6*filters, out_channels_left=filters, # 6, 1\n",
    "                                 in_channels_right=6*filters, out_channels_right=filters) # 6, 1\n",
    "        self.cell_3 = NormalCell(in_channels_left=6*filters, out_channels_left=filters, # 6, 1\n",
    "                                 in_channels_right=6*filters, out_channels_right=filters) # 6, 1\n",
    "\n",
    "        self.reduction_cell_0 = ReductionCell0(in_channels_left=6*filters, out_channels_left=2*filters, # 6, 2\n",
    "                                               in_channels_right=6*filters, out_channels_right=2*filters) # 6, 2\n",
    "\n",
    "        self.cell_6 = FirstCell(in_channels_left=6*filters, out_channels_left=filters, # 6, 1\n",
    "                                in_channels_right=8*filters, out_channels_right=2*filters) # 8, 2\n",
    "        self.cell_7 = NormalCell(in_channels_left=8*filters, out_channels_left=2*filters, # 8, 2\n",
    "                                 in_channels_right=12*filters, out_channels_right=2*filters) # 12, 2\n",
    "        self.cell_8 = NormalCell(in_channels_left=12*filters, out_channels_left=2*filters, # 12, 2\n",
    "                                 in_channels_right=12*filters, out_channels_right=2*filters) # 12, 2\n",
    "        self.cell_9 = NormalCell(in_channels_left=12*filters, out_channels_left=2*filters, # 12, 2\n",
    "                                 in_channels_right=12*filters, out_channels_right=2*filters) # 12, 2\n",
    "\n",
    "        self.reduction_cell_1 = ReductionCell1(in_channels_left=12*filters, out_channels_left=4*filters, # 12, 4\n",
    "                                               in_channels_right=12*filters, out_channels_right=4*filters) # 12, 4\n",
    "\n",
    "        self.cell_12 = FirstCell(in_channels_left=12*filters, out_channels_left=2*filters, # 12, 2\n",
    "                                 in_channels_right=16*filters, out_channels_right=4*filters) # 16, 4\n",
    "        self.cell_13 = NormalCell(in_channels_left=16*filters, out_channels_left=4*filters, # 16, 4\n",
    "                                  in_channels_right=24*filters, out_channels_right=4*filters) # 24, 4\n",
    "        self.cell_14 = NormalCell(in_channels_left=24*filters, out_channels_left=4*filters, # 24, 4\n",
    "                                  in_channels_right=24*filters, out_channels_right=4*filters) # 24, 4\n",
    "        self.cell_15 = NormalCell(in_channels_left=24*filters, out_channels_left=4*filters, # 24, 4\n",
    "                                  in_channels_right=24*filters, out_channels_right=4*filters) # 24, 4\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        self.avg_pool = nn.AvgPool2d(7, stride=1, padding=0)\n",
    "        self.dropout = nn.Dropout()\n",
    "        self.last_linear = nn.Linear(24*filters, self.num_classes)\n",
    "\n",
    "    def features(self, input):\n",
    "        x_conv0 = self.conv0(input)\n",
    "        x_stem_0 = self.cell_stem_0(x_conv0)\n",
    "        x_stem_1 = self.cell_stem_1(x_conv0, x_stem_0)\n",
    "\n",
    "        x_cell_0 = self.cell_0(x_stem_1, x_stem_0)\n",
    "        x_cell_1 = self.cell_1(x_cell_0, x_stem_1)\n",
    "        x_cell_2 = self.cell_2(x_cell_1, x_cell_0)\n",
    "        x_cell_3 = self.cell_3(x_cell_2, x_cell_1)\n",
    "\n",
    "        x_reduction_cell_0 = self.reduction_cell_0(x_cell_3, x_cell_2)\n",
    "\n",
    "        x_cell_6 = self.cell_6(x_reduction_cell_0, x_cell_3)\n",
    "        x_cell_7 = self.cell_7(x_cell_6, x_reduction_cell_0)\n",
    "        x_cell_8 = self.cell_8(x_cell_7, x_cell_6)\n",
    "        x_cell_9 = self.cell_9(x_cell_8, x_cell_7)\n",
    "\n",
    "        x_reduction_cell_1 = self.reduction_cell_1(x_cell_9, x_cell_8)\n",
    "\n",
    "        x_cell_12 = self.cell_12(x_reduction_cell_1, x_cell_9)\n",
    "        x_cell_13 = self.cell_13(x_cell_12, x_reduction_cell_1)\n",
    "        x_cell_14 = self.cell_14(x_cell_13, x_cell_12)\n",
    "        x_cell_15 = self.cell_15(x_cell_14, x_cell_13)\n",
    "        return x_cell_15\n",
    "\n",
    "    def logits(self, features):\n",
    "        x = self.relu(features)\n",
    "        x = self.avg_pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.dropout(x)\n",
    "        x = self.last_linear(x)\n",
    "        return x\n",
    "\n",
    "    def forward(self, input):\n",
    "        x = self.features(input)\n",
    "        x = self.logits(x)\n",
    "        return x\n",
    "\n",
    "    #-#-# You do NOT have to modify the code below this line. #-#-#\n",
    "\n",
    "# instantiate the CNN\n",
    "model_NasNetAMobile = NASNetAMobile(num_classes=133)\n",
    "\n",
    "# move tensors to GPU if CUDA is available\n",
    "if use_cuda:\n",
    "    model_NasNetAMobile.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion_NasNetAMobile = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer_NasNetAMobile = optim.SGD(model_NasNetAMobile.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 : 0 train_loss: tensor(3.8846, device='cuda:0')\n",
      "1 : 200 train_loss: tensor(4.0166, device='cuda:0')\n",
      "1 : 400 train_loss: tensor(4.0126, device='cuda:0')\n",
      "Elapsed Epoch Training Time: 181.81515288352966\n",
      "Epoch: 1 \tTraining Loss: 4.015560 \tValidation Loss: 4.093968\n",
      "Validation loss decreased (inf --> 4.093968).  Saving model ...\n",
      "2 : 0 train_loss: tensor(3.7928, device='cuda:0')\n",
      "2 : 200 train_loss: tensor(3.9425, device='cuda:0')\n",
      "2 : 400 train_loss: tensor(3.9319, device='cuda:0')\n",
      "Elapsed Epoch Training Time: 183.66796374320984\n",
      "Epoch: 2 \tTraining Loss: 3.933797 \tValidation Loss: 4.395972\n",
      "3 : 0 train_loss: tensor(3.8606, device='cuda:0')\n",
      "3 : 200 train_loss: tensor(3.8199, device='cuda:0')\n",
      "3 : 400 train_loss: tensor(3.8228, device='cuda:0')\n",
      "Elapsed Epoch Training Time: 184.02156233787537\n",
      "Epoch: 3 \tTraining Loss: 3.826439 \tValidation Loss: 4.378470\n",
      "4 : 0 train_loss: tensor(3.9218, device='cuda:0')\n",
      "4 : 200 train_loss: tensor(3.7214, device='cuda:0')\n",
      "4 : 400 train_loss: tensor(3.7200, device='cuda:0')\n",
      "Elapsed Epoch Training Time: 187.25531554222107\n",
      "Epoch: 4 \tTraining Loss: 3.717348 \tValidation Loss: 3.894355\n",
      "Validation loss decreased (4.093968 --> 3.894355).  Saving model ...\n",
      "5 : 0 train_loss: tensor(3.4710, device='cuda:0')\n",
      "5 : 200 train_loss: tensor(3.6108, device='cuda:0')\n",
      "5 : 400 train_loss: tensor(3.6227, device='cuda:0')\n",
      "Elapsed Epoch Training Time: 185.94623923301697\n",
      "Epoch: 5 \tTraining Loss: 3.618740 \tValidation Loss: 3.993497\n",
      "6 : 0 train_loss: tensor(3.3263, device='cuda:0')\n",
      "6 : 200 train_loss: tensor(3.5296, device='cuda:0')\n",
      "6 : 400 train_loss: tensor(3.5152, device='cuda:0')\n",
      "Elapsed Epoch Training Time: 185.39100098609924\n",
      "Epoch: 6 \tTraining Loss: 3.514714 \tValidation Loss: 3.781954\n",
      "Validation loss decreased (3.894355 --> 3.781954).  Saving model ...\n",
      "7 : 0 train_loss: tensor(3.7538, device='cuda:0')\n",
      "7 : 200 train_loss: tensor(3.3952, device='cuda:0')\n",
      "7 : 400 train_loss: tensor(3.4204, device='cuda:0')\n",
      "Elapsed Epoch Training Time: 185.01502108573914\n",
      "Epoch: 7 \tTraining Loss: 3.420090 \tValidation Loss: 4.019055\n",
      "8 : 0 train_loss: tensor(3.5628, device='cuda:0')\n",
      "8 : 200 train_loss: tensor(3.2724, device='cuda:0')\n",
      "8 : 400 train_loss: tensor(3.3081, device='cuda:0')\n",
      "Elapsed Epoch Training Time: 186.5977177619934\n",
      "Epoch: 8 \tTraining Loss: 3.310977 \tValidation Loss: 3.738063\n",
      "Validation loss decreased (3.781954 --> 3.738063).  Saving model ...\n",
      "9 : 0 train_loss: tensor(3.0916, device='cuda:0')\n",
      "9 : 200 train_loss: tensor(3.1844, device='cuda:0')\n",
      "9 : 400 train_loss: tensor(3.2204, device='cuda:0')\n",
      "Elapsed Epoch Training Time: 184.6981189250946\n",
      "Epoch: 9 \tTraining Loss: 3.218884 \tValidation Loss: 3.709413\n",
      "Validation loss decreased (3.738063 --> 3.709413).  Saving model ...\n",
      "10 : 0 train_loss: tensor(3.1867, device='cuda:0')\n",
      "10 : 200 train_loss: tensor(3.0425, device='cuda:0')\n",
      "10 : 400 train_loss: tensor(3.0817, device='cuda:0')\n",
      "Elapsed Epoch Training Time: 184.12770009040833\n",
      "Epoch: 10 \tTraining Loss: 3.082708 \tValidation Loss: 4.035333\n",
      "11 : 0 train_loss: tensor(3.1036, device='cuda:0')\n",
      "11 : 200 train_loss: tensor(2.9799, device='cuda:0')\n",
      "11 : 400 train_loss: tensor(2.9894, device='cuda:0')\n",
      "Elapsed Epoch Training Time: 182.7216715812683\n",
      "Epoch: 11 \tTraining Loss: 2.987781 \tValidation Loss: 4.232343\n",
      "12 : 0 train_loss: tensor(2.8583, device='cuda:0')\n",
      "12 : 200 train_loss: tensor(2.8282, device='cuda:0')\n",
      "12 : 400 train_loss: tensor(2.8686, device='cuda:0')\n",
      "Elapsed Epoch Training Time: 187.51201820373535\n",
      "Epoch: 12 \tTraining Loss: 2.871396 \tValidation Loss: 3.799222\n",
      "13 : 0 train_loss: tensor(2.9842, device='cuda:0')\n",
      "13 : 200 train_loss: tensor(2.7015, device='cuda:0')\n",
      "13 : 400 train_loss: tensor(2.7417, device='cuda:0')\n",
      "Elapsed Epoch Training Time: 190.3646035194397\n",
      "Epoch: 13 \tTraining Loss: 2.743073 \tValidation Loss: 4.606892\n",
      "14 : 0 train_loss: tensor(2.0574, device='cuda:0')\n",
      "14 : 200 train_loss: tensor(2.5701, device='cuda:0')\n",
      "14 : 400 train_loss: tensor(2.6322, device='cuda:0')\n",
      "Elapsed Epoch Training Time: 191.12604594230652\n",
      "Epoch: 14 \tTraining Loss: 2.636600 \tValidation Loss: 3.523544\n",
      "Validation loss decreased (3.709413 --> 3.523544).  Saving model ...\n",
      "15 : 0 train_loss: tensor(2.4308, device='cuda:0')\n",
      "15 : 200 train_loss: tensor(2.4497, device='cuda:0')\n",
      "15 : 400 train_loss: tensor(2.4985, device='cuda:0')\n",
      "Elapsed Epoch Training Time: 181.73647212982178\n",
      "Epoch: 15 \tTraining Loss: 2.501900 \tValidation Loss: 4.698419\n",
      "16 : 0 train_loss: tensor(2.1824, device='cuda:0')\n",
      "16 : 200 train_loss: tensor(2.3371, device='cuda:0')\n",
      "16 : 400 train_loss: tensor(2.3754, device='cuda:0')\n",
      "Elapsed Epoch Training Time: 184.00996947288513\n",
      "Epoch: 16 \tTraining Loss: 2.381204 \tValidation Loss: 3.691011\n",
      "17 : 0 train_loss: tensor(2.4262, device='cuda:0')\n",
      "17 : 200 train_loss: tensor(2.2030, device='cuda:0')\n",
      "17 : 400 train_loss: tensor(2.2767, device='cuda:0')\n",
      "Elapsed Epoch Training Time: 184.60149455070496\n",
      "Epoch: 17 \tTraining Loss: 2.283833 \tValidation Loss: 3.929769\n",
      "18 : 0 train_loss: tensor(2.4964, device='cuda:0')\n",
      "18 : 200 train_loss: tensor(2.0868, device='cuda:0')\n",
      "18 : 400 train_loss: tensor(2.1563, device='cuda:0')\n",
      "Elapsed Epoch Training Time: 184.65692138671875\n",
      "Epoch: 18 \tTraining Loss: 2.163804 \tValidation Loss: 4.434538\n",
      "19 : 0 train_loss: tensor(1.4855, device='cuda:0')\n",
      "19 : 200 train_loss: tensor(1.9164, device='cuda:0')\n",
      "19 : 400 train_loss: tensor(2.0141, device='cuda:0')\n",
      "Elapsed Epoch Training Time: 185.3594446182251\n",
      "Epoch: 19 \tTraining Loss: 2.027212 \tValidation Loss: 4.033458\n",
      "20 : 0 train_loss: tensor(2.3327, device='cuda:0')\n",
      "20 : 200 train_loss: tensor(1.8476, device='cuda:0')\n",
      "20 : 400 train_loss: tensor(1.9051, device='cuda:0')\n",
      "Elapsed Epoch Training Time: 185.949524641037\n",
      "Epoch: 20 \tTraining Loss: 1.905896 \tValidation Loss: 4.105760\n"
     ]
    }
   ],
   "source": [
    "model_NasNetAMobile.load_state_dict(torch.load('model_NasNetAMobile.pt'))\n",
    "\n",
    "model_NasNetAMobile = train(20, loaders_NasNetAMobile, model_NasNetAMobile, optimizer_NasNetAMobile, \n",
    "                      criterion_NasNetAMobile, use_cuda, 'model_NasNetAMobile.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 4.221585\n",
      "\n",
      "\n",
      "Test Accuracy: 13% (117/836)\n"
     ]
    }
   ],
   "source": [
    "test(loaders_NasNetAMobile, model_NasNetAMobile, criterion_NasNetAMobile, use_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 3.491812\n",
      "\n",
      "\n",
      "Test Accuracy: 17% (146/836)\n"
     ]
    }
   ],
   "source": [
    "# load the model that got the best validation accuracy\n",
    "model_NasNetAMobile.load_state_dict(torch.load('model_NasNetAMobile.pt'))\n",
    "test(loaders_NasNetAMobile, model_NasNetAMobile, criterion_NasNetAMobile, use_cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SENet-154 and NasNet (Large) to Classify Dog Breeds (using Transfer Learning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SE-Net154"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SE-Net154\n",
    "batch_size = 64\n",
    "\n",
    "train_dir = r\"D:\\Python\\deep-learning-v2-pytorch\\project-dog-classification\\dogImages\\train\"\n",
    "valid_dir = r\"D:\\Python\\deep-learning-v2-pytorch\\project-dog-classification\\dogImages\\valid\"\n",
    "test_dir = r\"D:\\Python\\deep-learning-v2-pytorch\\project-dog-classification\\dogImages\\test\"\n",
    "\n",
    "transform_transfer = transforms.Compose([transforms.Resize((224,224)), \n",
    "                                transforms.ToTensor(), \n",
    "                                transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])])\n",
    "\n",
    "train_set_transfer = datasets.ImageFolder(train_dir, transform=transform_transfer)\n",
    "train_loader_transfer = torch.utils.data.DataLoader(train_set_transfer, shuffle=True, batch_size=batch_size)\n",
    "#train_images, train_labels = next(iter(train_loader))\n",
    "\n",
    "valid_set_transfer = datasets.ImageFolder(valid_dir, transform=transform_transfer)\n",
    "valid_loader_transfer = torch.utils.data.DataLoader(valid_set_transfer, shuffle=True, batch_size=batch_size)\n",
    "#valid_images, valid_labels = next(iter(valid_loader))\n",
    "\n",
    "test_set_transfer = datasets.ImageFolder(test_dir, transform=transform_transfer)\n",
    "test_loader_transfer = torch.utils.data.DataLoader(test_set_transfer, shuffle=True, batch_size=batch_size)\n",
    "#test_images, test_labels = next(iter(test_loader))\n",
    "\n",
    "loaders_transfer={'train':train_loader_transfer, 'valid': valid_loader_transfer, 'test':test_loader_transfer}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model architecture \n",
    "from __future__ import print_function, division, absolute_import\n",
    "from collections import OrderedDict\n",
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "from torch.utils import model_zoo\n",
    "\n",
    "__all__ = ['SENet', 'senet154', 'se_resnet50', 'se_resnet101', 'se_resnet152',\n",
    "           'se_resnext50_32x4d', 'se_resnext101_32x4d']\n",
    "\n",
    "pretrained_settings = {\n",
    "    'senet154': {\n",
    "        'imagenet': {\n",
    "            'url': 'http://data.lip6.fr/cadene/pretrainedmodels/senet154-c7b49a05.pth',\n",
    "            'input_space': 'RGB',\n",
    "            'input_size': [3, 224, 224],\n",
    "            'input_range': [0, 1],\n",
    "            'mean': [0.485, 0.456, 0.406],\n",
    "            'std': [0.229, 0.224, 0.225],\n",
    "            'num_classes': 1000\n",
    "        }\n",
    "    },\n",
    "    'se_resnet50': {\n",
    "        'imagenet': {\n",
    "            'url': 'http://data.lip6.fr/cadene/pretrainedmodels/se_resnet50-ce0d4300.pth',\n",
    "            'input_space': 'RGB',\n",
    "            'input_size': [3, 224, 224],\n",
    "            'input_range': [0, 1],\n",
    "            'mean': [0.485, 0.456, 0.406],\n",
    "            'std': [0.229, 0.224, 0.225],\n",
    "            'num_classes': 1000\n",
    "        }\n",
    "    },\n",
    "    'se_resnet101': {\n",
    "        'imagenet': {\n",
    "            'url': 'http://data.lip6.fr/cadene/pretrainedmodels/se_resnet101-7e38fcc6.pth',\n",
    "            'input_space': 'RGB',\n",
    "            'input_size': [3, 224, 224],\n",
    "            'input_range': [0, 1],\n",
    "            'mean': [0.485, 0.456, 0.406],\n",
    "            'std': [0.229, 0.224, 0.225],\n",
    "            'num_classes': 1000\n",
    "        }\n",
    "    },\n",
    "    'se_resnet152': {\n",
    "        'imagenet': {\n",
    "            'url': 'http://data.lip6.fr/cadene/pretrainedmodels/se_resnet152-d17c99b7.pth',\n",
    "            'input_space': 'RGB',\n",
    "            'input_size': [3, 224, 224],\n",
    "            'input_range': [0, 1],\n",
    "            'mean': [0.485, 0.456, 0.406],\n",
    "            'std': [0.229, 0.224, 0.225],\n",
    "            'num_classes': 1000\n",
    "        }\n",
    "    },\n",
    "    'se_resnext50_32x4d': {\n",
    "        'imagenet': {\n",
    "            'url': 'http://data.lip6.fr/cadene/pretrainedmodels/se_resnext50_32x4d-a260b3a4.pth',\n",
    "            'input_space': 'RGB',\n",
    "            'input_size': [3, 224, 224],\n",
    "            'input_range': [0, 1],\n",
    "            'mean': [0.485, 0.456, 0.406],\n",
    "            'std': [0.229, 0.224, 0.225],\n",
    "            'num_classes': 1000\n",
    "        }\n",
    "    },\n",
    "    'se_resnext101_32x4d': {\n",
    "        'imagenet': {\n",
    "            'url': 'http://data.lip6.fr/cadene/pretrainedmodels/se_resnext101_32x4d-3b2fe3d8.pth',\n",
    "            'input_space': 'RGB',\n",
    "            'input_size': [3, 224, 224],\n",
    "            'input_range': [0, 1],\n",
    "            'mean': [0.485, 0.456, 0.406],\n",
    "            'std': [0.229, 0.224, 0.225],\n",
    "            'num_classes': 1000\n",
    "        }\n",
    "    },\n",
    "}\n",
    "\n",
    "\n",
    "class SEModule(nn.Module):\n",
    "\n",
    "    def __init__(self, channels, reduction):\n",
    "        super(SEModule, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc1 = nn.Conv2d(channels, channels // reduction, kernel_size=1,\n",
    "                             padding=0)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.fc2 = nn.Conv2d(channels // reduction, channels, kernel_size=1,\n",
    "                             padding=0)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        module_input = x\n",
    "        x = self.avg_pool(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return module_input * x\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    \"\"\"\n",
    "    Base class for bottlenecks that implements `forward()` method.\n",
    "    \"\"\"\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out = self.se_module(out) + residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class SEBottleneck(Bottleneck):\n",
    "    \"\"\"\n",
    "    Bottleneck for SENet154.\n",
    "    \"\"\"\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, groups, reduction, stride=1,\n",
    "                 downsample=None):\n",
    "        super(SEBottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(inplanes, planes * 2, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes * 2)\n",
    "        self.conv2 = nn.Conv2d(planes * 2, planes * 4, kernel_size=3,\n",
    "                               stride=stride, padding=1, groups=groups,\n",
    "                               bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes * 4)\n",
    "        self.conv3 = nn.Conv2d(planes * 4, planes * 4, kernel_size=1,\n",
    "                               bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(planes * 4)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.se_module = SEModule(planes * 4, reduction=reduction)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "\n",
    "class SEResNetBottleneck(Bottleneck):\n",
    "    \"\"\"\n",
    "    ResNet bottleneck with a Squeeze-and-Excitation module. It follows Caffe\n",
    "    implementation and uses `stride=stride` in `conv1` and not in `conv2`\n",
    "    (the latter is used in the torchvision implementation of ResNet).\n",
    "    \"\"\"\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, groups, reduction, stride=1,\n",
    "                 downsample=None):\n",
    "        super(SEResNetBottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False,\n",
    "                               stride=stride)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, padding=1,\n",
    "                               groups=groups, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(planes * 4)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.se_module = SEModule(planes * 4, reduction=reduction)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "\n",
    "class SEResNeXtBottleneck(Bottleneck):\n",
    "    \"\"\"\n",
    "    ResNeXt bottleneck type C with a Squeeze-and-Excitation module.\n",
    "    \"\"\"\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, groups, reduction, stride=1,\n",
    "                 downsample=None, base_width=4):\n",
    "        super(SEResNeXtBottleneck, self).__init__()\n",
    "        width = math.floor(planes * (base_width / 64)) * groups\n",
    "        self.conv1 = nn.Conv2d(inplanes, width, kernel_size=1, bias=False,\n",
    "                               stride=1)\n",
    "        self.bn1 = nn.BatchNorm2d(width)\n",
    "        self.conv2 = nn.Conv2d(width, width, kernel_size=3, stride=stride,\n",
    "                               padding=1, groups=groups, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(width)\n",
    "        self.conv3 = nn.Conv2d(width, planes * 4, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(planes * 4)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.se_module = SEModule(planes * 4, reduction=reduction)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "\n",
    "class SENet(nn.Module):\n",
    "\n",
    "    def __init__(self, block, layers, groups, reduction, dropout_p=0.2,\n",
    "                 inplanes=128, input_3x3=True, downsample_kernel_size=3,\n",
    "                 downsample_padding=1, num_classes=1000):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        block (nn.Module): Bottleneck class.\n",
    "            - For SENet154: SEBottleneck\n",
    "            - For SE-ResNet models: SEResNetBottleneck\n",
    "            - For SE-ResNeXt models:  SEResNeXtBottleneck\n",
    "        layers (list of ints): Number of residual blocks for 4 layers of the\n",
    "            network (layer1...layer4).\n",
    "        groups (int): Number of groups for the 3x3 convolution in each\n",
    "            bottleneck block.\n",
    "            - For SENet154: 64\n",
    "            - For SE-ResNet models: 1\n",
    "            - For SE-ResNeXt models:  32\n",
    "        reduction (int): Reduction ratio for Squeeze-and-Excitation modules.\n",
    "            - For all models: 16\n",
    "        dropout_p (float or None): Drop probability for the Dropout layer.\n",
    "            If `None` the Dropout layer is not used.\n",
    "            - For SENet154: 0.2\n",
    "            - For SE-ResNet models: None\n",
    "            - For SE-ResNeXt models: None\n",
    "        inplanes (int):  Number of input channels for layer1.\n",
    "            - For SENet154: 128\n",
    "            - For SE-ResNet models: 64\n",
    "            - For SE-ResNeXt models: 64\n",
    "        input_3x3 (bool): If `True`, use three 3x3 convolutions instead of\n",
    "            a single 7x7 convolution in layer0.\n",
    "            - For SENet154: True\n",
    "            - For SE-ResNet models: False\n",
    "            - For SE-ResNeXt models: False\n",
    "        downsample_kernel_size (int): Kernel size for downsampling convolutions\n",
    "            in layer2, layer3 and layer4.\n",
    "            - For SENet154: 3\n",
    "            - For SE-ResNet models: 1\n",
    "            - For SE-ResNeXt models: 1\n",
    "        downsample_padding (int): Padding for downsampling convolutions in\n",
    "            layer2, layer3 and layer4.\n",
    "            - For SENet154: 1\n",
    "            - For SE-ResNet models: 0\n",
    "            - For SE-ResNeXt models: 0\n",
    "        num_classes (int): Number of outputs in `last_linear` layer.\n",
    "            - For all models: 1000\n",
    "        \"\"\"\n",
    "        super(SENet, self).__init__()\n",
    "        self.inplanes = inplanes\n",
    "        if input_3x3:\n",
    "            layer0_modules = [\n",
    "                ('conv1', nn.Conv2d(3, 64, 3, stride=2, padding=1,\n",
    "                                    bias=False)),\n",
    "                ('bn1', nn.BatchNorm2d(64)),\n",
    "                ('relu1', nn.ReLU(inplace=True)),\n",
    "                ('conv2', nn.Conv2d(64, 64, 3, stride=1, padding=1,\n",
    "                                    bias=False)),\n",
    "                ('bn2', nn.BatchNorm2d(64)),\n",
    "                ('relu2', nn.ReLU(inplace=True)),\n",
    "                ('conv3', nn.Conv2d(64, inplanes, 3, stride=1, padding=1,\n",
    "                                    bias=False)),\n",
    "                ('bn3', nn.BatchNorm2d(inplanes)),\n",
    "                ('relu3', nn.ReLU(inplace=True)),\n",
    "            ]\n",
    "        else:\n",
    "            layer0_modules = [\n",
    "                ('conv1', nn.Conv2d(3, inplanes, kernel_size=7, stride=2,\n",
    "                                    padding=3, bias=False)),\n",
    "                ('bn1', nn.BatchNorm2d(inplanes)),\n",
    "                ('relu1', nn.ReLU(inplace=True)),\n",
    "            ]\n",
    "        # To preserve compatibility with Caffe weights `ceil_mode=True`\n",
    "        # is used instead of `padding=1`.\n",
    "        layer0_modules.append(('pool', nn.MaxPool2d(3, stride=2,\n",
    "                                                    ceil_mode=True)))\n",
    "        self.layer0 = nn.Sequential(OrderedDict(layer0_modules))\n",
    "        self.layer1 = self._make_layer(\n",
    "            block,\n",
    "            planes=64,\n",
    "            blocks=layers[0],\n",
    "            groups=groups,\n",
    "            reduction=reduction,\n",
    "            downsample_kernel_size=1,\n",
    "            downsample_padding=0\n",
    "        )\n",
    "        self.layer2 = self._make_layer(\n",
    "            block,\n",
    "            planes=128,\n",
    "            blocks=layers[1],\n",
    "            stride=2,\n",
    "            groups=groups,\n",
    "            reduction=reduction,\n",
    "            downsample_kernel_size=downsample_kernel_size,\n",
    "            downsample_padding=downsample_padding\n",
    "        )\n",
    "        self.layer3 = self._make_layer(\n",
    "            block,\n",
    "            planes=256,\n",
    "            blocks=layers[2],\n",
    "            stride=2,\n",
    "            groups=groups,\n",
    "            reduction=reduction,\n",
    "            downsample_kernel_size=downsample_kernel_size,\n",
    "            downsample_padding=downsample_padding\n",
    "        )\n",
    "        self.layer4 = self._make_layer(\n",
    "            block,\n",
    "            planes=512,\n",
    "            blocks=layers[3],\n",
    "            stride=2,\n",
    "            groups=groups,\n",
    "            reduction=reduction,\n",
    "            downsample_kernel_size=downsample_kernel_size,\n",
    "            downsample_padding=downsample_padding\n",
    "        )\n",
    "        self.avg_pool = nn.AvgPool2d(7, stride=1)\n",
    "        self.dropout = nn.Dropout(dropout_p) if dropout_p is not None else None\n",
    "        self.last_linear = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, groups, reduction, stride=1,\n",
    "                    downsample_kernel_size=1, downsample_padding=0):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
    "                          kernel_size=downsample_kernel_size, stride=stride,\n",
    "                          padding=downsample_padding, bias=False),\n",
    "                nn.BatchNorm2d(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, groups, reduction, stride,\n",
    "                            downsample))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes, groups, reduction))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def features(self, x):\n",
    "        x = self.layer0(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        return x\n",
    "\n",
    "    def logits(self, x):\n",
    "        x = self.avg_pool(x)\n",
    "        if self.dropout is not None:\n",
    "            x = self.dropout(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.last_linear(x)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.logits(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def initialize_pretrained_model(model, num_classes, settings):\n",
    "    assert num_classes == settings['num_classes'], \\\n",
    "        'num_classes should be {}, but is {}'.format(\n",
    "            settings['num_classes'], num_classes)\n",
    "    model.load_state_dict(model_zoo.load_url(settings['url']))\n",
    "    model.input_space = settings['input_space']\n",
    "    model.input_size = settings['input_size']\n",
    "    model.input_range = settings['input_range']\n",
    "    model.mean = settings['mean']\n",
    "    model.std = settings['std']\n",
    "\n",
    "\n",
    "def senet154(num_classes=1000, pretrained='imagenet'):\n",
    "    model = SENet(SEBottleneck, [3, 8, 36, 3], groups=64, reduction=16,\n",
    "                  dropout_p=0.2, num_classes=num_classes)\n",
    "    if pretrained is not None:\n",
    "        settings = pretrained_settings['senet154'][pretrained]\n",
    "        initialize_pretrained_model(model, num_classes, settings)\n",
    "    return model\n",
    "\n",
    "\n",
    "def se_resnet50(num_classes=1000, pretrained='imagenet'):\n",
    "    model = SENet(SEResNetBottleneck, [3, 4, 6, 3], groups=1, reduction=16,\n",
    "                  dropout_p=None, inplanes=64, input_3x3=False,\n",
    "                  downsample_kernel_size=1, downsample_padding=0,\n",
    "                  num_classes=num_classes)\n",
    "    if pretrained is not None:\n",
    "        settings = pretrained_settings['se_resnet50'][pretrained]\n",
    "        initialize_pretrained_model(model, num_classes, settings)\n",
    "    return model\n",
    "\n",
    "\n",
    "def se_resnet101(num_classes=1000, pretrained='imagenet'):\n",
    "    model = SENet(SEResNetBottleneck, [3, 4, 23, 3], groups=1, reduction=16,\n",
    "                  dropout_p=None, inplanes=64, input_3x3=False,\n",
    "                  downsample_kernel_size=1, downsample_padding=0,\n",
    "                  num_classes=num_classes)\n",
    "    if pretrained is not None:\n",
    "        settings = pretrained_settings['se_resnet101'][pretrained]\n",
    "        initialize_pretrained_model(model, num_classes, settings)\n",
    "    return model\n",
    "\n",
    "\n",
    "def se_resnet152(num_classes=1000, pretrained='imagenet'):\n",
    "    model = SENet(SEResNetBottleneck, [3, 8, 36, 3], groups=1, reduction=16,\n",
    "                  dropout_p=None, inplanes=64, input_3x3=False,\n",
    "                  downsample_kernel_size=1, downsample_padding=0,\n",
    "                  num_classes=num_classes)\n",
    "    if pretrained is not None:\n",
    "        settings = pretrained_settings['se_resnet152'][pretrained]\n",
    "        initialize_pretrained_model(model, num_classes, settings)\n",
    "    return model\n",
    "\n",
    "\n",
    "def se_resnext50_32x4d(num_classes=1000, pretrained='imagenet'):\n",
    "    model = SENet(SEResNeXtBottleneck, [3, 4, 6, 3], groups=32, reduction=16,\n",
    "                  dropout_p=None, inplanes=64, input_3x3=False,\n",
    "                  downsample_kernel_size=1, downsample_padding=0,\n",
    "                  num_classes=num_classes)\n",
    "    if pretrained is not None:\n",
    "        settings = pretrained_settings['se_resnext50_32x4d'][pretrained]\n",
    "        initialize_pretrained_model(model, num_classes, settings)\n",
    "    return model\n",
    "\n",
    "\n",
    "def se_resnext101_32x4d(num_classes=1000, pretrained='imagenet'):\n",
    "    model = SENet(SEResNeXtBottleneck, [3, 4, 23, 3], groups=32, reduction=16,\n",
    "                  dropout_p=None, inplanes=64, input_3x3=False,\n",
    "                  downsample_kernel_size=1, downsample_padding=0,\n",
    "                  num_classes=num_classes)\n",
    "    if pretrained is not None:\n",
    "        settings = pretrained_settings['se_resnext101_32x4d'][pretrained]\n",
    "        initialize_pretrained_model(model, num_classes, settings)\n",
    "    return model\n",
    "\n",
    "\n",
    "model_transfer = senet154(pretrained='imagenet')\n",
    "\n",
    "if use_cuda:\n",
    "    model_transfer = model_transfer.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SENet(\n",
       "  (layer0): Sequential(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu1): ReLU(inplace)\n",
       "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu2): ReLU(inplace)\n",
       "    (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu3): ReLU(inplace)\n",
       "    (pool): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
       "  )\n",
       "  (layer1): Sequential(\n",
       "    (0): SEBottleneck(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (se_module): SEModule(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc1): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU(inplace)\n",
       "        (fc2): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): SEBottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (se_module): SEModule(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc1): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU(inplace)\n",
       "        (fc2): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "    )\n",
       "    (2): SEBottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (se_module): SEModule(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc1): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU(inplace)\n",
       "        (fc2): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): SEBottleneck(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (se_module): SEModule(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc1): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU(inplace)\n",
       "        (fc2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): SEBottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (se_module): SEModule(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc1): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU(inplace)\n",
       "        (fc2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "    )\n",
       "    (2): SEBottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (se_module): SEModule(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc1): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU(inplace)\n",
       "        (fc2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "    )\n",
       "    (3): SEBottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (se_module): SEModule(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc1): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU(inplace)\n",
       "        (fc2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "    )\n",
       "    (4): SEBottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (se_module): SEModule(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc1): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU(inplace)\n",
       "        (fc2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "    )\n",
       "    (5): SEBottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (se_module): SEModule(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc1): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU(inplace)\n",
       "        (fc2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "    )\n",
       "    (6): SEBottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (se_module): SEModule(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc1): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU(inplace)\n",
       "        (fc2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "    )\n",
       "    (7): SEBottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (se_module): SEModule(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc1): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU(inplace)\n",
       "        (fc2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): SEBottleneck(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)\n",
       "      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (se_module): SEModule(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU(inplace)\n",
       "        (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): SEBottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
       "      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (se_module): SEModule(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU(inplace)\n",
       "        (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "    )\n",
       "    (2): SEBottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
       "      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (se_module): SEModule(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU(inplace)\n",
       "        (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "    )\n",
       "    (3): SEBottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
       "      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (se_module): SEModule(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU(inplace)\n",
       "        (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "    )\n",
       "    (4): SEBottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
       "      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (se_module): SEModule(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU(inplace)\n",
       "        (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "    )\n",
       "    (5): SEBottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
       "      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (se_module): SEModule(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU(inplace)\n",
       "        (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "    )\n",
       "    (6): SEBottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
       "      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (se_module): SEModule(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU(inplace)\n",
       "        (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "    )\n",
       "    (7): SEBottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
       "      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (se_module): SEModule(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU(inplace)\n",
       "        (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "    )\n",
       "    (8): SEBottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
       "      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (se_module): SEModule(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU(inplace)\n",
       "        (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "    )\n",
       "    (9): SEBottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
       "      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (se_module): SEModule(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU(inplace)\n",
       "        (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "    )\n",
       "    (10): SEBottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
       "      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (se_module): SEModule(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU(inplace)\n",
       "        (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "    )\n",
       "    (11): SEBottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
       "      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (se_module): SEModule(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU(inplace)\n",
       "        (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "    )\n",
       "    (12): SEBottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
       "      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (se_module): SEModule(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU(inplace)\n",
       "        (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "    )\n",
       "    (13): SEBottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
       "      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (se_module): SEModule(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU(inplace)\n",
       "        (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "    )\n",
       "    (14): SEBottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
       "      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (se_module): SEModule(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU(inplace)\n",
       "        (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "    )\n",
       "    (15): SEBottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
       "      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (se_module): SEModule(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU(inplace)\n",
       "        (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "    )\n",
       "    (16): SEBottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
       "      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (se_module): SEModule(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU(inplace)\n",
       "        (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "    )\n",
       "    (17): SEBottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
       "      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (se_module): SEModule(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU(inplace)\n",
       "        (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "    )\n",
       "    (18): SEBottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
       "      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (se_module): SEModule(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU(inplace)\n",
       "        (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "    )\n",
       "    (19): SEBottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
       "      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (se_module): SEModule(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU(inplace)\n",
       "        (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "    )\n",
       "    (20): SEBottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
       "      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (se_module): SEModule(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU(inplace)\n",
       "        (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "    )\n",
       "    (21): SEBottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
       "      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (se_module): SEModule(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU(inplace)\n",
       "        (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "    )\n",
       "    (22): SEBottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
       "      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (se_module): SEModule(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU(inplace)\n",
       "        (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "    )\n",
       "    (23): SEBottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
       "      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (se_module): SEModule(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU(inplace)\n",
       "        (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "    )\n",
       "    (24): SEBottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
       "      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (se_module): SEModule(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU(inplace)\n",
       "        (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "    )\n",
       "    (25): SEBottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
       "      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (se_module): SEModule(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU(inplace)\n",
       "        (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "    )\n",
       "    (26): SEBottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
       "      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (se_module): SEModule(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU(inplace)\n",
       "        (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "    )\n",
       "    (27): SEBottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
       "      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (se_module): SEModule(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU(inplace)\n",
       "        (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "    )\n",
       "    (28): SEBottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
       "      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (se_module): SEModule(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU(inplace)\n",
       "        (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "    )\n",
       "    (29): SEBottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
       "      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (se_module): SEModule(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU(inplace)\n",
       "        (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "    )\n",
       "    (30): SEBottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
       "      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (se_module): SEModule(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU(inplace)\n",
       "        (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "    )\n",
       "    (31): SEBottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
       "      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (se_module): SEModule(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU(inplace)\n",
       "        (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "    )\n",
       "    (32): SEBottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
       "      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (se_module): SEModule(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU(inplace)\n",
       "        (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "    )\n",
       "    (33): SEBottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
       "      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (se_module): SEModule(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU(inplace)\n",
       "        (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "    )\n",
       "    (34): SEBottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
       "      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (se_module): SEModule(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU(inplace)\n",
       "        (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "    )\n",
       "    (35): SEBottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
       "      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (se_module): SEModule(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU(inplace)\n",
       "        (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): SEBottleneck(\n",
       "      (conv1): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(1024, 2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)\n",
       "      (bn2): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (se_module): SEModule(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc1): Conv2d(2048, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU(inplace)\n",
       "        (fc2): Conv2d(128, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): SEBottleneck(\n",
       "      (conv1): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(1024, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
       "      (bn2): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (se_module): SEModule(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc1): Conv2d(2048, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU(inplace)\n",
       "        (fc2): Conv2d(128, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "    )\n",
       "    (2): SEBottleneck(\n",
       "      (conv1): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(1024, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
       "      (bn2): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (se_module): SEModule(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc1): Conv2d(2048, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU(inplace)\n",
       "        (fc2): Conv2d(128, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (avg_pool): AvgPool2d(kernel_size=7, stride=1, padding=0)\n",
       "  (dropout): Dropout(p=0.2)\n",
       "  (last_linear): Linear(in_features=2048, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_transfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "SENet154_feature_layers = [model_transfer.layer0.parameters(),\n",
    "                               model_transfer.layer1.parameters(),\n",
    "                               model_transfer.layer2.parameters(),\n",
    "                               model_transfer.layer3.parameters(),\n",
    "                               model_transfer.layer4.parameters()]\n",
    "\n",
    "for parameters in SENet154_feature_layers:\n",
    "    for param in parameters:\n",
    "        param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133\n"
     ]
    }
   ],
   "source": [
    "n_inputs = model_transfer.last_linear.in_features\n",
    "\n",
    "# add last linear layer (n_inputs -> 5 flower classes)\n",
    "# new layers automatically have requires_grad = True\n",
    "last_layer = nn.Linear(n_inputs, 133)\n",
    "\n",
    "model_transfer.last_linear = last_layer\n",
    "\n",
    "if use_cuda:\n",
    "    model_transfer.cuda()\n",
    "\n",
    "# check to see that your last layer produces the expected number of outputs\n",
    "print(model_transfer.last_linear.out_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion_transfer = nn.CrossEntropyLoss()\n",
    "optimizer_transfer = optim.SGD(model_transfer.last_linear.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 : 0 train_loss: tensor(5.0374, device='cuda:0')\n",
      "1 : 200 train_loss: tensor(3.8990, device='cuda:0')\n",
      "1 : 400 train_loss: tensor(3.1161, device='cuda:0')\n",
      "Elapsed Epoch Training Time: 196.9351155757904\n",
      "Epoch: 1 \tTraining Loss: 3.062150 \tValidation Loss: 1.385900\n",
      "Validation loss decreased (inf --> 1.385900).  Saving model ...\n",
      "2 : 0 train_loss: tensor(1.4919, device='cuda:0')\n",
      "2 : 200 train_loss: tensor(1.3825, device='cuda:0')\n",
      "2 : 400 train_loss: tensor(1.2102, device='cuda:0')\n",
      "Elapsed Epoch Training Time: 203.80352592468262\n",
      "Epoch: 2 \tTraining Loss: 1.198206 \tValidation Loss: 0.702694\n",
      "Validation loss decreased (1.385900 --> 0.702694).  Saving model ...\n",
      "3 : 0 train_loss: tensor(0.8345, device='cuda:0')\n",
      "3 : 200 train_loss: tensor(0.8172, device='cuda:0')\n",
      "3 : 400 train_loss: tensor(0.7529, device='cuda:0')\n",
      "Elapsed Epoch Training Time: 204.196204662323\n",
      "Epoch: 3 \tTraining Loss: 0.750162 \tValidation Loss: 0.548016\n",
      "Validation loss decreased (0.702694 --> 0.548016).  Saving model ...\n",
      "4 : 0 train_loss: tensor(0.4983, device='cuda:0')\n",
      "4 : 200 train_loss: tensor(0.6109, device='cuda:0')\n",
      "4 : 400 train_loss: tensor(0.5969, device='cuda:0')\n",
      "Elapsed Epoch Training Time: 204.005610704422\n",
      "Epoch: 4 \tTraining Loss: 0.597450 \tValidation Loss: 0.474213\n",
      "Validation loss decreased (0.548016 --> 0.474213).  Saving model ...\n",
      "5 : 0 train_loss: tensor(0.7605, device='cuda:0')\n",
      "5 : 200 train_loss: tensor(0.5295, device='cuda:0')\n",
      "5 : 400 train_loss: tensor(0.5218, device='cuda:0')\n",
      "Elapsed Epoch Training Time: 204.85872769355774\n",
      "Epoch: 5 \tTraining Loss: 0.519276 \tValidation Loss: 0.455015\n",
      "Validation loss decreased (0.474213 --> 0.455015).  Saving model ...\n",
      "6 : 0 train_loss: tensor(0.6148, device='cuda:0')\n",
      "6 : 200 train_loss: tensor(0.4709, device='cuda:0')\n",
      "6 : 400 train_loss: tensor(0.4549, device='cuda:0')\n",
      "Elapsed Epoch Training Time: 204.2246596813202\n",
      "Epoch: 6 \tTraining Loss: 0.453796 \tValidation Loss: 0.431987\n",
      "Validation loss decreased (0.455015 --> 0.431987).  Saving model ...\n",
      "7 : 0 train_loss: tensor(0.5594, device='cuda:0')\n",
      "7 : 200 train_loss: tensor(0.4181, device='cuda:0')\n",
      "7 : 400 train_loss: tensor(0.4169, device='cuda:0')\n",
      "Elapsed Epoch Training Time: 204.78680801391602\n",
      "Epoch: 7 \tTraining Loss: 0.415845 \tValidation Loss: 0.392891\n",
      "Validation loss decreased (0.431987 --> 0.392891).  Saving model ...\n",
      "8 : 0 train_loss: tensor(0.4817, device='cuda:0')\n",
      "8 : 200 train_loss: tensor(0.3896, device='cuda:0')\n",
      "8 : 400 train_loss: tensor(0.3871, device='cuda:0')\n",
      "Elapsed Epoch Training Time: 204.54016661643982\n",
      "Epoch: 8 \tTraining Loss: 0.386726 \tValidation Loss: 0.402157\n",
      "9 : 0 train_loss: tensor(0.2466, device='cuda:0')\n",
      "9 : 200 train_loss: tensor(0.3735, device='cuda:0')\n",
      "9 : 400 train_loss: tensor(0.3754, device='cuda:0')\n",
      "Elapsed Epoch Training Time: 204.49299669265747\n",
      "Epoch: 9 \tTraining Loss: 0.374904 \tValidation Loss: 0.388407\n",
      "Validation loss decreased (0.392891 --> 0.388407).  Saving model ...\n",
      "10 : 0 train_loss: tensor(0.2383, device='cuda:0')\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-70-6f7324371302>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mn_epochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mmodel_transfer\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloaders_transfer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_transfer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer_transfer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion_transfer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse_cuda\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'model_transfer.pt'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-4-614070b0eafc>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(n_epochs, loaders, model, optimizer, criterion, use_cuda, save_path)\u001b[0m\n\u001b[0;32m     25\u001b[0m             \u001b[1;31m# move to GPU\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0muse_cuda\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m                 \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m             \u001b[1;31m## find the loss and update the model parameters accordingly\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m             \u001b[1;31m## record the average training loss, using something like\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "n_epochs = 20\n",
    "\n",
    "model_transfer =  train(n_epochs, loaders_transfer, model_transfer, optimizer_transfer, criterion_transfer, use_cuda, 'model_transfer.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paused and batch size increased in aim for greater efficiency. 11 more epochs performed to make 20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 : 0 train_loss: tensor(0.2222, device='cuda:0')\n",
      "Elapsed Epoch Training Time: 186.15393257141113\n",
      "Epoch: 1 \tTraining Loss: 0.275660 \tValidation Loss: 0.432712\n",
      "Validation loss decreased (inf --> 0.432712).  Saving model ...\n",
      "2 : 0 train_loss: tensor(0.2746, device='cuda:0')\n",
      "Elapsed Epoch Training Time: 196.0345950126648\n",
      "Epoch: 2 \tTraining Loss: 0.268347 \tValidation Loss: 0.339280\n",
      "Validation loss decreased (0.432712 --> 0.339280).  Saving model ...\n",
      "3 : 0 train_loss: tensor(0.2621, device='cuda:0')\n",
      "Elapsed Epoch Training Time: 195.0541229248047\n",
      "Epoch: 3 \tTraining Loss: 0.263972 \tValidation Loss: 0.377662\n",
      "4 : 0 train_loss: tensor(0.2727, device='cuda:0')\n",
      "Elapsed Epoch Training Time: 193.12825345993042\n",
      "Epoch: 4 \tTraining Loss: 0.259358 \tValidation Loss: 0.337423\n",
      "Validation loss decreased (0.339280 --> 0.337423).  Saving model ...\n",
      "5 : 0 train_loss: tensor(0.2386, device='cuda:0')\n",
      "Elapsed Epoch Training Time: 193.3861689567566\n",
      "Epoch: 5 \tTraining Loss: 0.254979 \tValidation Loss: 0.334507\n",
      "Validation loss decreased (0.337423 --> 0.334507).  Saving model ...\n",
      "6 : 0 train_loss: tensor(0.2312, device='cuda:0')\n",
      "Elapsed Epoch Training Time: 193.2827160358429\n",
      "Epoch: 6 \tTraining Loss: 0.252924 \tValidation Loss: 0.342032\n",
      "7 : 0 train_loss: tensor(0.2184, device='cuda:0')\n",
      "Elapsed Epoch Training Time: 193.28894424438477\n",
      "Epoch: 7 \tTraining Loss: 0.249509 \tValidation Loss: 0.358179\n",
      "8 : 0 train_loss: tensor(0.1937, device='cuda:0')\n",
      "Elapsed Epoch Training Time: 195.5749740600586\n",
      "Epoch: 8 \tTraining Loss: 0.247680 \tValidation Loss: 0.379309\n",
      "9 : 0 train_loss: tensor(0.1913, device='cuda:0')\n",
      "Elapsed Epoch Training Time: 193.9168963432312\n",
      "Epoch: 9 \tTraining Loss: 0.243349 \tValidation Loss: 0.348792\n",
      "10 : 0 train_loss: tensor(0.2315, device='cuda:0')\n",
      "Elapsed Epoch Training Time: 193.95293617248535\n",
      "Epoch: 10 \tTraining Loss: 0.239290 \tValidation Loss: 0.321195\n",
      "Validation loss decreased (0.334507 --> 0.321195).  Saving model ...\n",
      "11 : 0 train_loss: tensor(0.2892, device='cuda:0')\n",
      "Elapsed Epoch Training Time: 192.27054858207703\n",
      "Epoch: 11 \tTraining Loss: 0.233672 \tValidation Loss: 0.315278\n",
      "Validation loss decreased (0.321195 --> 0.315278).  Saving model ...\n"
     ]
    }
   ],
   "source": [
    "model_transfer =  train(11, loaders_transfer, model_transfer, optimizer_transfer, criterion_transfer, use_cuda, 'model_transfer.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_transfer.load_state_dict(torch.load('model_transfer.pt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.374402\n",
      "\n",
      "\n",
      "Test Accuracy: 89% (745/836)\n"
     ]
    }
   ],
   "source": [
    "test(loaders_transfer, model_transfer, criterion_transfer, use_cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NasNetALarge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## NasNetALarge uses 331x331 size images\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "train_dir = r\"D:\\Python\\deep-learning-v2-pytorch\\project-dog-classification\\dogImages\\train\"\n",
    "valid_dir = r\"D:\\Python\\deep-learning-v2-pytorch\\project-dog-classification\\dogImages\\valid\"\n",
    "test_dir = r\"D:\\Python\\deep-learning-v2-pytorch\\project-dog-classification\\dogImages\\test\"\n",
    "\n",
    "transform_transfer_NasNetALarge = transforms.Compose([transforms.Resize((331,331)), \n",
    "                                transforms.ToTensor(), \n",
    "                                transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])])\n",
    "\n",
    "train_set_transfer_NasNetALarge = datasets.ImageFolder(train_dir, transform=transform_transfer_NasNetALarge)\n",
    "train_loader_transfer_NasNetALarge = torch.utils.data.DataLoader(train_set_transfer_NasNetALarge, shuffle=True, batch_size=batch_size)\n",
    "#train_images, train_labels = next(iter(train_loader))\n",
    "\n",
    "valid_set_transfer_NasNetALarge = datasets.ImageFolder(valid_dir, transform=transform_transfer_NasNetALarge)\n",
    "valid_loader_transfer_NasNetALarge = torch.utils.data.DataLoader(valid_set_transfer_NasNetALarge, shuffle=True, batch_size=batch_size)\n",
    "#valid_images, valid_labels = next(iter(valid_loader))\n",
    "\n",
    "test_set_transfer_NasNetALarge = datasets.ImageFolder(test_dir, transform=transform_transfer_NasNetALarge)\n",
    "test_loader_transfer_NasNetALarge = torch.utils.data.DataLoader(test_set_transfer_NasNetALarge, shuffle=True, batch_size=batch_size)\n",
    "#test_images, test_labels = next(iter(test_loader))\n",
    "\n",
    "loaders_transfer_NasNetALarge={'train':train_loader_transfer_NasNetALarge, 'valid': valid_loader_transfer_NasNetALarge, 'test':test_loader_transfer_NasNetALarge}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division, absolute_import\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "from torch.autograd import Variable\n",
    "\n",
    "pretrained_settings = {\n",
    "    'nasnetalarge': {\n",
    "        'imagenet': {\n",
    "            'url': 'http://data.lip6.fr/cadene/pretrainedmodels/nasnetalarge-a1897284.pth',\n",
    "            'input_space': 'RGB',\n",
    "            'input_size': [3, 331, 331], # resize 354\n",
    "            'input_range': [0, 1],\n",
    "            'mean': [0.5, 0.5, 0.5],\n",
    "            'std': [0.5, 0.5, 0.5],\n",
    "            'num_classes': 1000\n",
    "        },\n",
    "        'imagenet+background': {\n",
    "            'url': 'http://data.lip6.fr/cadene/pretrainedmodels/nasnetalarge-a1897284.pth',\n",
    "            'input_space': 'RGB',\n",
    "            'input_size': [3, 331, 331], # resize 354\n",
    "            'input_range': [0, 1],\n",
    "            'mean': [0.5, 0.5, 0.5],\n",
    "            'std': [0.5, 0.5, 0.5],\n",
    "            'num_classes': 1001\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "class MaxPoolPad(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(MaxPoolPad, self).__init__()\n",
    "        self.pad = nn.ZeroPad2d((1, 0, 1, 0))\n",
    "        self.pool = nn.MaxPool2d(3, stride=2, padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pad(x)\n",
    "        x = self.pool(x)\n",
    "        x = x[:, :, 1:, 1:]\n",
    "        return x\n",
    "\n",
    "\n",
    "class AvgPoolPad(nn.Module):\n",
    "\n",
    "    def __init__(self, stride=2, padding=1):\n",
    "        super(AvgPoolPad, self).__init__()\n",
    "        self.pad = nn.ZeroPad2d((1, 0, 1, 0))\n",
    "        self.pool = nn.AvgPool2d(3, stride=stride, padding=padding, count_include_pad=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pad(x)\n",
    "        x = self.pool(x)\n",
    "        x = x[:, :, 1:, 1:]\n",
    "        return x\n",
    "\n",
    "\n",
    "class SeparableConv2d(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, dw_kernel, dw_stride, dw_padding, bias=False):\n",
    "        super(SeparableConv2d, self).__init__()\n",
    "        self.depthwise_conv2d = nn.Conv2d(in_channels, in_channels, dw_kernel,\n",
    "                                          stride=dw_stride,\n",
    "                                          padding=dw_padding,\n",
    "                                          bias=bias,\n",
    "                                          groups=in_channels)\n",
    "        self.pointwise_conv2d = nn.Conv2d(in_channels, out_channels, 1, stride=1, bias=bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.depthwise_conv2d(x)\n",
    "        x = self.pointwise_conv2d(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class BranchSeparables(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, bias=False):\n",
    "        super(BranchSeparables, self).__init__()\n",
    "        self.relu = nn.ReLU()\n",
    "        self.separable_1 = SeparableConv2d(in_channels, in_channels, kernel_size, stride, padding, bias=bias)\n",
    "        self.bn_sep_1 = nn.BatchNorm2d(in_channels, eps=0.001, momentum=0.1, affine=True)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.separable_2 = SeparableConv2d(in_channels, out_channels, kernel_size, 1, padding, bias=bias)\n",
    "        self.bn_sep_2 = nn.BatchNorm2d(out_channels, eps=0.001, momentum=0.1, affine=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(x)\n",
    "        x = self.separable_1(x)\n",
    "        x = self.bn_sep_1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.separable_2(x)\n",
    "        x = self.bn_sep_2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class BranchSeparablesStem(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, bias=False):\n",
    "        super(BranchSeparablesStem, self).__init__()\n",
    "        self.relu = nn.ReLU()\n",
    "        self.separable_1 = SeparableConv2d(in_channels, out_channels, kernel_size, stride, padding, bias=bias)\n",
    "        self.bn_sep_1 = nn.BatchNorm2d(out_channels, eps=0.001, momentum=0.1, affine=True)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.separable_2 = SeparableConv2d(out_channels, out_channels, kernel_size, 1, padding, bias=bias)\n",
    "        self.bn_sep_2 = nn.BatchNorm2d(out_channels, eps=0.001, momentum=0.1, affine=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(x)\n",
    "        x = self.separable_1(x)\n",
    "        x = self.bn_sep_1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.separable_2(x)\n",
    "        x = self.bn_sep_2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class BranchSeparablesReduction(BranchSeparables):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, z_padding=1, bias=False):\n",
    "        BranchSeparables.__init__(self, in_channels, out_channels, kernel_size, stride, padding, bias)\n",
    "        self.padding = nn.ZeroPad2d((z_padding, 0, z_padding, 0))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(x)\n",
    "        x = self.padding(x)\n",
    "        x = self.separable_1(x)\n",
    "        x = x[:, :, 1:, 1:].contiguous()\n",
    "        x = self.bn_sep_1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.separable_2(x)\n",
    "        x = self.bn_sep_2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class CellStem0(nn.Module):\n",
    "    def __init__(self, stem_filters, num_filters=42):\n",
    "        super(CellStem0, self).__init__()\n",
    "        self.num_filters = num_filters\n",
    "        self.stem_filters = stem_filters\n",
    "        self.conv_1x1 = nn.Sequential()\n",
    "        self.conv_1x1.add_module('relu', nn.ReLU())\n",
    "        self.conv_1x1.add_module('conv', nn.Conv2d(self.stem_filters, self.num_filters, 1, stride=1, bias=False))\n",
    "        self.conv_1x1.add_module('bn', nn.BatchNorm2d(self.num_filters, eps=0.001, momentum=0.1, affine=True))\n",
    "\n",
    "        self.comb_iter_0_left = BranchSeparables(self.num_filters, self.num_filters, 5, 2, 2)\n",
    "        self.comb_iter_0_right = BranchSeparablesStem(self.stem_filters, self.num_filters, 7, 2, 3, bias=False)\n",
    "\n",
    "        self.comb_iter_1_left = nn.MaxPool2d(3, stride=2, padding=1)\n",
    "        self.comb_iter_1_right = BranchSeparablesStem(self.stem_filters, self.num_filters, 7, 2, 3, bias=False)\n",
    "\n",
    "        self.comb_iter_2_left = nn.AvgPool2d(3, stride=2, padding=1, count_include_pad=False)\n",
    "        self.comb_iter_2_right = BranchSeparablesStem(self.stem_filters, self.num_filters, 5, 2, 2, bias=False)\n",
    "\n",
    "        self.comb_iter_3_right = nn.AvgPool2d(3, stride=1, padding=1, count_include_pad=False)\n",
    "\n",
    "        self.comb_iter_4_left = BranchSeparables(self.num_filters, self.num_filters, 3, 1, 1, bias=False)\n",
    "        self.comb_iter_4_right = nn.MaxPool2d(3, stride=2, padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.conv_1x1(x)\n",
    "\n",
    "        x_comb_iter_0_left = self.comb_iter_0_left(x1)\n",
    "        x_comb_iter_0_right = self.comb_iter_0_right(x)\n",
    "        x_comb_iter_0 = x_comb_iter_0_left + x_comb_iter_0_right\n",
    "\n",
    "        x_comb_iter_1_left = self.comb_iter_1_left(x1)\n",
    "        x_comb_iter_1_right = self.comb_iter_1_right(x)\n",
    "        x_comb_iter_1 = x_comb_iter_1_left + x_comb_iter_1_right\n",
    "\n",
    "        x_comb_iter_2_left = self.comb_iter_2_left(x1)\n",
    "        x_comb_iter_2_right = self.comb_iter_2_right(x)\n",
    "        x_comb_iter_2 = x_comb_iter_2_left + x_comb_iter_2_right\n",
    "\n",
    "        x_comb_iter_3_right = self.comb_iter_3_right(x_comb_iter_0)\n",
    "        x_comb_iter_3 = x_comb_iter_3_right + x_comb_iter_1\n",
    "\n",
    "        x_comb_iter_4_left = self.comb_iter_4_left(x_comb_iter_0)\n",
    "        x_comb_iter_4_right = self.comb_iter_4_right(x1)\n",
    "        x_comb_iter_4 = x_comb_iter_4_left + x_comb_iter_4_right\n",
    "\n",
    "        x_out = torch.cat([x_comb_iter_1, x_comb_iter_2, x_comb_iter_3, x_comb_iter_4], 1)\n",
    "        return x_out\n",
    "\n",
    "\n",
    "class CellStem1(nn.Module):\n",
    "\n",
    "    def __init__(self, stem_filters, num_filters):\n",
    "        super(CellStem1, self).__init__()\n",
    "        self.num_filters = num_filters\n",
    "        self.stem_filters = stem_filters\n",
    "        self.conv_1x1 = nn.Sequential()\n",
    "        self.conv_1x1.add_module('relu', nn.ReLU())\n",
    "        self.conv_1x1.add_module('conv', nn.Conv2d(2*self.num_filters, self.num_filters, 1, stride=1, bias=False))\n",
    "        self.conv_1x1.add_module('bn', nn.BatchNorm2d(self.num_filters, eps=0.001, momentum=0.1, affine=True))\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        self.path_1 = nn.Sequential()\n",
    "        self.path_1.add_module('avgpool', nn.AvgPool2d(1, stride=2, count_include_pad=False))\n",
    "        self.path_1.add_module('conv', nn.Conv2d(self.stem_filters, self.num_filters//2, 1, stride=1, bias=False))\n",
    "        self.path_2 = nn.ModuleList()\n",
    "        self.path_2.add_module('pad', nn.ZeroPad2d((0, 1, 0, 1)))\n",
    "        self.path_2.add_module('avgpool', nn.AvgPool2d(1, stride=2, count_include_pad=False))\n",
    "        self.path_2.add_module('conv', nn.Conv2d(self.stem_filters, self.num_filters//2, 1, stride=1, bias=False))\n",
    "\n",
    "        self.final_path_bn = nn.BatchNorm2d(self.num_filters, eps=0.001, momentum=0.1, affine=True)\n",
    "\n",
    "        self.comb_iter_0_left = BranchSeparables(self.num_filters, self.num_filters, 5, 2, 2, bias=False)\n",
    "        self.comb_iter_0_right = BranchSeparables(self.num_filters, self.num_filters, 7, 2, 3, bias=False)\n",
    "\n",
    "        self.comb_iter_1_left = nn.MaxPool2d(3, stride=2, padding=1)\n",
    "        self.comb_iter_1_right = BranchSeparables(self.num_filters, self.num_filters, 7, 2, 3, bias=False)\n",
    "\n",
    "        self.comb_iter_2_left = nn.AvgPool2d(3, stride=2, padding=1, count_include_pad=False)\n",
    "        self.comb_iter_2_right = BranchSeparables(self.num_filters, self.num_filters, 5, 2, 2, bias=False)\n",
    "\n",
    "        self.comb_iter_3_right = nn.AvgPool2d(3, stride=1, padding=1, count_include_pad=False)\n",
    "\n",
    "        self.comb_iter_4_left = BranchSeparables(self.num_filters, self.num_filters, 3, 1, 1, bias=False)\n",
    "        self.comb_iter_4_right = nn.MaxPool2d(3, stride=2, padding=1)\n",
    "\n",
    "    def forward(self, x_conv0, x_stem_0):\n",
    "        x_left = self.conv_1x1(x_stem_0)\n",
    "\n",
    "        x_relu = self.relu(x_conv0)\n",
    "        # path 1\n",
    "        x_path1 = self.path_1(x_relu)\n",
    "        # path 2\n",
    "        x_path2 = self.path_2.pad(x_relu)\n",
    "        x_path2 = x_path2[:, :, 1:, 1:]\n",
    "        x_path2 = self.path_2.avgpool(x_path2)\n",
    "        x_path2 = self.path_2.conv(x_path2)\n",
    "        # final path\n",
    "        x_right = self.final_path_bn(torch.cat([x_path1, x_path2], 1))\n",
    "\n",
    "        x_comb_iter_0_left = self.comb_iter_0_left(x_left)\n",
    "        x_comb_iter_0_right = self.comb_iter_0_right(x_right)\n",
    "        x_comb_iter_0 = x_comb_iter_0_left + x_comb_iter_0_right\n",
    "\n",
    "        x_comb_iter_1_left = self.comb_iter_1_left(x_left)\n",
    "        x_comb_iter_1_right = self.comb_iter_1_right(x_right)\n",
    "        x_comb_iter_1 = x_comb_iter_1_left + x_comb_iter_1_right\n",
    "\n",
    "        x_comb_iter_2_left = self.comb_iter_2_left(x_left)\n",
    "        x_comb_iter_2_right = self.comb_iter_2_right(x_right)\n",
    "        x_comb_iter_2 = x_comb_iter_2_left + x_comb_iter_2_right\n",
    "\n",
    "        x_comb_iter_3_right = self.comb_iter_3_right(x_comb_iter_0)\n",
    "        x_comb_iter_3 = x_comb_iter_3_right + x_comb_iter_1\n",
    "\n",
    "        x_comb_iter_4_left = self.comb_iter_4_left(x_comb_iter_0)\n",
    "        x_comb_iter_4_right = self.comb_iter_4_right(x_left)\n",
    "        x_comb_iter_4 = x_comb_iter_4_left + x_comb_iter_4_right\n",
    "\n",
    "        x_out = torch.cat([x_comb_iter_1, x_comb_iter_2, x_comb_iter_3, x_comb_iter_4], 1)\n",
    "        return x_out\n",
    "\n",
    "\n",
    "class FirstCell(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels_left, out_channels_left, in_channels_right, out_channels_right):\n",
    "        super(FirstCell, self).__init__()\n",
    "        self.conv_1x1 = nn.Sequential()\n",
    "        self.conv_1x1.add_module('relu', nn.ReLU())\n",
    "        self.conv_1x1.add_module('conv', nn.Conv2d(in_channels_right, out_channels_right, 1, stride=1, bias=False))\n",
    "        self.conv_1x1.add_module('bn', nn.BatchNorm2d(out_channels_right, eps=0.001, momentum=0.1, affine=True))\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        self.path_1 = nn.Sequential()\n",
    "        self.path_1.add_module('avgpool', nn.AvgPool2d(1, stride=2, count_include_pad=False))\n",
    "        self.path_1.add_module('conv', nn.Conv2d(in_channels_left, out_channels_left, 1, stride=1, bias=False))\n",
    "        self.path_2 = nn.ModuleList()\n",
    "        self.path_2.add_module('pad', nn.ZeroPad2d((0, 1, 0, 1)))\n",
    "        self.path_2.add_module('avgpool', nn.AvgPool2d(1, stride=2, count_include_pad=False))\n",
    "        self.path_2.add_module('conv', nn.Conv2d(in_channels_left, out_channels_left, 1, stride=1, bias=False))\n",
    "\n",
    "        self.final_path_bn = nn.BatchNorm2d(out_channels_left * 2, eps=0.001, momentum=0.1, affine=True)\n",
    "\n",
    "        self.comb_iter_0_left = BranchSeparables(out_channels_right, out_channels_right, 5, 1, 2, bias=False)\n",
    "        self.comb_iter_0_right = BranchSeparables(out_channels_right, out_channels_right, 3, 1, 1, bias=False)\n",
    "\n",
    "        self.comb_iter_1_left = BranchSeparables(out_channels_right, out_channels_right, 5, 1, 2, bias=False)\n",
    "        self.comb_iter_1_right = BranchSeparables(out_channels_right, out_channels_right, 3, 1, 1, bias=False)\n",
    "\n",
    "        self.comb_iter_2_left = nn.AvgPool2d(3, stride=1, padding=1, count_include_pad=False)\n",
    "\n",
    "        self.comb_iter_3_left = nn.AvgPool2d(3, stride=1, padding=1, count_include_pad=False)\n",
    "        self.comb_iter_3_right = nn.AvgPool2d(3, stride=1, padding=1, count_include_pad=False)\n",
    "\n",
    "        self.comb_iter_4_left = BranchSeparables(out_channels_right, out_channels_right, 3, 1, 1, bias=False)\n",
    "\n",
    "    def forward(self, x, x_prev):\n",
    "        x_relu = self.relu(x_prev)\n",
    "        # path 1\n",
    "        x_path1 = self.path_1(x_relu)\n",
    "        # path 2\n",
    "        x_path2 = self.path_2.pad(x_relu)\n",
    "        x_path2 = x_path2[:, :, 1:, 1:]\n",
    "        x_path2 = self.path_2.avgpool(x_path2)\n",
    "        x_path2 = self.path_2.conv(x_path2)\n",
    "        # final path\n",
    "        x_left = self.final_path_bn(torch.cat([x_path1, x_path2], 1))\n",
    "\n",
    "        x_right = self.conv_1x1(x)\n",
    "\n",
    "        x_comb_iter_0_left = self.comb_iter_0_left(x_right)\n",
    "        x_comb_iter_0_right = self.comb_iter_0_right(x_left)\n",
    "        x_comb_iter_0 = x_comb_iter_0_left + x_comb_iter_0_right\n",
    "\n",
    "        x_comb_iter_1_left = self.comb_iter_1_left(x_left)\n",
    "        x_comb_iter_1_right = self.comb_iter_1_right(x_left)\n",
    "        x_comb_iter_1 = x_comb_iter_1_left + x_comb_iter_1_right\n",
    "\n",
    "        x_comb_iter_2_left = self.comb_iter_2_left(x_right)\n",
    "        x_comb_iter_2 = x_comb_iter_2_left + x_left\n",
    "\n",
    "        x_comb_iter_3_left = self.comb_iter_3_left(x_left)\n",
    "        x_comb_iter_3_right = self.comb_iter_3_right(x_left)\n",
    "        x_comb_iter_3 = x_comb_iter_3_left + x_comb_iter_3_right\n",
    "\n",
    "        x_comb_iter_4_left = self.comb_iter_4_left(x_right)\n",
    "        x_comb_iter_4 = x_comb_iter_4_left + x_right\n",
    "\n",
    "        x_out = torch.cat([x_left, x_comb_iter_0, x_comb_iter_1, x_comb_iter_2, x_comb_iter_3, x_comb_iter_4], 1)\n",
    "        return x_out\n",
    "\n",
    "\n",
    "class NormalCell(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels_left, out_channels_left, in_channels_right, out_channels_right):\n",
    "        super(NormalCell, self).__init__()\n",
    "        self.conv_prev_1x1 = nn.Sequential()\n",
    "        self.conv_prev_1x1.add_module('relu', nn.ReLU())\n",
    "        self.conv_prev_1x1.add_module('conv', nn.Conv2d(in_channels_left, out_channels_left, 1, stride=1, bias=False))\n",
    "        self.conv_prev_1x1.add_module('bn', nn.BatchNorm2d(out_channels_left, eps=0.001, momentum=0.1, affine=True))\n",
    "\n",
    "        self.conv_1x1 = nn.Sequential()\n",
    "        self.conv_1x1.add_module('relu', nn.ReLU())\n",
    "        self.conv_1x1.add_module('conv', nn.Conv2d(in_channels_right, out_channels_right, 1, stride=1, bias=False))\n",
    "        self.conv_1x1.add_module('bn', nn.BatchNorm2d(out_channels_right, eps=0.001, momentum=0.1, affine=True))\n",
    "\n",
    "        self.comb_iter_0_left = BranchSeparables(out_channels_right, out_channels_right, 5, 1, 2, bias=False)\n",
    "        self.comb_iter_0_right = BranchSeparables(out_channels_left, out_channels_left, 3, 1, 1, bias=False)\n",
    "\n",
    "        self.comb_iter_1_left = BranchSeparables(out_channels_left, out_channels_left, 5, 1, 2, bias=False)\n",
    "        self.comb_iter_1_right = BranchSeparables(out_channels_left, out_channels_left, 3, 1, 1, bias=False)\n",
    "\n",
    "        self.comb_iter_2_left = nn.AvgPool2d(3, stride=1, padding=1, count_include_pad=False)\n",
    "\n",
    "        self.comb_iter_3_left = nn.AvgPool2d(3, stride=1, padding=1, count_include_pad=False)\n",
    "        self.comb_iter_3_right = nn.AvgPool2d(3, stride=1, padding=1, count_include_pad=False)\n",
    "\n",
    "        self.comb_iter_4_left = BranchSeparables(out_channels_right, out_channels_right, 3, 1, 1, bias=False)\n",
    "\n",
    "    def forward(self, x, x_prev):\n",
    "        x_left = self.conv_prev_1x1(x_prev)\n",
    "        x_right = self.conv_1x1(x)\n",
    "\n",
    "        x_comb_iter_0_left = self.comb_iter_0_left(x_right)\n",
    "        x_comb_iter_0_right = self.comb_iter_0_right(x_left)\n",
    "        x_comb_iter_0 = x_comb_iter_0_left + x_comb_iter_0_right\n",
    "\n",
    "        x_comb_iter_1_left = self.comb_iter_1_left(x_left)\n",
    "        x_comb_iter_1_right = self.comb_iter_1_right(x_left)\n",
    "        x_comb_iter_1 = x_comb_iter_1_left + x_comb_iter_1_right\n",
    "\n",
    "        x_comb_iter_2_left = self.comb_iter_2_left(x_right)\n",
    "        x_comb_iter_2 = x_comb_iter_2_left + x_left\n",
    "\n",
    "        x_comb_iter_3_left = self.comb_iter_3_left(x_left)\n",
    "        x_comb_iter_3_right = self.comb_iter_3_right(x_left)\n",
    "        x_comb_iter_3 = x_comb_iter_3_left + x_comb_iter_3_right\n",
    "\n",
    "        x_comb_iter_4_left = self.comb_iter_4_left(x_right)\n",
    "        x_comb_iter_4 = x_comb_iter_4_left + x_right\n",
    "\n",
    "        x_out = torch.cat([x_left, x_comb_iter_0, x_comb_iter_1, x_comb_iter_2, x_comb_iter_3, x_comb_iter_4], 1)\n",
    "        return x_out\n",
    "\n",
    "\n",
    "class ReductionCell0(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels_left, out_channels_left, in_channels_right, out_channels_right):\n",
    "        super(ReductionCell0, self).__init__()\n",
    "        self.conv_prev_1x1 = nn.Sequential()\n",
    "        self.conv_prev_1x1.add_module('relu', nn.ReLU())\n",
    "        self.conv_prev_1x1.add_module('conv', nn.Conv2d(in_channels_left, out_channels_left, 1, stride=1, bias=False))\n",
    "        self.conv_prev_1x1.add_module('bn', nn.BatchNorm2d(out_channels_left, eps=0.001, momentum=0.1, affine=True))\n",
    "\n",
    "        self.conv_1x1 = nn.Sequential()\n",
    "        self.conv_1x1.add_module('relu', nn.ReLU())\n",
    "        self.conv_1x1.add_module('conv', nn.Conv2d(in_channels_right, out_channels_right, 1, stride=1, bias=False))\n",
    "        self.conv_1x1.add_module('bn', nn.BatchNorm2d(out_channels_right, eps=0.001, momentum=0.1, affine=True))\n",
    "\n",
    "        self.comb_iter_0_left = BranchSeparablesReduction(out_channels_right, out_channels_right, 5, 2, 2, bias=False)\n",
    "        self.comb_iter_0_right = BranchSeparablesReduction(out_channels_right, out_channels_right, 7, 2, 3, bias=False)\n",
    "\n",
    "        self.comb_iter_1_left = MaxPoolPad()\n",
    "        self.comb_iter_1_right = BranchSeparablesReduction(out_channels_right, out_channels_right, 7, 2, 3, bias=False)\n",
    "\n",
    "        self.comb_iter_2_left = AvgPoolPad()\n",
    "        self.comb_iter_2_right = BranchSeparablesReduction(out_channels_right, out_channels_right, 5, 2, 2, bias=False)\n",
    "\n",
    "        self.comb_iter_3_right = nn.AvgPool2d(3, stride=1, padding=1, count_include_pad=False)\n",
    "\n",
    "        self.comb_iter_4_left = BranchSeparablesReduction(out_channels_right, out_channels_right, 3, 1, 1, bias=False)\n",
    "        self.comb_iter_4_right = MaxPoolPad()\n",
    "\n",
    "    def forward(self, x, x_prev):\n",
    "        x_left = self.conv_prev_1x1(x_prev)\n",
    "        x_right = self.conv_1x1(x)\n",
    "\n",
    "        x_comb_iter_0_left = self.comb_iter_0_left(x_right)\n",
    "        x_comb_iter_0_right = self.comb_iter_0_right(x_left)\n",
    "        x_comb_iter_0 = x_comb_iter_0_left + x_comb_iter_0_right\n",
    "\n",
    "        x_comb_iter_1_left = self.comb_iter_1_left(x_right)\n",
    "        x_comb_iter_1_right = self.comb_iter_1_right(x_left)\n",
    "        x_comb_iter_1 = x_comb_iter_1_left + x_comb_iter_1_right\n",
    "\n",
    "        x_comb_iter_2_left = self.comb_iter_2_left(x_right)\n",
    "        x_comb_iter_2_right = self.comb_iter_2_right(x_left)\n",
    "        x_comb_iter_2 = x_comb_iter_2_left + x_comb_iter_2_right\n",
    "\n",
    "        x_comb_iter_3_right = self.comb_iter_3_right(x_comb_iter_0)\n",
    "        x_comb_iter_3 = x_comb_iter_3_right + x_comb_iter_1\n",
    "\n",
    "        x_comb_iter_4_left = self.comb_iter_4_left(x_comb_iter_0)\n",
    "        x_comb_iter_4_right = self.comb_iter_4_right(x_right)\n",
    "        x_comb_iter_4 = x_comb_iter_4_left + x_comb_iter_4_right\n",
    "\n",
    "        x_out = torch.cat([x_comb_iter_1, x_comb_iter_2, x_comb_iter_3, x_comb_iter_4], 1)\n",
    "        return x_out\n",
    "\n",
    "\n",
    "class ReductionCell1(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels_left, out_channels_left, in_channels_right, out_channels_right):\n",
    "        super(ReductionCell1, self).__init__()\n",
    "        self.conv_prev_1x1 = nn.Sequential()\n",
    "        self.conv_prev_1x1.add_module('relu', nn.ReLU())\n",
    "        self.conv_prev_1x1.add_module('conv', nn.Conv2d(in_channels_left, out_channels_left, 1, stride=1, bias=False))\n",
    "        self.conv_prev_1x1.add_module('bn', nn.BatchNorm2d(out_channels_left, eps=0.001, momentum=0.1, affine=True))\n",
    "\n",
    "        self.conv_1x1 = nn.Sequential()\n",
    "        self.conv_1x1.add_module('relu', nn.ReLU())\n",
    "        self.conv_1x1.add_module('conv', nn.Conv2d(in_channels_right, out_channels_right, 1, stride=1, bias=False))\n",
    "        self.conv_1x1.add_module('bn', nn.BatchNorm2d(out_channels_right, eps=0.001, momentum=0.1, affine=True))\n",
    "\n",
    "        self.comb_iter_0_left = BranchSeparables(out_channels_right, out_channels_right, 5, 2, 2, bias=False)\n",
    "        self.comb_iter_0_right = BranchSeparables(out_channels_right, out_channels_right, 7, 2, 3, bias=False)\n",
    "\n",
    "        self.comb_iter_1_left = nn.MaxPool2d(3, stride=2, padding=1)\n",
    "        self.comb_iter_1_right = BranchSeparables(out_channels_right, out_channels_right, 7, 2, 3, bias=False)\n",
    "\n",
    "        self.comb_iter_2_left = nn.AvgPool2d(3, stride=2, padding=1, count_include_pad=False)\n",
    "        self.comb_iter_2_right = BranchSeparables(out_channels_right, out_channels_right, 5, 2, 2, bias=False)\n",
    "\n",
    "        self.comb_iter_3_right = nn.AvgPool2d(3, stride=1, padding=1, count_include_pad=False)\n",
    "\n",
    "        self.comb_iter_4_left = BranchSeparables(out_channels_right, out_channels_right, 3, 1, 1, bias=False)\n",
    "        self.comb_iter_4_right = nn.MaxPool2d(3, stride=2, padding=1)\n",
    "\n",
    "    def forward(self, x, x_prev):\n",
    "        x_left = self.conv_prev_1x1(x_prev)\n",
    "        x_right = self.conv_1x1(x)\n",
    "\n",
    "        x_comb_iter_0_left = self.comb_iter_0_left(x_right)\n",
    "        x_comb_iter_0_right = self.comb_iter_0_right(x_left)\n",
    "        x_comb_iter_0 = x_comb_iter_0_left + x_comb_iter_0_right\n",
    "\n",
    "        x_comb_iter_1_left = self.comb_iter_1_left(x_right)\n",
    "        x_comb_iter_1_right = self.comb_iter_1_right(x_left)\n",
    "        x_comb_iter_1 = x_comb_iter_1_left + x_comb_iter_1_right\n",
    "\n",
    "        x_comb_iter_2_left = self.comb_iter_2_left(x_right)\n",
    "        x_comb_iter_2_right = self.comb_iter_2_right(x_left)\n",
    "        x_comb_iter_2 = x_comb_iter_2_left + x_comb_iter_2_right\n",
    "\n",
    "        x_comb_iter_3_right = self.comb_iter_3_right(x_comb_iter_0)\n",
    "        x_comb_iter_3 = x_comb_iter_3_right + x_comb_iter_1\n",
    "\n",
    "        x_comb_iter_4_left = self.comb_iter_4_left(x_comb_iter_0)\n",
    "        x_comb_iter_4_right = self.comb_iter_4_right(x_right)\n",
    "        x_comb_iter_4 = x_comb_iter_4_left + x_comb_iter_4_right\n",
    "\n",
    "        x_out = torch.cat([x_comb_iter_1, x_comb_iter_2, x_comb_iter_3, x_comb_iter_4], 1)\n",
    "        return x_out\n",
    "\n",
    "\n",
    "class NASNetALarge(nn.Module):\n",
    "    \"\"\"NASNetALarge (6 @ 4032) \"\"\"\n",
    "\n",
    "    def __init__(self, num_classes=1000, stem_filters=96, penultimate_filters=4032, filters_multiplier=2):\n",
    "        super(NASNetALarge, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.stem_filters = stem_filters\n",
    "        self.penultimate_filters = penultimate_filters\n",
    "        self.filters_multiplier = filters_multiplier\n",
    "\n",
    "        filters = self.penultimate_filters // 24\n",
    "        # 24 is default value for the architecture\n",
    "\n",
    "        self.conv0 = nn.Sequential()\n",
    "        self.conv0.add_module('conv', nn.Conv2d(in_channels=3, out_channels=self.stem_filters, kernel_size=3, padding=0, stride=2,\n",
    "                                                bias=False))\n",
    "        self.conv0.add_module('bn', nn.BatchNorm2d(self.stem_filters, eps=0.001, momentum=0.1, affine=True))\n",
    "\n",
    "        self.cell_stem_0 = CellStem0(self.stem_filters, num_filters=filters // (filters_multiplier ** 2))\n",
    "        self.cell_stem_1 = CellStem1(self.stem_filters, num_filters=filters // filters_multiplier)\n",
    "\n",
    "        self.cell_0 = FirstCell(in_channels_left=filters, out_channels_left=filters//2,\n",
    "                                in_channels_right=2*filters, out_channels_right=filters)\n",
    "        self.cell_1 = NormalCell(in_channels_left=2*filters, out_channels_left=filters,\n",
    "                                 in_channels_right=6*filters, out_channels_right=filters)\n",
    "        self.cell_2 = NormalCell(in_channels_left=6*filters, out_channels_left=filters,\n",
    "                                 in_channels_right=6*filters, out_channels_right=filters)\n",
    "        self.cell_3 = NormalCell(in_channels_left=6*filters, out_channels_left=filters,\n",
    "                                 in_channels_right=6*filters, out_channels_right=filters)\n",
    "        self.cell_4 = NormalCell(in_channels_left=6*filters, out_channels_left=filters,\n",
    "                                 in_channels_right=6*filters, out_channels_right=filters)\n",
    "        self.cell_5 = NormalCell(in_channels_left=6*filters, out_channels_left=filters,\n",
    "                                 in_channels_right=6*filters, out_channels_right=filters)\n",
    "\n",
    "        self.reduction_cell_0 = ReductionCell0(in_channels_left=6*filters, out_channels_left=2*filters,\n",
    "                                               in_channels_right=6*filters, out_channels_right=2*filters)\n",
    "\n",
    "        self.cell_6 = FirstCell(in_channels_left=6*filters, out_channels_left=filters,\n",
    "                                in_channels_right=8*filters, out_channels_right=2*filters)\n",
    "        self.cell_7 = NormalCell(in_channels_left=8*filters, out_channels_left=2*filters,\n",
    "                                 in_channels_right=12*filters, out_channels_right=2*filters)\n",
    "        self.cell_8 = NormalCell(in_channels_left=12*filters, out_channels_left=2*filters,\n",
    "                                 in_channels_right=12*filters, out_channels_right=2*filters)\n",
    "        self.cell_9 = NormalCell(in_channels_left=12*filters, out_channels_left=2*filters,\n",
    "                                 in_channels_right=12*filters, out_channels_right=2*filters)\n",
    "        self.cell_10 = NormalCell(in_channels_left=12*filters, out_channels_left=2*filters,\n",
    "                                  in_channels_right=12*filters, out_channels_right=2*filters)\n",
    "        self.cell_11 = NormalCell(in_channels_left=12*filters, out_channels_left=2*filters,\n",
    "                                  in_channels_right=12*filters, out_channels_right=2*filters)\n",
    "\n",
    "        self.reduction_cell_1 = ReductionCell1(in_channels_left=12*filters, out_channels_left=4*filters,\n",
    "                                               in_channels_right=12*filters, out_channels_right=4*filters)\n",
    "\n",
    "        self.cell_12 = FirstCell(in_channels_left=12*filters, out_channels_left=2*filters,\n",
    "                                 in_channels_right=16*filters, out_channels_right=4*filters)\n",
    "        self.cell_13 = NormalCell(in_channels_left=16*filters, out_channels_left=4*filters,\n",
    "                                  in_channels_right=24*filters, out_channels_right=4*filters)\n",
    "        self.cell_14 = NormalCell(in_channels_left=24*filters, out_channels_left=4*filters,\n",
    "                                  in_channels_right=24*filters, out_channels_right=4*filters)\n",
    "        self.cell_15 = NormalCell(in_channels_left=24*filters, out_channels_left=4*filters,\n",
    "                                  in_channels_right=24*filters, out_channels_right=4*filters)\n",
    "        self.cell_16 = NormalCell(in_channels_left=24*filters, out_channels_left=4*filters,\n",
    "                                  in_channels_right=24*filters, out_channels_right=4*filters)\n",
    "        self.cell_17 = NormalCell(in_channels_left=24*filters, out_channels_left=4*filters,\n",
    "                                  in_channels_right=24*filters, out_channels_right=4*filters)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        self.avg_pool = nn.AvgPool2d(11, stride=1, padding=0)\n",
    "        self.dropout = nn.Dropout()\n",
    "        self.last_linear = nn.Linear(24*filters, self.num_classes)\n",
    "\n",
    "    def features(self, input):\n",
    "        x_conv0 = self.conv0(input)\n",
    "        x_stem_0 = self.cell_stem_0(x_conv0)\n",
    "        x_stem_1 = self.cell_stem_1(x_conv0, x_stem_0)\n",
    "\n",
    "        x_cell_0 = self.cell_0(x_stem_1, x_stem_0)\n",
    "        x_cell_1 = self.cell_1(x_cell_0, x_stem_1)\n",
    "        x_cell_2 = self.cell_2(x_cell_1, x_cell_0)\n",
    "        x_cell_3 = self.cell_3(x_cell_2, x_cell_1)\n",
    "        x_cell_4 = self.cell_4(x_cell_3, x_cell_2)\n",
    "        x_cell_5 = self.cell_5(x_cell_4, x_cell_3)\n",
    "\n",
    "        x_reduction_cell_0 = self.reduction_cell_0(x_cell_5, x_cell_4)\n",
    "\n",
    "        x_cell_6 = self.cell_6(x_reduction_cell_0, x_cell_4)\n",
    "        x_cell_7 = self.cell_7(x_cell_6, x_reduction_cell_0)\n",
    "        x_cell_8 = self.cell_8(x_cell_7, x_cell_6)\n",
    "        x_cell_9 = self.cell_9(x_cell_8, x_cell_7)\n",
    "        x_cell_10 = self.cell_10(x_cell_9, x_cell_8)\n",
    "        x_cell_11 = self.cell_11(x_cell_10, x_cell_9)\n",
    "\n",
    "        x_reduction_cell_1 = self.reduction_cell_1(x_cell_11, x_cell_10)\n",
    "\n",
    "        x_cell_12 = self.cell_12(x_reduction_cell_1, x_cell_10)\n",
    "        x_cell_13 = self.cell_13(x_cell_12, x_reduction_cell_1)\n",
    "        x_cell_14 = self.cell_14(x_cell_13, x_cell_12)\n",
    "        x_cell_15 = self.cell_15(x_cell_14, x_cell_13)\n",
    "        x_cell_16 = self.cell_16(x_cell_15, x_cell_14)\n",
    "        x_cell_17 = self.cell_17(x_cell_16, x_cell_15)\n",
    "        return x_cell_17\n",
    "\n",
    "    def logits(self, features):\n",
    "        x = self.relu(features)\n",
    "        x = self.avg_pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.dropout(x)\n",
    "        x = self.last_linear(x)\n",
    "        return x\n",
    "\n",
    "    def forward(self, input):\n",
    "        x = self.features(input)\n",
    "        x = self.logits(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def nasnetalarge(num_classes=1000, pretrained='imagenet'):\n",
    "    r\"\"\"NASNetALarge model architecture from the\n",
    "    `\"NASNet\" <https://arxiv.org/abs/1707.07012>`_ paper.\n",
    "    \"\"\"\n",
    "    if pretrained:\n",
    "        settings = pretrained_settings['nasnetalarge'][pretrained]\n",
    "        assert num_classes == settings['num_classes'], \\\n",
    "            \"num_classes should be {}, but is {}\".format(settings['num_classes'], num_classes)\n",
    "\n",
    "        # both 'imagenet'&'imagenet+background' are loaded from same parameters\n",
    "        model = NASNetALarge(num_classes=1001)\n",
    "        model.load_state_dict(model_zoo.load_url(settings['url']))\n",
    "\n",
    "        if pretrained == 'imagenet':\n",
    "            new_last_linear = nn.Linear(model.last_linear.in_features, 1000)\n",
    "            new_last_linear.weight.data = model.last_linear.weight.data[1:]\n",
    "            new_last_linear.bias.data = model.last_linear.bias.data[1:]\n",
    "            model.last_linear = new_last_linear\n",
    "\n",
    "        model.input_space = settings['input_space']\n",
    "        model.input_size = settings['input_size']\n",
    "        model.input_range = settings['input_range']\n",
    "\n",
    "        model.mean = settings['mean']\n",
    "        model.std = settings['std']\n",
    "    else:\n",
    "        model = NASNetALarge(num_classes=num_classes)\n",
    "    return model\n",
    "\n",
    "\n",
    "model_transfer_NasNetALarge = nasnetalarge(pretrained='imagenet')\n",
    "\n",
    "if use_cuda:\n",
    "    model_transfer_NasNetALarge = model_transfer_NasNetALarge.cuda()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NASNetALarge(\n",
       "  (conv0): Sequential(\n",
       "    (conv): Conv2d(3, 96, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "    (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (cell_stem_0): CellStem0(\n",
       "    (conv_1x1): Sequential(\n",
       "      (relu): ReLU()\n",
       "      (conv): Conv2d(96, 42, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(42, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_0_left): BranchSeparables(\n",
       "      (relu): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(42, 42, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=42, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(42, 42, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(42, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU()\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(42, 42, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=42, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(42, 42, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(42, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_0_right): BranchSeparablesStem(\n",
       "      (relu): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(96, 96, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), groups=96, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(96, 42, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(42, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU()\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(42, 42, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=42, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(42, 42, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(42, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_1_left): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (comb_iter_1_right): BranchSeparablesStem(\n",
       "      (relu): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(96, 96, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), groups=96, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(96, 42, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(42, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU()\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(42, 42, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=42, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(42, 42, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(42, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_2_left): AvgPool2d(kernel_size=3, stride=2, padding=1)\n",
       "    (comb_iter_2_right): BranchSeparablesStem(\n",
       "      (relu): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(96, 96, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=96, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(96, 42, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(42, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU()\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(42, 42, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=42, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(42, 42, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(42, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_3_right): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
       "    (comb_iter_4_left): BranchSeparables(\n",
       "      (relu): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(42, 42, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=42, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(42, 42, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(42, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU()\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(42, 42, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=42, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(42, 42, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(42, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_4_right): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (cell_stem_1): CellStem1(\n",
       "    (conv_1x1): Sequential(\n",
       "      (relu): ReLU()\n",
       "      (conv): Conv2d(168, 84, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(84, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (relu): ReLU()\n",
       "    (path_1): Sequential(\n",
       "      (avgpool): AvgPool2d(kernel_size=1, stride=2, padding=0)\n",
       "      (conv): Conv2d(96, 42, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    )\n",
       "    (path_2): ModuleList(\n",
       "      (pad): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
       "      (avgpool): AvgPool2d(kernel_size=1, stride=2, padding=0)\n",
       "      (conv): Conv2d(96, 42, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    )\n",
       "    (final_path_bn): BatchNorm2d(84, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (comb_iter_0_left): BranchSeparables(\n",
       "      (relu): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(84, 84, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=84, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(84, 84, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(84, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU()\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(84, 84, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=84, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(84, 84, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(84, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_0_right): BranchSeparables(\n",
       "      (relu): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(84, 84, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), groups=84, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(84, 84, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(84, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU()\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(84, 84, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=84, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(84, 84, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(84, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_1_left): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (comb_iter_1_right): BranchSeparables(\n",
       "      (relu): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(84, 84, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), groups=84, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(84, 84, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(84, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU()\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(84, 84, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=84, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(84, 84, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(84, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_2_left): AvgPool2d(kernel_size=3, stride=2, padding=1)\n",
       "    (comb_iter_2_right): BranchSeparables(\n",
       "      (relu): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(84, 84, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=84, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(84, 84, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(84, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU()\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(84, 84, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=84, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(84, 84, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(84, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_3_right): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
       "    (comb_iter_4_left): BranchSeparables(\n",
       "      (relu): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(84, 84, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=84, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(84, 84, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(84, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU()\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(84, 84, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=84, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(84, 84, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(84, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_4_right): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (cell_0): FirstCell(\n",
       "    (conv_1x1): Sequential(\n",
       "      (relu): ReLU()\n",
       "      (conv): Conv2d(336, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (relu): ReLU()\n",
       "    (path_1): Sequential(\n",
       "      (avgpool): AvgPool2d(kernel_size=1, stride=2, padding=0)\n",
       "      (conv): Conv2d(168, 84, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    )\n",
       "    (path_2): ModuleList(\n",
       "      (pad): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
       "      (avgpool): AvgPool2d(kernel_size=1, stride=2, padding=0)\n",
       "      (conv): Conv2d(168, 84, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    )\n",
       "    (final_path_bn): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (comb_iter_0_left): BranchSeparables(\n",
       "      (relu): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(168, 168, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=168, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(168, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU()\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(168, 168, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=168, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(168, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_0_right): BranchSeparables(\n",
       "      (relu): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(168, 168, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=168, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(168, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU()\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(168, 168, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=168, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(168, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_1_left): BranchSeparables(\n",
       "      (relu): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(168, 168, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=168, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(168, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU()\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(168, 168, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=168, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(168, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_1_right): BranchSeparables(\n",
       "      (relu): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(168, 168, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=168, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(168, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU()\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(168, 168, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=168, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(168, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_2_left): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
       "    (comb_iter_3_left): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
       "    (comb_iter_3_right): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
       "    (comb_iter_4_left): BranchSeparables(\n",
       "      (relu): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(168, 168, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=168, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(168, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU()\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(168, 168, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=168, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(168, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (cell_1): NormalCell(\n",
       "    (conv_prev_1x1): Sequential(\n",
       "      (relu): ReLU()\n",
       "      (conv): Conv2d(336, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (conv_1x1): Sequential(\n",
       "      (relu): ReLU()\n",
       "      (conv): Conv2d(1008, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_0_left): BranchSeparables(\n",
       "      (relu): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(168, 168, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=168, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(168, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU()\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(168, 168, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=168, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(168, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_0_right): BranchSeparables(\n",
       "      (relu): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(168, 168, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=168, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(168, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU()\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(168, 168, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=168, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(168, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_1_left): BranchSeparables(\n",
       "      (relu): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(168, 168, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=168, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(168, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU()\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(168, 168, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=168, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(168, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_1_right): BranchSeparables(\n",
       "      (relu): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(168, 168, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=168, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(168, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU()\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(168, 168, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=168, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(168, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_2_left): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
       "    (comb_iter_3_left): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
       "    (comb_iter_3_right): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
       "    (comb_iter_4_left): BranchSeparables(\n",
       "      (relu): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(168, 168, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=168, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(168, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU()\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(168, 168, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=168, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(168, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (cell_2): NormalCell(\n",
       "    (conv_prev_1x1): Sequential(\n",
       "      (relu): ReLU()\n",
       "      (conv): Conv2d(1008, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (conv_1x1): Sequential(\n",
       "      (relu): ReLU()\n",
       "      (conv): Conv2d(1008, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_0_left): BranchSeparables(\n",
       "      (relu): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(168, 168, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=168, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(168, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU()\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(168, 168, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=168, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(168, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_0_right): BranchSeparables(\n",
       "      (relu): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(168, 168, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=168, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(168, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU()\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(168, 168, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=168, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(168, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_1_left): BranchSeparables(\n",
       "      (relu): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(168, 168, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=168, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(168, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU()\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(168, 168, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=168, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(168, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_1_right): BranchSeparables(\n",
       "      (relu): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(168, 168, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=168, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(168, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU()\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(168, 168, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=168, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(168, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_2_left): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
       "    (comb_iter_3_left): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
       "    (comb_iter_3_right): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
       "    (comb_iter_4_left): BranchSeparables(\n",
       "      (relu): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(168, 168, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=168, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(168, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU()\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(168, 168, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=168, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(168, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (cell_3): NormalCell(\n",
       "    (conv_prev_1x1): Sequential(\n",
       "      (relu): ReLU()\n",
       "      (conv): Conv2d(1008, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (conv_1x1): Sequential(\n",
       "      (relu): ReLU()\n",
       "      (conv): Conv2d(1008, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_0_left): BranchSeparables(\n",
       "      (relu): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(168, 168, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=168, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(168, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU()\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(168, 168, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=168, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(168, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_0_right): BranchSeparables(\n",
       "      (relu): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(168, 168, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=168, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(168, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU()\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(168, 168, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=168, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(168, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_1_left): BranchSeparables(\n",
       "      (relu): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(168, 168, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=168, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(168, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU()\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(168, 168, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=168, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(168, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_1_right): BranchSeparables(\n",
       "      (relu): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(168, 168, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=168, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(168, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU()\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(168, 168, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=168, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(168, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_2_left): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
       "    (comb_iter_3_left): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
       "    (comb_iter_3_right): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
       "    (comb_iter_4_left): BranchSeparables(\n",
       "      (relu): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(168, 168, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=168, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(168, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU()\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(168, 168, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=168, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(168, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (cell_4): NormalCell(\n",
       "    (conv_prev_1x1): Sequential(\n",
       "      (relu): ReLU()\n",
       "      (conv): Conv2d(1008, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (conv_1x1): Sequential(\n",
       "      (relu): ReLU()\n",
       "      (conv): Conv2d(1008, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_0_left): BranchSeparables(\n",
       "      (relu): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(168, 168, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=168, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(168, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU()\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(168, 168, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=168, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(168, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_0_right): BranchSeparables(\n",
       "      (relu): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(168, 168, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=168, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(168, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU()\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(168, 168, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=168, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(168, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_1_left): BranchSeparables(\n",
       "      (relu): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(168, 168, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=168, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(168, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU()\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(168, 168, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=168, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(168, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_1_right): BranchSeparables(\n",
       "      (relu): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(168, 168, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=168, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(168, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU()\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(168, 168, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=168, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(168, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_2_left): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
       "    (comb_iter_3_left): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
       "    (comb_iter_3_right): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
       "    (comb_iter_4_left): BranchSeparables(\n",
       "      (relu): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(168, 168, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=168, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(168, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU()\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(168, 168, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=168, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(168, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (cell_5): NormalCell(\n",
       "    (conv_prev_1x1): Sequential(\n",
       "      (relu): ReLU()\n",
       "      (conv): Conv2d(1008, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (conv_1x1): Sequential(\n",
       "      (relu): ReLU()\n",
       "      (conv): Conv2d(1008, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_0_left): BranchSeparables(\n",
       "      (relu): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(168, 168, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=168, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(168, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU()\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(168, 168, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=168, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(168, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_0_right): BranchSeparables(\n",
       "      (relu): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(168, 168, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=168, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(168, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU()\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(168, 168, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=168, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(168, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_1_left): BranchSeparables(\n",
       "      (relu): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(168, 168, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=168, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(168, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU()\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(168, 168, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=168, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(168, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_1_right): BranchSeparables(\n",
       "      (relu): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(168, 168, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=168, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(168, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU()\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(168, 168, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=168, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(168, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_2_left): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
       "    (comb_iter_3_left): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
       "    (comb_iter_3_right): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
       "    (comb_iter_4_left): BranchSeparables(\n",
       "      (relu): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(168, 168, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=168, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(168, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU()\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(168, 168, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=168, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(168, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (reduction_cell_0): ReductionCell0(\n",
       "    (conv_prev_1x1): Sequential(\n",
       "      (relu): ReLU()\n",
       "      (conv): Conv2d(1008, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (conv_1x1): Sequential(\n",
       "      (relu): ReLU()\n",
       "      (conv): Conv2d(1008, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_0_left): BranchSeparablesReduction(\n",
       "      (relu): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=336, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU()\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=336, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (padding): ZeroPad2d(padding=(1, 0, 1, 0), value=0.0)\n",
       "    )\n",
       "    (comb_iter_0_right): BranchSeparablesReduction(\n",
       "      (relu): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), groups=336, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU()\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=336, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (padding): ZeroPad2d(padding=(1, 0, 1, 0), value=0.0)\n",
       "    )\n",
       "    (comb_iter_1_left): MaxPoolPad(\n",
       "      (pad): ZeroPad2d(padding=(1, 0, 1, 0), value=0.0)\n",
       "      (pool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (comb_iter_1_right): BranchSeparablesReduction(\n",
       "      (relu): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), groups=336, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU()\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=336, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (padding): ZeroPad2d(padding=(1, 0, 1, 0), value=0.0)\n",
       "    )\n",
       "    (comb_iter_2_left): AvgPoolPad(\n",
       "      (pad): ZeroPad2d(padding=(1, 0, 1, 0), value=0.0)\n",
       "      (pool): AvgPool2d(kernel_size=3, stride=2, padding=1)\n",
       "    )\n",
       "    (comb_iter_2_right): BranchSeparablesReduction(\n",
       "      (relu): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=336, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU()\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=336, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (padding): ZeroPad2d(padding=(1, 0, 1, 0), value=0.0)\n",
       "    )\n",
       "    (comb_iter_3_right): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
       "    (comb_iter_4_left): BranchSeparablesReduction(\n",
       "      (relu): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=336, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU()\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=336, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (padding): ZeroPad2d(padding=(1, 0, 1, 0), value=0.0)\n",
       "    )\n",
       "    (comb_iter_4_right): MaxPoolPad(\n",
       "      (pad): ZeroPad2d(padding=(1, 0, 1, 0), value=0.0)\n",
       "      (pool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "  )\n",
       "  (cell_6): FirstCell(\n",
       "    (conv_1x1): Sequential(\n",
       "      (relu): ReLU()\n",
       "      (conv): Conv2d(1344, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (relu): ReLU()\n",
       "    (path_1): Sequential(\n",
       "      (avgpool): AvgPool2d(kernel_size=1, stride=2, padding=0)\n",
       "      (conv): Conv2d(1008, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    )\n",
       "    (path_2): ModuleList(\n",
       "      (pad): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
       "      (avgpool): AvgPool2d(kernel_size=1, stride=2, padding=0)\n",
       "      (conv): Conv2d(1008, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    )\n",
       "    (final_path_bn): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (comb_iter_0_left): BranchSeparables(\n",
       "      (relu): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=336, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU()\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=336, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_0_right): BranchSeparables(\n",
       "      (relu): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=336, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU()\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=336, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_1_left): BranchSeparables(\n",
       "      (relu): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=336, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU()\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=336, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_1_right): BranchSeparables(\n",
       "      (relu): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=336, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU()\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=336, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_2_left): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
       "    (comb_iter_3_left): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
       "    (comb_iter_3_right): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
       "    (comb_iter_4_left): BranchSeparables(\n",
       "      (relu): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=336, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU()\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=336, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (cell_7): NormalCell(\n",
       "    (conv_prev_1x1): Sequential(\n",
       "      (relu): ReLU()\n",
       "      (conv): Conv2d(1344, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (conv_1x1): Sequential(\n",
       "      (relu): ReLU()\n",
       "      (conv): Conv2d(2016, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_0_left): BranchSeparables(\n",
       "      (relu): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=336, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU()\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=336, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_0_right): BranchSeparables(\n",
       "      (relu): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=336, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU()\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=336, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_1_left): BranchSeparables(\n",
       "      (relu): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=336, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU()\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=336, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_1_right): BranchSeparables(\n",
       "      (relu): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=336, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU()\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=336, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_2_left): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
       "    (comb_iter_3_left): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
       "    (comb_iter_3_right): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
       "    (comb_iter_4_left): BranchSeparables(\n",
       "      (relu): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=336, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU()\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=336, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (cell_8): NormalCell(\n",
       "    (conv_prev_1x1): Sequential(\n",
       "      (relu): ReLU()\n",
       "      (conv): Conv2d(2016, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (conv_1x1): Sequential(\n",
       "      (relu): ReLU()\n",
       "      (conv): Conv2d(2016, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_0_left): BranchSeparables(\n",
       "      (relu): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=336, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU()\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=336, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_0_right): BranchSeparables(\n",
       "      (relu): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=336, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU()\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=336, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_1_left): BranchSeparables(\n",
       "      (relu): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=336, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU()\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=336, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_1_right): BranchSeparables(\n",
       "      (relu): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=336, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU()\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=336, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_2_left): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
       "    (comb_iter_3_left): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
       "    (comb_iter_3_right): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
       "    (comb_iter_4_left): BranchSeparables(\n",
       "      (relu): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=336, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU()\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=336, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (cell_9): NormalCell(\n",
       "    (conv_prev_1x1): Sequential(\n",
       "      (relu): ReLU()\n",
       "      (conv): Conv2d(2016, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (conv_1x1): Sequential(\n",
       "      (relu): ReLU()\n",
       "      (conv): Conv2d(2016, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_0_left): BranchSeparables(\n",
       "      (relu): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=336, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU()\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=336, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_0_right): BranchSeparables(\n",
       "      (relu): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=336, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU()\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=336, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_1_left): BranchSeparables(\n",
       "      (relu): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=336, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU()\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=336, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_1_right): BranchSeparables(\n",
       "      (relu): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=336, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU()\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=336, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_2_left): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
       "    (comb_iter_3_left): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
       "    (comb_iter_3_right): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
       "    (comb_iter_4_left): BranchSeparables(\n",
       "      (relu): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=336, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU()\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=336, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (cell_10): NormalCell(\n",
       "    (conv_prev_1x1): Sequential(\n",
       "      (relu): ReLU()\n",
       "      (conv): Conv2d(2016, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (conv_1x1): Sequential(\n",
       "      (relu): ReLU()\n",
       "      (conv): Conv2d(2016, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_0_left): BranchSeparables(\n",
       "      (relu): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=336, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU()\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=336, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_0_right): BranchSeparables(\n",
       "      (relu): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=336, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU()\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=336, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_1_left): BranchSeparables(\n",
       "      (relu): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=336, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU()\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=336, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_1_right): BranchSeparables(\n",
       "      (relu): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=336, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU()\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=336, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_2_left): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
       "    (comb_iter_3_left): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
       "    (comb_iter_3_right): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
       "    (comb_iter_4_left): BranchSeparables(\n",
       "      (relu): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=336, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU()\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=336, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (cell_11): NormalCell(\n",
       "    (conv_prev_1x1): Sequential(\n",
       "      (relu): ReLU()\n",
       "      (conv): Conv2d(2016, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (conv_1x1): Sequential(\n",
       "      (relu): ReLU()\n",
       "      (conv): Conv2d(2016, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_0_left): BranchSeparables(\n",
       "      (relu): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=336, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU()\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=336, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_0_right): BranchSeparables(\n",
       "      (relu): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=336, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU()\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=336, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_1_left): BranchSeparables(\n",
       "      (relu): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=336, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU()\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=336, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_1_right): BranchSeparables(\n",
       "      (relu): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=336, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU()\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=336, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_2_left): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
       "    (comb_iter_3_left): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
       "    (comb_iter_3_right): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
       "    (comb_iter_4_left): BranchSeparables(\n",
       "      (relu): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=336, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU()\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=336, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (reduction_cell_1): ReductionCell1(\n",
       "    (conv_prev_1x1): Sequential(\n",
       "      (relu): ReLU()\n",
       "      (conv): Conv2d(2016, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (conv_1x1): Sequential(\n",
       "      (relu): ReLU()\n",
       "      (conv): Conv2d(2016, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_0_left): BranchSeparables(\n",
       "      (relu): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=672, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU()\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_0_right): BranchSeparables(\n",
       "      (relu): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), groups=672, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU()\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=672, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_1_left): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (comb_iter_1_right): BranchSeparables(\n",
       "      (relu): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), groups=672, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU()\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=672, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_2_left): AvgPool2d(kernel_size=3, stride=2, padding=1)\n",
       "    (comb_iter_2_right): BranchSeparables(\n",
       "      (relu): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=672, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU()\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_3_right): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
       "    (comb_iter_4_left): BranchSeparables(\n",
       "      (relu): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU()\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_4_right): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (cell_12): FirstCell(\n",
       "    (conv_1x1): Sequential(\n",
       "      (relu): ReLU()\n",
       "      (conv): Conv2d(2688, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (relu): ReLU()\n",
       "    (path_1): Sequential(\n",
       "      (avgpool): AvgPool2d(kernel_size=1, stride=2, padding=0)\n",
       "      (conv): Conv2d(2016, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    )\n",
       "    (path_2): ModuleList(\n",
       "      (pad): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
       "      (avgpool): AvgPool2d(kernel_size=1, stride=2, padding=0)\n",
       "      (conv): Conv2d(2016, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    )\n",
       "    (final_path_bn): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (comb_iter_0_left): BranchSeparables(\n",
       "      (relu): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU()\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_0_right): BranchSeparables(\n",
       "      (relu): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU()\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_1_left): BranchSeparables(\n",
       "      (relu): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU()\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_1_right): BranchSeparables(\n",
       "      (relu): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU()\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_2_left): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
       "    (comb_iter_3_left): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
       "    (comb_iter_3_right): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
       "    (comb_iter_4_left): BranchSeparables(\n",
       "      (relu): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU()\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (cell_13): NormalCell(\n",
       "    (conv_prev_1x1): Sequential(\n",
       "      (relu): ReLU()\n",
       "      (conv): Conv2d(2688, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (conv_1x1): Sequential(\n",
       "      (relu): ReLU()\n",
       "      (conv): Conv2d(4032, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_0_left): BranchSeparables(\n",
       "      (relu): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU()\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_0_right): BranchSeparables(\n",
       "      (relu): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU()\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_1_left): BranchSeparables(\n",
       "      (relu): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU()\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_1_right): BranchSeparables(\n",
       "      (relu): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU()\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_2_left): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
       "    (comb_iter_3_left): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
       "    (comb_iter_3_right): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
       "    (comb_iter_4_left): BranchSeparables(\n",
       "      (relu): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU()\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (cell_14): NormalCell(\n",
       "    (conv_prev_1x1): Sequential(\n",
       "      (relu): ReLU()\n",
       "      (conv): Conv2d(4032, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (conv_1x1): Sequential(\n",
       "      (relu): ReLU()\n",
       "      (conv): Conv2d(4032, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_0_left): BranchSeparables(\n",
       "      (relu): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU()\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_0_right): BranchSeparables(\n",
       "      (relu): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU()\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_1_left): BranchSeparables(\n",
       "      (relu): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU()\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_1_right): BranchSeparables(\n",
       "      (relu): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU()\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_2_left): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
       "    (comb_iter_3_left): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
       "    (comb_iter_3_right): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
       "    (comb_iter_4_left): BranchSeparables(\n",
       "      (relu): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU()\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (cell_15): NormalCell(\n",
       "    (conv_prev_1x1): Sequential(\n",
       "      (relu): ReLU()\n",
       "      (conv): Conv2d(4032, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (conv_1x1): Sequential(\n",
       "      (relu): ReLU()\n",
       "      (conv): Conv2d(4032, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_0_left): BranchSeparables(\n",
       "      (relu): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU()\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_0_right): BranchSeparables(\n",
       "      (relu): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU()\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_1_left): BranchSeparables(\n",
       "      (relu): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU()\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_1_right): BranchSeparables(\n",
       "      (relu): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU()\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_2_left): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
       "    (comb_iter_3_left): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
       "    (comb_iter_3_right): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
       "    (comb_iter_4_left): BranchSeparables(\n",
       "      (relu): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU()\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (cell_16): NormalCell(\n",
       "    (conv_prev_1x1): Sequential(\n",
       "      (relu): ReLU()\n",
       "      (conv): Conv2d(4032, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (conv_1x1): Sequential(\n",
       "      (relu): ReLU()\n",
       "      (conv): Conv2d(4032, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_0_left): BranchSeparables(\n",
       "      (relu): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU()\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_0_right): BranchSeparables(\n",
       "      (relu): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU()\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_1_left): BranchSeparables(\n",
       "      (relu): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU()\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_1_right): BranchSeparables(\n",
       "      (relu): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU()\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_2_left): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
       "    (comb_iter_3_left): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
       "    (comb_iter_3_right): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
       "    (comb_iter_4_left): BranchSeparables(\n",
       "      (relu): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU()\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (cell_17): NormalCell(\n",
       "    (conv_prev_1x1): Sequential(\n",
       "      (relu): ReLU()\n",
       "      (conv): Conv2d(4032, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (conv_1x1): Sequential(\n",
       "      (relu): ReLU()\n",
       "      (conv): Conv2d(4032, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_0_left): BranchSeparables(\n",
       "      (relu): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU()\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_0_right): BranchSeparables(\n",
       "      (relu): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU()\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_1_left): BranchSeparables(\n",
       "      (relu): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU()\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_1_right): BranchSeparables(\n",
       "      (relu): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU()\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (comb_iter_2_left): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
       "    (comb_iter_3_left): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
       "    (comb_iter_3_right): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
       "    (comb_iter_4_left): BranchSeparables(\n",
       "      (relu): ReLU()\n",
       "      (separable_1): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_1): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU()\n",
       "      (separable_2): SeparableConv2d(\n",
       "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
       "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn_sep_2): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (relu): ReLU()\n",
       "  (avg_pool): AvgPool2d(kernel_size=11, stride=1, padding=0)\n",
       "  (dropout): Dropout(p=0.5)\n",
       "  (last_linear): Linear(in_features=4032, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_transfer_NasNetALarge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "NasNetALarge_feature_layers = [model_transfer_NasNetALarge.conv0.parameters(),\n",
    "                               model_transfer_NasNetALarge.cell_stem_0.parameters(),\n",
    "                               model_transfer_NasNetALarge.cell_stem_1.parameters(),\n",
    "                               model_transfer_NasNetALarge.cell_0.parameters(),\n",
    "                               model_transfer_NasNetALarge.cell_1.parameters(),\n",
    "                               model_transfer_NasNetALarge.cell_2.parameters(),\n",
    "                               model_transfer_NasNetALarge.cell_3.parameters(),\n",
    "                               model_transfer_NasNetALarge.cell_4.parameters(),\n",
    "                               model_transfer_NasNetALarge.cell_5.parameters(),\n",
    "                               model_transfer_NasNetALarge.reduction_cell_0.parameters(),\n",
    "                               model_transfer_NasNetALarge.cell_6.parameters(),\n",
    "                               model_transfer_NasNetALarge.cell_7.parameters(),\n",
    "                               model_transfer_NasNetALarge.cell_8.parameters(),\n",
    "                               model_transfer_NasNetALarge.cell_9.parameters(),\n",
    "                               model_transfer_NasNetALarge.cell_10.parameters(),\n",
    "                               model_transfer_NasNetALarge.cell_11.parameters(),\n",
    "                               model_transfer_NasNetALarge.reduction_cell_1.parameters(),\n",
    "                               model_transfer_NasNetALarge.cell_12.parameters(),\n",
    "                               model_transfer_NasNetALarge.cell_13.parameters(),\n",
    "                               model_transfer_NasNetALarge.cell_14.parameters(),\n",
    "                               model_transfer_NasNetALarge.cell_15.parameters(),\n",
    "                               model_transfer_NasNetALarge.cell_16.parameters(),\n",
    "                               model_transfer_NasNetALarge.cell_17.parameters(),\n",
    "                               model_transfer_NasNetALarge.relu.parameters()]\n",
    "\n",
    "for parameters in NasNetALarge_feature_layers:\n",
    "    for param in parameters:\n",
    "        param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133\n"
     ]
    }
   ],
   "source": [
    "n_inputs_NasNetALarge = model_transfer_NasNetALarge.last_linear.in_features\n",
    "\n",
    "# add last linear layer (n_inputs -> 5 flower classes)\n",
    "# new layers automatically have requires_grad = True\n",
    "last_layer_NasNetALarge = nn.Linear(n_inputs_NasNetALarge, 133)\n",
    "\n",
    "model_transfer_NasNetALarge.last_linear = last_layer_NasNetALarge\n",
    "\n",
    "if use_cuda:\n",
    "    model_transfer_NasNetALarge.cuda()\n",
    "\n",
    "# check to see that your last layer produces the expected number of outputs\n",
    "print(model_transfer_NasNetALarge.last_linear.out_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion_transfer_NasNetALarge = nn.CrossEntropyLoss()\n",
    "optimizer_transfer_NasNetALarge = optim.SGD(model_transfer_NasNetALarge.last_linear.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 : 0 train_loss: tensor(4.8650, device='cuda:0')\n",
      "1 : 200 train_loss: tensor(4.3737, device='cuda:0')\n",
      "1 : 400 train_loss: tensor(3.9004, device='cuda:0')\n",
      "Elapsed Epoch Training Time: 344.8077828884125\n",
      "Epoch: 1 \tTraining Loss: 3.858470 \tValidation Loss: 2.799154\n",
      "Validation loss decreased (inf --> 2.799154).  Saving model ...\n",
      "2 : 0 train_loss: tensor(2.8581, device='cuda:0')\n",
      "2 : 200 train_loss: tensor(2.5007, device='cuda:0')\n",
      "2 : 400 train_loss: tensor(2.2025, device='cuda:0')\n",
      "Elapsed Epoch Training Time: 354.4239730834961\n",
      "Epoch: 2 \tTraining Loss: 2.180674 \tValidation Loss: 1.554366\n",
      "Validation loss decreased (2.799154 --> 1.554366).  Saving model ...\n",
      "3 : 0 train_loss: tensor(1.3278, device='cuda:0')\n",
      "3 : 200 train_loss: tensor(1.4501, device='cuda:0')\n",
      "3 : 400 train_loss: tensor(1.3072, device='cuda:0')\n",
      "Elapsed Epoch Training Time: 354.53896975517273\n",
      "Epoch: 3 \tTraining Loss: 1.300031 \tValidation Loss: 1.014098\n",
      "Validation loss decreased (1.554366 --> 1.014098).  Saving model ...\n",
      "4 : 0 train_loss: tensor(1.0943, device='cuda:0')\n",
      "4 : 200 train_loss: tensor(0.9718, device='cuda:0')\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-07fbf18dc032>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# train the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel_transfer_NasNetALarge\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloaders_transfer_NasNetALarge\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_transfer_NasNetALarge\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer_transfer_NasNetALarge\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion_transfer_NasNetALarge\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse_cuda\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'model_transfer_NasNetALarge.pt'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-4-614070b0eafc>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(n_epochs, loaders, model, optimizer, criterion, use_cuda, save_path)\u001b[0m\n\u001b[0;32m     30\u001b[0m             \u001b[1;31m## train_loss = train_loss + ((1 / (batch_idx + 1)) * (loss.data - train_loss))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m             \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m             \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    488\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 489\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    490\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-a8ad56e23a84>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    601\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    602\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 603\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    604\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogits\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    605\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-a8ad56e23a84>\u001b[0m in \u001b[0;36mfeatures\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    582\u001b[0m         \u001b[0mx_cell_11\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcell_11\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_cell_10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_cell_9\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    583\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 584\u001b[1;33m         \u001b[0mx_reduction_cell_1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduction_cell_1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_cell_11\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_cell_10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    585\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    586\u001b[0m         \u001b[0mx_cell_12\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcell_12\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_reduction_cell_1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_cell_10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    488\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 489\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    490\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-a8ad56e23a84>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x, x_prev)\u001b[0m\n\u001b[0;32m    465\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_prev\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    466\u001b[0m         \u001b[0mx_left\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv_prev_1x1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_prev\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 467\u001b[1;33m         \u001b[0mx_right\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv_1x1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    468\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    469\u001b[0m         \u001b[0mx_comb_iter_0_left\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcomb_iter_0_left\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_right\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    488\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 489\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    490\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     90\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 92\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    488\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 489\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    490\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\batchnorm.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# TODO: if statement only here to tell the jit to skip emitting this when it is None\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_batches_tracked\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_batches_tracked\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmomentum\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# use cumulative moving average\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m                     \u001b[0mexponential_average_factor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1.0\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_batches_tracked\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "model_transfer_NasNetALarge = train(20, loaders_transfer_NasNetALarge, model_transfer_NasNetALarge, optimizer_transfer_NasNetALarge, criterion_transfer_NasNetALarge, use_cuda, 'model_transfer_NasNetALarge.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model paused and batch size increased. Training for 17 more epochs to make 20 in total."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_transfer_NasNetALarge.load_state_dict(torch.load('model_transfer_NasNetALarge.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 : 0 train_loss: tensor(0.9790, device='cuda:0')\n",
      "1 : 200 train_loss: tensor(0.9584, device='cuda:0')\n",
      "Elapsed Epoch Training Time: 330.01981568336487\n",
      "Epoch: 1 \tTraining Loss: 0.957301 \tValidation Loss: 0.865920\n",
      "Validation loss decreased (inf --> 0.865920).  Saving model ...\n",
      "2 : 0 train_loss: tensor(0.8997, device='cuda:0')\n",
      "2 : 200 train_loss: tensor(0.8261, device='cuda:0')\n",
      "Elapsed Epoch Training Time: 338.4977078437805\n",
      "Epoch: 2 \tTraining Loss: 0.824055 \tValidation Loss: 0.753508\n",
      "Validation loss decreased (0.865920 --> 0.753508).  Saving model ...\n",
      "3 : 0 train_loss: tensor(0.8101, device='cuda:0')\n",
      "3 : 200 train_loss: tensor(0.7431, device='cuda:0')\n",
      "Elapsed Epoch Training Time: 337.2247977256775\n",
      "Epoch: 3 \tTraining Loss: 0.739929 \tValidation Loss: 0.682400\n",
      "Validation loss decreased (0.753508 --> 0.682400).  Saving model ...\n",
      "4 : 0 train_loss: tensor(0.7415, device='cuda:0')\n",
      "4 : 200 train_loss: tensor(0.6796, device='cuda:0')\n",
      "Elapsed Epoch Training Time: 340.5649924278259\n",
      "Epoch: 4 \tTraining Loss: 0.679777 \tValidation Loss: 0.623530\n",
      "Validation loss decreased (0.682400 --> 0.623530).  Saving model ...\n",
      "5 : 0 train_loss: tensor(0.6186, device='cuda:0')\n",
      "5 : 200 train_loss: tensor(0.6197, device='cuda:0')\n",
      "Elapsed Epoch Training Time: 341.04398798942566\n",
      "Epoch: 5 \tTraining Loss: 0.621320 \tValidation Loss: 0.594958\n",
      "Validation loss decreased (0.623530 --> 0.594958).  Saving model ...\n",
      "6 : 0 train_loss: tensor(0.6688, device='cuda:0')\n",
      "6 : 200 train_loss: tensor(0.5807, device='cuda:0')\n",
      "Elapsed Epoch Training Time: 339.3090651035309\n",
      "Epoch: 6 \tTraining Loss: 0.581067 \tValidation Loss: 0.556295\n",
      "Validation loss decreased (0.594958 --> 0.556295).  Saving model ...\n",
      "7 : 0 train_loss: tensor(0.4656, device='cuda:0')\n",
      "7 : 200 train_loss: tensor(0.5485, device='cuda:0')\n",
      "Elapsed Epoch Training Time: 340.084312915802\n",
      "Epoch: 7 \tTraining Loss: 0.548951 \tValidation Loss: 0.563368\n",
      "8 : 0 train_loss: tensor(0.6369, device='cuda:0')\n",
      "8 : 200 train_loss: tensor(0.5234, device='cuda:0')\n",
      "Elapsed Epoch Training Time: 349.01486802101135\n",
      "Epoch: 8 \tTraining Loss: 0.519267 \tValidation Loss: 0.516835\n",
      "Validation loss decreased (0.556295 --> 0.516835).  Saving model ...\n",
      "9 : 0 train_loss: tensor(0.5609, device='cuda:0')\n",
      "9 : 200 train_loss: tensor(0.5029, device='cuda:0')\n",
      "Elapsed Epoch Training Time: 339.47634530067444\n",
      "Epoch: 9 \tTraining Loss: 0.500675 \tValidation Loss: 0.498010\n",
      "Validation loss decreased (0.516835 --> 0.498010).  Saving model ...\n",
      "10 : 0 train_loss: tensor(0.7436, device='cuda:0')\n",
      "10 : 200 train_loss: tensor(0.4806, device='cuda:0')\n",
      "Elapsed Epoch Training Time: 341.7320246696472\n",
      "Epoch: 10 \tTraining Loss: 0.481525 \tValidation Loss: 0.483873\n",
      "Validation loss decreased (0.498010 --> 0.483873).  Saving model ...\n",
      "11 : 0 train_loss: tensor(0.3613, device='cuda:0')\n",
      "11 : 200 train_loss: tensor(0.4615, device='cuda:0')\n",
      "Elapsed Epoch Training Time: 340.40434527397156\n",
      "Epoch: 11 \tTraining Loss: 0.460744 \tValidation Loss: 0.460164\n",
      "Validation loss decreased (0.483873 --> 0.460164).  Saving model ...\n",
      "12 : 0 train_loss: tensor(0.3349, device='cuda:0')\n",
      "12 : 200 train_loss: tensor(0.4504, device='cuda:0')\n",
      "Elapsed Epoch Training Time: 336.732928276062\n",
      "Epoch: 12 \tTraining Loss: 0.449460 \tValidation Loss: 0.448940\n",
      "Validation loss decreased (0.460164 --> 0.448940).  Saving model ...\n",
      "13 : 0 train_loss: tensor(0.3813, device='cuda:0')\n",
      "13 : 200 train_loss: tensor(0.4374, device='cuda:0')\n",
      "Elapsed Epoch Training Time: 341.3818590641022\n",
      "Epoch: 13 \tTraining Loss: 0.435944 \tValidation Loss: 0.445728\n",
      "Validation loss decreased (0.448940 --> 0.445728).  Saving model ...\n",
      "14 : 0 train_loss: tensor(0.3976, device='cuda:0')\n",
      "14 : 200 train_loss: tensor(0.4226, device='cuda:0')\n",
      "Elapsed Epoch Training Time: 346.7178158760071\n",
      "Epoch: 14 \tTraining Loss: 0.422513 \tValidation Loss: 0.440276\n",
      "Validation loss decreased (0.445728 --> 0.440276).  Saving model ...\n",
      "15 : 0 train_loss: tensor(0.4632, device='cuda:0')\n",
      "15 : 200 train_loss: tensor(0.4149, device='cuda:0')\n",
      "Elapsed Epoch Training Time: 347.51279520988464\n",
      "Epoch: 15 \tTraining Loss: 0.414667 \tValidation Loss: 0.420804\n",
      "Validation loss decreased (0.440276 --> 0.420804).  Saving model ...\n",
      "16 : 0 train_loss: tensor(0.4111, device='cuda:0')\n",
      "16 : 200 train_loss: tensor(0.4005, device='cuda:0')\n",
      "Elapsed Epoch Training Time: 343.78440499305725\n",
      "Epoch: 16 \tTraining Loss: 0.401954 \tValidation Loss: 0.414454\n",
      "Validation loss decreased (0.420804 --> 0.414454).  Saving model ...\n",
      "17 : 0 train_loss: tensor(0.2467, device='cuda:0')\n",
      "17 : 200 train_loss: tensor(0.3962, device='cuda:0')\n",
      "Elapsed Epoch Training Time: 344.17880153656006\n",
      "Epoch: 17 \tTraining Loss: 0.394631 \tValidation Loss: 0.404560\n",
      "Validation loss decreased (0.414454 --> 0.404560).  Saving model ...\n"
     ]
    }
   ],
   "source": [
    "model_transfer_NasNetALarge = train(17, loaders_transfer_NasNetALarge, model_transfer_NasNetALarge, optimizer_transfer_NasNetALarge, criterion_transfer_NasNetALarge, use_cuda, 'model_transfer_NasNetALarge.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_transfer_NasNetALarge.load_state_dict(torch.load('model_transfer_NasNetALarge.pt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.444795\n",
      "\n",
      "\n",
      "Test Accuracy: 88% (737/836)\n"
     ]
    }
   ],
   "source": [
    "test(loaders_transfer_NasNetALarge, model_transfer_NasNetALarge, criterion_transfer_NasNetALarge, use_cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interestingly NasNetALarge didn't perform as well as SENet-154, in both accuracy, and time/performance demand. This perhaps maybe due to factors such as different accuracy of pretraining for dog breeds, and the much higher dropout (50%) in NasNetALarge prior to the last linear layer (as a result NasNetALarge did not show evidence of overfitting like SENet-154 did in higher epochs). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Dog Breed with the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_transfer.load_state_dict(torch.load('model_transfer.pt'))\n",
    "\n",
    "# list of class names by index, i.e. a name can be accessed like class_names[0]\n",
    "class_names = [item[4:].replace(\"_\", \" \") for item in train_set_transfer.classes]\n",
    "\n",
    "def predict_breed_transfer(img_path):\n",
    "    # load the image and return the predicted breed\n",
    "    img = Image.open(img_path)\n",
    "    img_tensor = transform_transfer(img)\n",
    "    img_tensor = img_tensor.unsqueeze_(0)\n",
    "    img_tensor = img_tensor.cuda()\n",
    "    model_transfer.eval()\n",
    "    output = model_transfer(img_tensor)\n",
    "    pred = output.data.max(1, keepdim=True)[1]\n",
    "    \n",
    "    return class_names[pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_app(img_path):\n",
    "    ## handle cases for a human face, dog, and neither\n",
    "    if VGG_dog_detector(img_path, vgg='VGG19') == True:\n",
    "        dog_breed = predict_breed_transfer(img_path)\n",
    "        print('Dog detected. Predicted dog breed is:', dog_breed)\n",
    "        return dog_breed\n",
    "    elif face_detector(img_path) == True:\n",
    "        human_breed = predict_breed_transfer(img_path)\n",
    "        print('Human face detected. Dog breed most resebmbling human face is:', human_breed)\n",
    "        return human_breed\n",
    "    else:\n",
    "        print('Neither human nor dog detected. Returning None.')\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human face detected. Dog breed most resebmbling human face is: Dachshund\n",
      "Human face detected. Dog breed most resebmbling human face is: Smooth fox terrier\n",
      "Neither human nor dog detected. Returning None.\n",
      "Human face detected. Dog breed most resebmbling human face is: Dachshund\n",
      "Human face detected. Dog breed most resebmbling human face is: Irish red and white setter\n",
      "Human face detected. Dog breed most resebmbling human face is: Dachshund\n",
      "Human face detected. Dog breed most resebmbling human face is: Chinese crested\n",
      "Human face detected. Dog breed most resebmbling human face is: Lowchen\n",
      "Human face detected. Dog breed most resebmbling human face is: Poodle\n",
      "Human face detected. Dog breed most resebmbling human face is: Australian shepherd\n",
      "Human face detected. Dog breed most resebmbling human face is: Australian shepherd\n",
      "Human face detected. Dog breed most resebmbling human face is: Glen of imaal terrier\n",
      "Human face detected. Dog breed most resebmbling human face is: Glen of imaal terrier\n",
      "Human face detected. Dog breed most resebmbling human face is: Australian shepherd\n",
      "Human face detected. Dog breed most resebmbling human face is: Bull terrier\n",
      "Human face detected. Dog breed most resebmbling human face is: Lowchen\n",
      "Human face detected. Dog breed most resebmbling human face is: Dachshund\n",
      "Human face detected. Dog breed most resebmbling human face is: Poodle\n",
      "Human face detected. Dog breed most resebmbling human face is: Poodle\n",
      "Human face detected. Dog breed most resebmbling human face is: German shorthaired pointer\n",
      "Human face detected. Dog breed most resebmbling human face is: Xoloitzcuintli\n",
      "Human face detected. Dog breed most resebmbling human face is: Australian shepherd\n",
      "Human face detected. Dog breed most resebmbling human face is: Poodle\n",
      "Human face detected. Dog breed most resebmbling human face is: Australian shepherd\n",
      "Human face detected. Dog breed most resebmbling human face is: Australian shepherd\n",
      "Human face detected. Dog breed most resebmbling human face is: Poodle\n",
      "Human face detected. Dog breed most resebmbling human face is: Australian shepherd\n",
      "Neither human nor dog detected. Returning None.\n",
      "Human face detected. Dog breed most resebmbling human face is: Petit basset griffon vendeen\n",
      "Human face detected. Dog breed most resebmbling human face is: Lowchen\n",
      "Human face detected. Dog breed most resebmbling human face is: Australian shepherd\n",
      "Human face detected. Dog breed most resebmbling human face is: Lowchen\n",
      "Human face detected. Dog breed most resebmbling human face is: Dogue de bordeaux\n",
      "Human face detected. Dog breed most resebmbling human face is: Lowchen\n",
      "Human face detected. Dog breed most resebmbling human face is: Australian shepherd\n",
      "Human face detected. Dog breed most resebmbling human face is: Glen of imaal terrier\n",
      "Human face detected. Dog breed most resebmbling human face is: Australian shepherd\n",
      "Human face detected. Dog breed most resebmbling human face is: Australian shepherd\n",
      "Human face detected. Dog breed most resebmbling human face is: Australian shepherd\n",
      "Human face detected. Dog breed most resebmbling human face is: Bull terrier\n",
      "Human face detected. Dog breed most resebmbling human face is: Glen of imaal terrier\n",
      "Human face detected. Dog breed most resebmbling human face is: Australian shepherd\n",
      "Human face detected. Dog breed most resebmbling human face is: Australian shepherd\n",
      "Human face detected. Dog breed most resebmbling human face is: Australian shepherd\n",
      "Human face detected. Dog breed most resebmbling human face is: Australian shepherd\n",
      "Neither human nor dog detected. Returning None.\n",
      "Human face detected. Dog breed most resebmbling human face is: Glen of imaal terrier\n",
      "Human face detected. Dog breed most resebmbling human face is: Lowchen\n",
      "Human face detected. Dog breed most resebmbling human face is: Poodle\n",
      "Human face detected. Dog breed most resebmbling human face is: Poodle\n",
      "Human face detected. Dog breed most resebmbling human face is: Lowchen\n",
      "Human face detected. Dog breed most resebmbling human face is: Australian shepherd\n",
      "Neither human nor dog detected. Returning None.\n",
      "Human face detected. Dog breed most resebmbling human face is: Australian shepherd\n",
      "Human face detected. Dog breed most resebmbling human face is: Australian shepherd\n",
      "Human face detected. Dog breed most resebmbling human face is: Australian shepherd\n",
      "Human face detected. Dog breed most resebmbling human face is: Australian shepherd\n",
      "Human face detected. Dog breed most resebmbling human face is: Australian shepherd\n",
      "Human face detected. Dog breed most resebmbling human face is: Icelandic sheepdog\n",
      "Human face detected. Dog breed most resebmbling human face is: Australian cattle dog\n",
      "Human face detected. Dog breed most resebmbling human face is: Chinese crested\n",
      "Human face detected. Dog breed most resebmbling human face is: Australian shepherd\n",
      "Human face detected. Dog breed most resebmbling human face is: Chinese shar-pei\n",
      "Human face detected. Dog breed most resebmbling human face is: Australian shepherd\n",
      "Human face detected. Dog breed most resebmbling human face is: Petit basset griffon vendeen\n",
      "Human face detected. Dog breed most resebmbling human face is: Dachshund\n",
      "Human face detected. Dog breed most resebmbling human face is: Dachshund\n",
      "Human face detected. Dog breed most resebmbling human face is: Australian shepherd\n",
      "Human face detected. Dog breed most resebmbling human face is: Poodle\n",
      "Human face detected. Dog breed most resebmbling human face is: Dachshund\n",
      "Human face detected. Dog breed most resebmbling human face is: Lowchen\n",
      "Human face detected. Dog breed most resebmbling human face is: Australian shepherd\n",
      "Human face detected. Dog breed most resebmbling human face is: Chinese crested\n",
      "Human face detected. Dog breed most resebmbling human face is: Akita\n",
      "Human face detected. Dog breed most resebmbling human face is: Dachshund\n",
      "Human face detected. Dog breed most resebmbling human face is: Dachshund\n",
      "Human face detected. Dog breed most resebmbling human face is: Anatolian shepherd dog\n",
      "Human face detected. Dog breed most resebmbling human face is: Bichon frise\n",
      "Human face detected. Dog breed most resebmbling human face is: Petit basset griffon vendeen\n",
      "Human face detected. Dog breed most resebmbling human face is: Australian shepherd\n",
      "Human face detected. Dog breed most resebmbling human face is: Australian shepherd\n",
      "Human face detected. Dog breed most resebmbling human face is: Dachshund\n",
      "Human face detected. Dog breed most resebmbling human face is: Wirehaired pointing griffon\n",
      "Human face detected. Dog breed most resebmbling human face is: Dachshund\n",
      "Human face detected. Dog breed most resebmbling human face is: Australian shepherd\n",
      "Human face detected. Dog breed most resebmbling human face is: Glen of imaal terrier\n",
      "Human face detected. Dog breed most resebmbling human face is: Irish wolfhound\n",
      "Human face detected. Dog breed most resebmbling human face is: Chinese crested\n",
      "Human face detected. Dog breed most resebmbling human face is: Chinese crested\n",
      "Human face detected. Dog breed most resebmbling human face is: Lowchen\n",
      "Human face detected. Dog breed most resebmbling human face is: Lowchen\n",
      "Human face detected. Dog breed most resebmbling human face is: Irish red and white setter\n",
      "Human face detected. Dog breed most resebmbling human face is: Dogue de bordeaux\n",
      "Human face detected. Dog breed most resebmbling human face is: Australian shepherd\n",
      "Human face detected. Dog breed most resebmbling human face is: American water spaniel\n",
      "Human face detected. Dog breed most resebmbling human face is: Chinese crested\n",
      "Human face detected. Dog breed most resebmbling human face is: Poodle\n",
      "Human face detected. Dog breed most resebmbling human face is: Australian shepherd\n",
      "Human face detected. Dog breed most resebmbling human face is: Glen of imaal terrier\n",
      "Human face detected. Dog breed most resebmbling human face is: Glen of imaal terrier\n",
      "Dog detected. Predicted dog breed is: Affenpinscher\n",
      "Dog detected. Predicted dog breed is: Affenpinscher\n",
      "Dog detected. Predicted dog breed is: Affenpinscher\n",
      "Dog detected. Predicted dog breed is: Affenpinscher\n",
      "Dog detected. Predicted dog breed is: Affenpinscher\n",
      "Dog detected. Predicted dog breed is: Havanese\n",
      "Dog detected. Predicted dog breed is: Affenpinscher\n",
      "Dog detected. Predicted dog breed is: Affenpinscher\n",
      "Dog detected. Predicted dog breed is: Afghan hound\n",
      "Dog detected. Predicted dog breed is: Afghan hound\n",
      "Dog detected. Predicted dog breed is: Afghan hound\n",
      "Dog detected. Predicted dog breed is: Chinese crested\n",
      "Dog detected. Predicted dog breed is: Afghan hound\n",
      "Dog detected. Predicted dog breed is: Afghan hound\n",
      "Dog detected. Predicted dog breed is: Afghan hound\n",
      "Dog detected. Predicted dog breed is: Afghan hound\n",
      "Dog detected. Predicted dog breed is: Airedale terrier\n",
      "Dog detected. Predicted dog breed is: Airedale terrier\n",
      "Dog detected. Predicted dog breed is: Airedale terrier\n",
      "Dog detected. Predicted dog breed is: Airedale terrier\n",
      "Dog detected. Predicted dog breed is: Airedale terrier\n",
      "Dog detected. Predicted dog breed is: Airedale terrier\n",
      "Dog detected. Predicted dog breed is: Akita\n",
      "Dog detected. Predicted dog breed is: Akita\n",
      "Neither human nor dog detected. Returning None.\n",
      "Dog detected. Predicted dog breed is: Akita\n",
      "Dog detected. Predicted dog breed is: Akita\n",
      "Dog detected. Predicted dog breed is: Akita\n",
      "Dog detected. Predicted dog breed is: Akita\n",
      "Dog detected. Predicted dog breed is: Akita\n",
      "Dog detected. Predicted dog breed is: Alaskan malamute\n",
      "Dog detected. Predicted dog breed is: Alaskan malamute\n",
      "Dog detected. Predicted dog breed is: Alaskan malamute\n",
      "Dog detected. Predicted dog breed is: Alaskan malamute\n",
      "Dog detected. Predicted dog breed is: Alaskan malamute\n",
      "Dog detected. Predicted dog breed is: Alaskan malamute\n",
      "Dog detected. Predicted dog breed is: Alaskan malamute\n",
      "Dog detected. Predicted dog breed is: Alaskan malamute\n",
      "Dog detected. Predicted dog breed is: Alaskan malamute\n",
      "Dog detected. Predicted dog breed is: Alaskan malamute\n",
      "Dog detected. Predicted dog breed is: American eskimo dog\n",
      "Dog detected. Predicted dog breed is: American eskimo dog\n",
      "Dog detected. Predicted dog breed is: American eskimo dog\n",
      "Dog detected. Predicted dog breed is: American eskimo dog\n",
      "Neither human nor dog detected. Returning None.\n",
      "Dog detected. Predicted dog breed is: American eskimo dog\n",
      "Dog detected. Predicted dog breed is: American eskimo dog\n",
      "Dog detected. Predicted dog breed is: American eskimo dog\n",
      "Dog detected. Predicted dog breed is: American foxhound\n",
      "Dog detected. Predicted dog breed is: American foxhound\n",
      "Dog detected. Predicted dog breed is: American foxhound\n",
      "Dog detected. Predicted dog breed is: American foxhound\n",
      "Dog detected. Predicted dog breed is: Beagle\n",
      "Dog detected. Predicted dog breed is: American foxhound\n",
      "Dog detected. Predicted dog breed is: Beagle\n",
      "Dog detected. Predicted dog breed is: American staffordshire terrier\n",
      "Dog detected. Predicted dog breed is: American staffordshire terrier\n",
      "Dog detected. Predicted dog breed is: American staffordshire terrier\n",
      "Dog detected. Predicted dog breed is: American staffordshire terrier\n",
      "Dog detected. Predicted dog breed is: American staffordshire terrier\n",
      "Dog detected. Predicted dog breed is: American staffordshire terrier\n",
      "Dog detected. Predicted dog breed is: American staffordshire terrier\n",
      "Dog detected. Predicted dog breed is: American staffordshire terrier\n",
      "Dog detected. Predicted dog breed is: Field spaniel\n",
      "Dog detected. Predicted dog breed is: American water spaniel\n",
      "Dog detected. Predicted dog breed is: American water spaniel\n",
      "Dog detected. Predicted dog breed is: American water spaniel\n",
      "Dog detected. Predicted dog breed is: Anatolian shepherd dog\n",
      "Dog detected. Predicted dog breed is: Anatolian shepherd dog\n",
      "Dog detected. Predicted dog breed is: Anatolian shepherd dog\n",
      "Dog detected. Predicted dog breed is: Anatolian shepherd dog\n",
      "Dog detected. Predicted dog breed is: Anatolian shepherd dog\n",
      "Dog detected. Predicted dog breed is: Anatolian shepherd dog\n",
      "Dog detected. Predicted dog breed is: Australian cattle dog\n",
      "Neither human nor dog detected. Returning None.\n",
      "Dog detected. Predicted dog breed is: Australian cattle dog\n",
      "Dog detected. Predicted dog breed is: Australian cattle dog\n",
      "Human face detected. Dog breed most resebmbling human face is: Canaan dog\n",
      "Dog detected. Predicted dog breed is: Australian cattle dog\n",
      "Dog detected. Predicted dog breed is: Australian cattle dog\n",
      "Human face detected. Dog breed most resebmbling human face is: Australian cattle dog\n",
      "Dog detected. Predicted dog breed is: Australian cattle dog\n",
      "Dog detected. Predicted dog breed is: Australian shepherd\n",
      "Dog detected. Predicted dog breed is: Australian shepherd\n",
      "Dog detected. Predicted dog breed is: Nova scotia duck tolling retriever\n",
      "Dog detected. Predicted dog breed is: Australian shepherd\n",
      "Dog detected. Predicted dog breed is: Australian shepherd\n",
      "Dog detected. Predicted dog breed is: Australian shepherd\n",
      "Dog detected. Predicted dog breed is: Australian shepherd\n",
      "Dog detected. Predicted dog breed is: Australian shepherd\n",
      "Dog detected. Predicted dog breed is: Australian shepherd\n",
      "Dog detected. Predicted dog breed is: Australian terrier\n",
      "Dog detected. Predicted dog breed is: Australian terrier\n",
      "Dog detected. Predicted dog breed is: Australian terrier\n",
      "Dog detected. Predicted dog breed is: Australian terrier\n",
      "Dog detected. Predicted dog breed is: Australian terrier\n",
      "Dog detected. Predicted dog breed is: Australian terrier\n",
      "Dog detected. Predicted dog breed is: Basenji\n",
      "Dog detected. Predicted dog breed is: Basenji\n",
      "Dog detected. Predicted dog breed is: Basenji\n"
     ]
    }
   ],
   "source": [
    "for file in np.hstack((human_files[:100], dog_files[:100])):\n",
    "    run_app(file)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
